<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[linux 平均负载 load average 的含义]]></title>
    <url>%2F2019%2F09%2F14%2Flinux-load%2F</url>
    <content type="text"><![CDATA[load average 的含义平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数。和 CPU 使用率并没有直接的关系 一般的进程需要消耗 CPU、内存、磁盘I/O、网络I/O等资源，在这种情况下，平均负载就不是单独指的CPU使用情况。即内存、磁盘、网络等因素也可以影响系统的平均负载值。不过影响最大的是 CPU 使用率、CPU 等待和磁盘I/O。 一个机器的负载情况通常是通过 CPU 核数来判断的。当平均负载比 CPU 核数还大的时候，系统已经出现了过载。 如在单核处理器中，平均负载值为 1 或者小于 1 的时候，系统处理进程会非常轻松，即负载很低。当达到 3 的时候，就会显得很忙，达到 5 或者 8 的时候就不能很好的处理进程了（其中 5 和 8 目前还是个争议的阈值，为了保守起见，建议选择低的）。 查看load average 数据下面几个命令都可以看到 load average 123# top # uptime # w 截图如下： top 命令: uptime 命令: w 命令: 这里的 load average 的三个值分别指系统在最后 1/5/15 分钟 的平均负载值。 根据经验：我们应该把重点放在5/15分钟的平均负载，因为 1 分钟的平均负载太频繁，一瞬间的高并发就会导致该值的大幅度改变。 平均负载与 CPU 使用率在日常使用中，我们经常容易把平均负载和 CPU 使用率混淆，这里我们做下区分。 可能我们会有疑惑，既然平均负载代表的是活跃进程数，那么平均负载高了，不就意味着 CPU 使用率高了吗？ 这里我们还得回到平均负载的含义上来，平均负载是指单位时间内，处于可运行状态和不可中断状态的进程数。所以，他不仅包扩了正在使用CPU的进程，还包括等待 CPU 和等待磁盘I/O的进程。 而 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，和平均负载并不一定完全对应。比如： CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的。 I/O 密集型进程， 等待 I/O 也会导致平均负载升高，但是 CPU 使用率不一定很高。 大量等待CPU的进程调用也会导致平均负载升高，此时的 CPU 使用率也会比较高。 平均负载案例分析机器是一个 16 核 CPU 的。 这里会用到 2 个工具，stress 和 sysstat。 stress 是一个 Linux 系统压力测试工具，这里我们用作异常进程模拟平均负载升高的场景。 sysstat 是一个 Linux 性能工具，用来监控和分析系统的性能，以下案例中会用到这个包的 2 个命令 mpstat 和 pidstat。 mpstat 是一个常用的多核 CPU 性能分析工具，用来实时查看每个 CPU 的性能指标，以及所有 CPU 的平均指标。 pidstat 是一个常用的进程性能分析工具，用来实时查看进程的 CPU、内存、I/O 以及上下文切换等性能指标。 场景1：CPU密集型进程我们打开终端一运行 stree 命令，模拟一个 CPU 使用率 100% 的场景 12[root@localhost ~]# stress --cpu 1 --timeout 600stress: info: [5399] dispatching hogs: 1 cpu, 0 io, 0 vm, 0 hdd 我们打开终端二，查看 CPU 负载的上升状态 12345678910[root@localhost ~]# uptime 01:50:42 up 1 day, 1:42, 3 users, load average: 0.68, 0.22, 0.11[root@localhost ~]# uptime 01:50:45 up 1 day, 1:42, 3 users, load average: 0.71, 0.23, 0.12[root@localhost ~]# uptime 01:51:10 up 1 day, 1:43, 3 users, load average: 0.81, 0.29, 0.14[root@localhost ~]# uptime 01:54:58 up 1 day, 1:47, 4 users, load average: 1.03, 0.68, 0.33# 一段时间后，我们发现1分钟的平均 load 值超过了1，为啥？ 设备上还有些其他进程运行啊。 打开终端三，查看 CPU 使用状态 1234567891011121314151617181920212223[root@localhost ~]# mpstat -P ALL 5Linux 3.10.0-514.16.1.el7.x86_64 (localhost.localdomain) 11/24/2018 _x86_64_ (16 CPU)01:53:08 AM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle01:53:13 AM all 6.24 0.00 0.01 0.00 0.00 0.00 0.01 0.00 0.00 93.7301:53:13 AM 0 0.00 0.00 0.00 0.00 0.00 0.00 0.20 0.00 0.00 99.8001:53:13 AM 1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0001:53:13 AM 2 0.20 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.8001:53:13 AM 3 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0001:53:13 AM 4 0.00 0.00 0.20 0.00 0.00 0.00 0.00 0.00 0.00 99.8001:53:13 AM 5 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0001:53:13 AM 6 0.00 0.00 0.20 0.00 0.00 0.00 0.00 0.00 0.00 99.8001:53:13 AM 7 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0001:53:13 AM 8 0.20 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.8001:53:13 AM 9 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0001:53:13 AM 10 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0001:53:13 AM 11 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0001:53:13 AM 12 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0001:53:13 AM 13 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0001:53:13 AM 14 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0001:53:13 AM 15 100.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00# 这里我们可以看到，在CPU15上 CPU的使用率一直处于100%状态，使用这个工具可以持续看到状态的变化。 从终端二中可以看到，1 分钟的平均负载慢慢会增加到 1；而从终端三中可以看到，正好有一个 CPU 的使用率为 100%，但他的 iowait 为 0。这说明，平均负载的升高正是由于 CPU 使用率为 100% 导致的。 那么，到底是哪个进程导致了 CPU 使用率为 100% 呢？ 你可以使用 pidstat 来查询： 123456789101112[root@localhost ~]# pidstat -u 5 1Linux 3.10.0-514.16.1.el7.x86_64 (localhost.localdomain) 11/24/2018 _x86_64_ (16 CPU)02:00:20 AM UID PID %usr %system %guest %CPU CPU Command02:00:25 AM 0 8451 100.00 0.00 0.00 100.00 2 stress02:00:25 AM 0 8456 0.00 0.20 0.00 0.20 3 pidstat02:00:25 AM 0 8457 0.20 0.20 0.00 0.40 15 clientAverage: UID PID %usr %system %guest %CPU CPU CommandAverage: 0 8451 100.00 0.00 0.00 100.00 - stressAverage: 0 8456 0.00 0.20 0.00 0.20 - pidstatAverage: 0 8457 0.20 0.20 0.00 0.40 - client 从这里，可以明显看到，stress 进程的 CPU 使用率为 100%。 场景二：I/O 密集型进程首先还是运行 stress 命令，但这次模拟 I/O 压力，即不停的执行 sync。 打开终端一，执行 stress 12[root@localhost ~]# stress -i 1 --timeout 3600stress: info: [8817] dispatching hogs: 0 cpu, 1 io, 0 vm, 0 hdd 打开终端二 123456[root@localhost ~]# uptime 02:02:36 up 1 day, 1:54, 4 users, load average: 0.83, 0.85, 0.56[root@localhost ~]# uptime 02:05:27 up 1 day, 1:57, 4 users, load average: 0.99, 0.92, 0.63# 这里，也会看到，load会不断的升高 打开终端三 123456789101112131415161718192021222324[root@localhost ~]# mpstat -P ALL 5Linux 3.10.0-514.16.1.el7.x86_64 (localhost.localdomain) 11/24/2018 _x86_64_ (16 CPU)Average: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idleAverage: all 0.05 0.00 5.93 0.34 0.00 0.00 0.05 0.00 0.00 93.63Average: 0 0.16 0.00 0.48 0.00 0.00 0.00 0.14 0.00 0.00 99.22Average: 1 0.03 0.00 0.09 0.01 0.00 0.00 0.03 0.00 0.00 99.84Average: 2 0.03 0.00 0.09 0.00 0.00 0.00 0.01 0.00 0.00 99.88Average: 3 0.09 0.00 0.23 0.00 0.00 0.00 0.03 0.00 0.00 99.65Average: 4 0.13 0.00 0.53 0.00 0.00 0.00 0.05 0.00 0.00 99.29Average: 5 0.02 0.00 0.05 0.00 0.00 0.00 0.05 0.00 0.00 99.88Average: 6 0.02 0.00 0.35 0.00 0.00 0.00 0.08 0.00 0.00 99.56Average: 7 0.02 0.00 0.04 0.00 0.00 0.00 0.03 0.00 0.00 99.90Average: 8 0.02 0.00 0.14 0.00 0.00 0.00 0.04 0.00 0.00 99.80Average: 9 0.10 0.00 0.28 0.00 0.00 0.00 0.03 0.00 0.00 99.59Average: 10 0.09 0.00 0.34 0.00 0.00 0.00 0.05 0.00 0.00 99.52Average: 11 0.01 0.00 0.06 0.00 0.00 0.00 0.03 0.00 0.00 99.90Average: 12 0.03 0.00 33.73 1.96 0.00 0.00 0.05 0.00 0.00 64.23Average: 13 0.02 0.00 0.04 0.00 0.00 0.00 0.02 0.00 0.00 99.92Average: 14 0.03 0.00 2.43 0.12 0.00 0.00 0.04 0.00 0.00 97.37Average: 15 0.04 0.00 56.38 3.30 0.00 0.00 0.17 0.00 0.00 40.12# 这里看到，CPU 的 use 使用不是很高，反而 sys 使用的比较高，分布在了 2 个 CPU 上，约等于 100%# 同时可以看到 iowait 的值也升高了一些，由于我的设备全是 ssd 磁盘，所以这个 io 的性能可能会稍微好一些。 从以上操作中，我们看到 1 分钟的平均负载会慢慢的增加，其中一个 CPU 的系统 CPU 使用率提升到了 56 ，同时 iowait 也提升到了 3，这说明平均负载的升高是由于系统资源使用和 iowait 导致。 这里更新 sysstat 包的版本 12[root@localhost ~]# wget http://pagesperso-orange.fr/sebastien.godard/sysstat-12.1.1-1.x86_64.rpm[root@localhost ~]# rpm -Uvh sysstat-12.1.1-1.x86_64.rpm 那么到底是哪个进程，导致系统 CPU 使用率特别高，及 CPU 的等待 wait 情况 12345678910111213[root@localhost ~]# pidstat -u 5 1Linux 3.10.0-514.16.1.el7.x86_64 (localhost.localdomain) 11/24/2018 _x86_64_ (16 CPU)02:34:53 AM UID PID %usr %system %guest %wait %CPU CPU Command02:34:58 AM 0 730 0.00 0.20 0.00 0.00 0.20 12 xfsaild/vda602:34:58 AM 0 1471 0.00 0.20 0.00 0.00 0.20 10 kworker/10:202:34:58 AM 0 3042 0.00 0.40 0.00 0.00 0.40 7 kworker/7:1H02:34:58 AM 0 11617 0.00 1.59 0.00 0.00 1.59 2 kworker/u32:102:34:58 AM 0 15272 0.00 91.43 0.00 0.40 91.43 7 stress02:34:58 AM 0 15273 0.00 0.20 0.00 0.00 0.20 14 kworker/u32:002:34:58 AM 0 15274 0.20 0.40 0.00 0.00 0.60 5 pidstat# %wait：表示等待运行时任务占用 CPU 百分比。 通过以上的信息，可以很清晰的看到，是由于 stress 进程出现了大量的系统使用。 场景三：大量进程的场景当系统中运行进程超出CPU运行能力时，就会出现等待CPU的进程。 我们打开终端一：使用 stress 模拟 24 个进程 12[root@localhost ~]# stress -c 24 --timeout 3600stress: info: [11726] dispatching hogs: 24 cpu, 0 io, 0 vm, 0 hdd 打开终端二：看下当前的负载值 123456[root@localhost ~]# uptime 02:20:36 up 1 day, 2:12, 4 users, load average: 17.22, 5.98, 2.61[root@localhost ~]# uptime 02:20:52 up 1 day, 2:13, 4 users, load average: 18.72, 6.86, 2.95[root@localhost ~]# uptime 02:24:03 up 1 day, 2:16, 4 users, load average: 23.77, 14.94, 6.85 打开终端三：看下进程的资源使用信息 12345678910111213141516171819202122232425262728293031[root@localhost ~]# pidstat -u 5 1Linux 3.10.0-514.16.1.el7.x86_64 (localhost.localdomain) 11/24/2018 _x86_64_ (16 CPU)02:28:14 AM UID PID %usr %system %guest %wait %CPU CPU Command02:28:19 AM 0 43 0.00 0.20 0.00 0.00 0.20 7 ksoftirqd/702:28:19 AM 0 2292 0.20 0.00 0.00 0.00 0.20 11 dstat02:28:19 AM 0 11727 48.81 0.00 0.00 44.05 48.81 5 stress02:28:19 AM 0 11728 44.64 0.00 0.00 0.00 44.64 12 stress02:28:19 AM 0 11729 41.27 0.00 0.00 49.60 41.27 11 stress02:28:19 AM 0 11730 46.03 0.00 0.00 41.27 46.03 2 stress02:28:19 AM 0 11731 59.92 0.00 0.00 30.16 59.92 15 stress02:28:19 AM 0 11732 47.62 0.00 0.00 25.60 47.62 13 stress02:28:19 AM 0 11733 65.67 0.00 0.00 22.02 65.67 2 stress02:28:19 AM 0 11734 41.67 0.00 0.00 50.40 41.67 10 stress02:28:19 AM 0 11735 54.17 0.00 0.00 32.34 54.17 15 stress02:28:19 AM 0 11736 42.06 0.00 0.00 50.20 42.06 6 stress02:28:19 AM 0 11737 35.91 0.00 0.00 29.96 35.91 3 stress02:28:19 AM 0 11738 50.20 0.00 0.00 5.16 50.20 10 stress02:28:19 AM 0 11739 42.06 0.00 0.00 49.60 42.06 6 stress02:28:19 AM 0 11740 58.73 0.00 0.00 34.92 58.73 4 stress02:28:19 AM 0 11741 46.63 0.00 0.00 13.49 46.63 1 stress02:28:19 AM 0 11742 43.45 0.00 0.00 50.79 43.45 14 stress02:28:19 AM 0 11743 44.05 0.00 0.00 45.24 44.05 7 stress02:28:19 AM 0 11744 56.55 0.00 0.00 12.70 56.55 0 stress02:28:19 AM 0 11745 46.23 0.00 0.00 49.80 46.23 5 stress02:28:19 AM 0 11746 49.40 0.00 0.00 41.27 49.40 11 stress02:28:19 AM 0 11747 43.65 0.00 0.00 49.40 43.65 14 stress02:28:19 AM 0 11748 59.33 0.00 0.00 0.99 59.33 8 stress02:28:19 AM 0 11749 46.43 0.00 0.00 45.24 46.43 4 stress02:28:19 AM 0 11750 51.19 0.00 0.00 24.60 51.19 9 stress02:28:19 AM 0 14276 0.00 0.40 0.00 0.20 0.40 10 pidstat 我们发现，运行的 24 个 stress 进程，出现了资源争抢的问题，既然出现了资源争抢，就会出现等待时间 wait。 注意事项1、iowait 不等于 cpu wait。 2、iowait 多少算高。 123一般 iowait 达 30% 就算高了，需要关注。使用：iostat -x 1 10其中如果 %util 到 70%，那么磁盘IO 就很频繁了，需要重点关注。 参考文章1、如何理解linux的平均负载？]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[percona-toolkit大表操作DDL使用]]></title>
    <url>%2F2019%2F09%2F02%2Fpercona01%2F</url>
    <content type="text"><![CDATA[操作系统与安装数据库1234567891011121314[root@zhang ~]# cat /etc/redhat-release # 也可以使用其他版本 CentOS Linux release 7.4.1708 (Core)[root@zhang ~]# yum install -y mariadb mariadb-server # CentOS7的mysql数据库为mariadb ………………[root@zhang ~]# systemctl enable mariadb.service # 开机自启动mariadb Created symlink from /etc/systemd/system/multi-user.target.wants/mariadb.service to /usr/lib/systemd/system/mariadb.service.[root@zhang ~]# systemctl start mariadb.service # 启动mariadb [root@zhang ~]# systemctl status mariadb.service # 查看mariadb服务状态 ● mariadb.service - MariaDB database server Loaded: loaded (/usr/lib/systemd/system/mariadb.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2018-05-23 17:13:35 CST; 6s ago Process: 1755 ExecStartPost=/usr/libexec/mariadb-wait-ready $MAINPID (code=exited, status=0/SUCCESS) Process: 1675 ExecStartPre=/usr/libexec/mariadb-prepare-db-dir %n (code=exited, status=0/SUCCESS)……………… 数据库准备工作数据库字符集修改数据库版本信息1234567MariaDB [(none)]&gt; select version();+----------------+| version() |+----------------+| 5.5.56-MariaDB |+----------------+row in set (0.00 sec) 支持哪些字符集12345678910111213141516171819202122232425262728293031323334353637383940414243444546MariaDB [(none)]&gt; show CHARACTER SET; ## 字符集 描述 默认校对规则 最大长度 +----------+-----------------------------+---------------------+--------+| Charset | Description | Default collation | Maxlen |+----------+-----------------------------+---------------------+--------+| big5 | Big5 Traditional Chinese | big5_chinese_ci | 2 || dec8 | DEC West European | dec8_swedish_ci | 1 || cp850 | DOS West European | cp850_general_ci | 1 || hp8 | HP West European | hp8_english_ci | 1 || koi8r | KOI8-R Relcom Russian | koi8r_general_ci | 1 || latin1 | cp1252 West European | latin1_swedish_ci | 1 || latin2 | ISO 8859-2 Central European | latin2_general_ci | 1 || swe7 | 7bit Swedish | swe7_swedish_ci | 1 || ascii | US ASCII | ascii_general_ci | 1 || ujis | EUC-JP Japanese | ujis_japanese_ci | 3 || sjis | Shift-JIS Japanese | sjis_japanese_ci | 2 || hebrew | ISO 8859-8 Hebrew | hebrew_general_ci | 1 || tis620 | TIS620 Thai | tis620_thai_ci | 1 || euckr | EUC-KR Korean | euckr_korean_ci | 2 || koi8u | KOI8-U Ukrainian | koi8u_general_ci | 1 || gb2312 | GB2312 Simplified Chinese | gb2312_chinese_ci | 2 || greek | ISO 8859-7 Greek | greek_general_ci | 1 || cp1250 | Windows Central European | cp1250_general_ci | 1 || gbk | GBK Simplified Chinese | gbk_chinese_ci | 2 || latin5 | ISO 8859-9 Turkish | latin5_turkish_ci | 1 || armscii8 | ARMSCII-8 Armenian | armscii8_general_ci | 1 || utf8 | UTF-8 Unicode | utf8_general_ci | 3 || ucs2 | UCS-2 Unicode | ucs2_general_ci | 2 || cp866 | DOS Russian | cp866_general_ci | 1 || keybcs2 | DOS Kamenicky Czech-Slovak | keybcs2_general_ci | 1 || macce | Mac Central European | macce_general_ci | 1 || macroman | Mac West European | macroman_general_ci | 1 || cp852 | DOS Central European | cp852_general_ci | 1 || latin7 | ISO 8859-13 Baltic | latin7_general_ci | 1 || utf8mb4 | UTF-8 Unicode | utf8mb4_general_ci | 4 || cp1251 | Windows Cyrillic | cp1251_general_ci | 1 || utf16 | UTF-16 Unicode | utf16_general_ci | 4 || cp1256 | Windows Arabic | cp1256_general_ci | 1 || cp1257 | Windows Baltic | cp1257_general_ci | 1 || utf32 | UTF-32 Unicode | utf32_general_ci | 4 || binary | Binary pseudo charset | binary | 1 || geostd8 | GEOSTD8 Georgian | geostd8_general_ci | 1 || cp932 | SJIS for Windows Japanese | cp932_japanese_ci | 2 || eucjpms | UJIS for Windows Japanese | eucjpms_japanese_ci | 3 |+----------+-----------------------------+---------------------+--------+39 rows in set (0.00 sec) 当前数据库默认字符集1234567891011121314MariaDB [(none)]&gt; show variables like &apos;%character_set%&apos;;+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 | ## 客户端来源数据使用的字符集| character_set_connection | utf8 | ## 连接层字符集| character_set_database | latin1 | ## 当前选中数据库的默认字符集| character_set_filesystem | binary || character_set_results | utf8 | ## 查询结果返回字符集| character_set_server | latin1 | ## 默认的内部操作字符集【服务端（数据库）字符】| character_set_system | utf8 | ## 系统元数据(字段名等)字符集【Linux系统字符集】| character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+rows in set (0.00 sec) 修改字符集为utf81234567891011121314151617181920212223242526272829303132333435363738394041[root@zhang ~]# vim /etc/my.cnf [client]default-character-set=utf8[mysqld]character-set-server=utf8datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemd[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid## include all files from the config directory#!includedir /etc/my.cnf.d[root@zhang ~]# systemctl restart mariadb.service # 重启mariadb# 字符集查看 MariaDB [(none)]&gt; show variables like &apos;%character_set%&apos;; +--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec) 数据库建库、授权操作创建数据库12345678910111213141516171819202122MariaDB [(none)]&gt; create database zhangtest01; Query OK, 1 row affected (0.00 sec)MariaDB [(none)]&gt; show create database zhangtest01; +-------------+----------------------------------------------------------------------+| Database | Create Database |+-------------+----------------------------------------------------------------------+| zhangtest01 | CREATE DATABASE `zhangtest01` /*!40100 DEFAULT CHARACTER SET utf8 */ |+-------------+----------------------------------------------------------------------+row in set (0.00 sec)MariaDB [(none)]&gt; show databases; +--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test || zhangtest01 |+--------------------+rows in set (0.00 sec) 授权123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354MariaDB [(none)]&gt; grant all on zhangtest01.* to zhang01@&apos;%&apos; identified by &apos;zhang01&apos;; # 错误授权【大表操作时会失败】 Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; grant all on *.* to zhang06@&apos;%&apos; identified by &apos;zhang06&apos;; # 正确授权 Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; flush privileges; # 刷新权限 Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; show grants for zhang01@&apos;%&apos; ; +--------------------------------------------------------------------------------------------------------+| Grants for zhang01@% |+--------------------------------------------------------------------------------------------------------+| GRANT USAGE ON *.* TO &apos;zhang01&apos;@&apos;%&apos; IDENTIFIED BY PASSWORD &apos;*4D6E977808109CE3DEEDEDA4E3EA17CE0F9CC8C1&apos; || GRANT ALL PRIVILEGES ON `zhangtest01`.* TO &apos;zhang01&apos;@&apos;%&apos; |+--------------------------------------------------------------------------------------------------------+2 rows in set (0.00 sec)MariaDB [(none)]&gt; show grants for zhang06@&apos;%&apos; ; +-----------------------------------------------------------------------------------------------------------------+| Grants for zhang06@% |+-----------------------------------------------------------------------------------------------------------------+| GRANT ALL PRIVILEGES ON *.* TO &apos;zhang06&apos;@&apos;%&apos; IDENTIFIED BY PASSWORD &apos;*45D6EF2FFF78EB89123D0056C9AE2FC6BA6DA0E7&apos; |+-----------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)mysql&gt; show variables like &apos;%connect%&apos;; +--------------------------+-----------------+| Variable_name | Value |+--------------------------+-----------------+| character_set_connection | utf8 || collation_connection | utf8_general_ci || connect_timeout | 10 || extra_max_connections | 1 || init_connect | || max_connect_errors | 10 || max_connections | 151 || max_user_connections | 0 |+--------------------------+-----------------+8 rows in set (0.00 sec)mysql&gt; show status like &apos;%connect%&apos;; # 连接信息 +--------------------------+-------+| Variable_name | Value |+--------------------------+-------+| Aborted_connects | 11 || Connections | 36 || Max_used_connections | 9 || Ssl_client_connects | 0 || Ssl_connect_renegotiates | 0 || Ssl_finished_connects | 0 || Threads_connected | 5 |+--------------------------+-------+7 rows in set (0.00 sec) 数据库建表、插入数据建表语句123456CREATE TABLE `zhang_test` ( `id` int(10) NOT NULL, `name` varchar(50) NOT NULL, `address` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 插入语句示例1INSERT INTO `zhangtest01`.`zhang_test` (`id`, `name`, `address`) VALUES (&apos;0&apos;, &apos;test0&apos;, &apos;中国XX省XX市0&apos;); 对应的批量SQL语句脚本1234567[root@zhang database]# vim batch_insert.sh #!/bin/shfor i in `echo &#123;1..2000000&#125;`;do echo &quot;INSERT INTO zhangtest01.zhang_test (id, name, address) VALUES (&apos;$&#123;i&#125;&apos;, &apos;test$&#123;i&#125;&apos;, &apos;中国XX省XX市$&#123;i&#125;&apos;); &quot;done 执行脚本将插入数据放到一个文本中，之后导入数据库即可 percona-toolkit安装【可以在另外一台机器】1234567# 官网下载[root@zhang tools]# wget https://www.percona.com/downloads/percona-toolkit/3.0.10/binary/redhat/7/x86_64/percona-toolkit-3.0.10-1.el7.x86_64.rpm ………………[root@zhang tools]# yum install -y percona-toolkit-3.0.10-1.el7.x86_64.rpm ………………[root@docker01 tools]# pt-online-schema-change --help # 帮助文档……………… 大表DDL操作添加表字段【并保存原始表】1234567891011121314151617181920212223242526[root@docker01 tools]# pt-online-schema-change -h172.16.1.14 -uzhang06 -pzhang06 --nocheck-replication-filters --nodrop-old-table --charset=UTF8 --max-load=&quot;Threads_running=1000&quot; --alter &quot;add uuid varchar(100) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;UUID&apos; after id&quot; D=zhangtest01,t=zhang_test --execute # 语句No slaves found. See --recursion-method if host zhang has slaves.Not checking slave lag because no slaves were found and --check-slave-lag was not specified.Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Altering `zhangtest01`.`zhang_test`...Creating new table...Created new table zhangtest01._zhang_test_new OK.Altering new table...Altered `zhangtest01`.`_zhang_test_new` OK.2018-05-23T13:02:13 Creating triggers...2018-05-23T13:02:13 Created triggers OK.2018-05-23T13:02:13 Copying approximately 2006480 rows...Copying `zhangtest01`.`zhang_test`: 74% 00:10 remain2018-05-23T13:02:21 Copied rows OK.2018-05-23T13:02:21 Swapping tables...2018-05-23T13:02:21 Swapped original and new tables OK.Not dropping old table because --no-drop-old-table was specified.2018-05-23T13:02:21 Dropping triggers...2018-05-23T13:02:21 Dropped triggers OK.Successfully altered `zhangtest01`.`zhang_test`. 修改后的表结构1234567CREATE TABLE `zhang_test` ( `id` int(10) NOT NULL, `uuid` varchar(100) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;UUID&apos;, `name` varchar(50) NOT NULL, `address` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 命令参数说明1234567891011121314151617181920--nocheck-replication-filters不检查复制过滤器【有主从复制也照样执行】--[no]drop-old-table 操作完后是否删除原始表【默认TRUE】--critical-load=&quot;Threads_running=1000&quot; # 终止拷贝【不优先使用】 类似于--max-load，不同的是检测到超高负载时会直接中断OSC进程而不是暂停--max-load=&quot;Threads_running=1000&quot; # 暂停拷贝【优先使用】 默认如果检测到服务器负载过重会暂停操作 检查每个块后显示全局状态，如果负载太高暂停（默认Threads_running＝25）D=zhangtest01 操作的哪个数据库t=zhang_test 操作哪张表--execute 执行操作 修改表字段123456789101112131415161718192021222324252627[root@docker01 ~]# pt-online-schema-change -h172.16.1.14 -uzhang06 -pzhang06 --nocheck-replication-filters --charset=UTF8 --max-load=&quot;Threads_running=1000&quot; --alter &quot;MODIFY uuid varchar(80)&quot; D=zhangtest01,t=zhang_test --execute [root@docker01 ~]# pt-online-schema-change -h172.16.1.14 -uzhang06 -pzhang06 --nocheck-replication-filters --charset=UTF8 --max-load=&quot;Threads_running=1000&quot; --alter &quot;MODIFY uuid int(11)&quot; D=zhangtest01,t=zhang_test --execute No slaves found. See --recursion-method if host zhang has slaves.Not checking slave lag because no slaves were found and --check-slave-lag was not specified.Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Altering `zhangtest01`.`zhang_test`...Creating new table...Created new table zhangtest01._zhang_test_new OK.Altering new table...Altered `zhangtest01`.`_zhang_test_new` OK.2018-05-23T22:11:15 Creating triggers...2018-05-23T22:11:15 Created triggers OK.2018-05-23T22:11:15 Copying approximately 2005915 rows...2018-05-23T22:11:22 Copied rows OK.2018-05-23T22:11:22 Swapping tables...2018-05-23T22:11:22 Swapped original and new tables OK.2018-05-23T22:11:22 Dropping old table...2018-05-23T22:11:22 Dropped old table `zhangtest01`.`__zhang_test_old` OK.2018-05-23T22:11:22 Dropping triggers...2018-05-23T22:11:22 Dropped triggers OK.Successfully altered `zhangtest01`.`zhang_test`. 删除表字段1234567891011121314151617181920212223242526[root@docker01 ~]# pt-online-schema-change -h172.16.1.14 -uzhang06 -pzhang06 --nocheck-replication-filters --charset=UTF8 --max-load=&quot;Threads_running=1000&quot; --alter &quot;DROP uuid&quot; D=zhangtest01,t=zhang_test --execute No slaves found. See --recursion-method if host zhang has slaves.Not checking slave lag because no slaves were found and --check-slave-lag was not specified.Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Altering `zhangtest01`.`zhang_test`...Creating new table...Created new table zhangtest01._zhang_test_new OK.Altering new table...Altered `zhangtest01`.`_zhang_test_new` OK.2018-05-23T22:04:38 Creating triggers...2018-05-23T22:04:38 Created triggers OK.2018-05-23T22:04:38 Copying approximately 1996965 rows...2018-05-23T22:04:47 Copied rows OK.2018-05-23T22:04:47 Swapping tables...2018-05-23T22:04:47 Swapped original and new tables OK.2018-05-23T22:04:47 Dropping old table...2018-05-23T22:04:47 Dropped old table `zhangtest01`.`__zhang_test_old` OK.2018-05-23T22:04:47 Dropping triggers...2018-05-23T22:04:47 Dropped triggers OK.Successfully altered `zhangtest01`.`zhang_test`. 添加表索引1234567891011121314151617181920212223242526[root@docker01 ~]# pt-online-schema-change -h172.16.1.14 -uzhang06 -pzhang06 --nocheck-replication-filters --charset=UTF8 --max-load=&quot;Threads_running=1000&quot; --alter &quot;ADD INDEX index_name(name)&quot; D=zhangtest01,t=zhang_test --execute # ADD INDEX indexName(columnName) No slaves found. See --recursion-method if host zhang has slaves.Not checking slave lag because no slaves were found and --check-slave-lag was not specified.Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Altering `zhangtest01`.`zhang_test`...Creating new table...Created new table zhangtest01._zhang_test_new OK.Altering new table...Altered `zhangtest01`.`_zhang_test_new` OK.2018-05-23T22:16:59 Creating triggers...2018-05-23T22:16:59 Created triggers OK.2018-05-23T22:16:59 Copying approximately 2013664 rows...2018-05-23T22:17:12 Copied rows OK.2018-05-23T22:17:12 Swapping tables...2018-05-23T22:17:12 Swapped original and new tables OK.2018-05-23T22:17:12 Dropping old table...2018-05-23T22:17:12 Dropped old table `zhangtest01`.`__zhang_test_old` OK.2018-05-23T22:17:12 Dropping triggers...2018-05-23T22:17:12 Dropped triggers OK.Successfully altered `zhangtest01`.`zhang_test`. 修改后的表结构12345678CREATE TABLE `zhang_test` ( `id` int(10) NOT NULL, `uuid` int(11) DEFAULT NULL, `name` varchar(50) NOT NULL, `address` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `index_name` (`name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 删除表索引1234567891011121314151617181920212223242526[root@docker01 ~]# pt-online-schema-change -h172.16.1.14 -uzhang06 -pzhang06 --nocheck-replication-filters --charset=UTF8 --max-load=&quot;Threads_running=1000&quot; --alter &quot;DROP INDEX index_name&quot; D=zhangtest01,t=zhang_test --execute # DROP INDEX indexName No slaves found. See --recursion-method if host zhang has slaves.Not checking slave lag because no slaves were found and --check-slave-lag was not specified.Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Altering `zhangtest01`.`zhang_test`...Creating new table...Created new table zhangtest01._zhang_test_new OK.Altering new table...Altered `zhangtest01`.`_zhang_test_new` OK.2018-05-23T22:19:31 Creating triggers...2018-05-23T22:19:31 Created triggers OK.2018-05-23T22:19:31 Copying approximately 2005445 rows...2018-05-23T22:19:38 Copied rows OK.2018-05-23T22:19:38 Swapping tables...2018-05-23T22:19:38 Swapped original and new tables OK.2018-05-23T22:19:38 Dropping old table...2018-05-23T22:19:38 Dropped old table `zhangtest01`.`__zhang_test_old` OK.2018-05-23T22:19:38 Dropping triggers...2018-05-23T22:19:38 Dropped triggers OK.Successfully altered `zhangtest01`.`zhang_test`. 添加唯一索引12345678910111213141516171819202122232425262728##### 注意：确保字段中数据的唯一性，不然会丢失数据[root@docker01 ~]# pt-online-schema-change -h172.16.1.14 -uzhang06 -pzhang06 --nocheck-replication-filters --nocheck-unique-key-change --charset=UTF8 --max-load=&quot;Threads_running=1000&quot; --alter &quot;ADD UNIQUE uniq_index_name(name)&quot; D=zhangtest01,t=zhang_test --execute # ADD UNIQUE uniqueName(columnName) No slaves found. See --recursion-method if host zhang has slaves.Not checking slave lag because no slaves were found and --check-slave-lag was not specified.Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Altering `zhangtest01`.`zhang_test`...Creating new table...Created new table zhangtest01._zhang_test_new OK.Altering new table...Altered `zhangtest01`.`_zhang_test_new` OK.2018-05-23T22:24:31 Creating triggers...2018-05-23T22:24:31 Created triggers OK.2018-05-23T22:24:31 Copying approximately 2005445 rows...Copying `zhangtest01`.`zhang_test`: 69% 00:13 remain2018-05-23T22:24:44 Copied rows OK.2018-05-23T22:24:44 Swapping tables...2018-05-23T22:24:44 Swapped original and new tables OK.2018-05-23T22:24:44 Dropping old table...2018-05-23T22:24:44 Dropped old table `zhangtest01`.`__zhang_test_old` OK.2018-05-23T22:24:44 Dropping triggers...2018-05-23T22:24:44 Dropped triggers OK.Successfully altered `zhangtest01`.`zhang_test`. 修改后的表结构12345678CREATE TABLE `zhang_test` ( `id` int(10) NOT NULL, `uuid` int(11) DEFAULT NULL, `name` varchar(50) NOT NULL, `address` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `uniq_index_name` (`name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 命令参数说明12--nocheck-unique-key-change 添加该参数选项，才可以添加唯一索引 删除唯一索引123456789101112131415161718192021222324252627##### 与删除普通索引一样[root@docker01 ~]# pt-online-schema-change -h172.16.1.14 -uzhang06 -pzhang06 --nocheck-replication-filters --charset=UTF8 --max-load=&quot;Threads_running=1000&quot; --alter &quot;DROP INDEX uniq_index_name&quot; D=zhangtest01,t=zhang_test --execute # DROP UNIQUE uniqueNameNo slaves found. See --recursion-method if host zhang has slaves.Not checking slave lag because no slaves were found and --check-slave-lag was not specified.Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Altering `zhangtest01`.`zhang_test`...Creating new table...Created new table zhangtest01._zhang_test_new OK.Altering new table...Altered `zhangtest01`.`_zhang_test_new` OK.2018-05-23T22:35:12 Creating triggers...2018-05-23T22:35:12 Created triggers OK.2018-05-23T22:35:12 Copying approximately 2005445 rows...2018-05-23T22:35:19 Copied rows OK.2018-05-23T22:35:19 Swapping tables...2018-05-23T22:35:19 Swapped original and new tables OK.2018-05-23T22:35:19 Dropping old table...2018-05-23T22:35:19 Dropped old table `zhangtest01`.`__zhang_test_old` OK.2018-05-23T22:35:19 Dropping triggers...2018-05-23T22:35:19 Dropped triggers OK.Successfully altered `zhangtest01`.`zhang_test`. 删除表主键重要说明1234567对主键修改的步骤： 1、保证有一个唯一索引【如果没有那么就添加一个唯一索引】 2、删除原主键 3、添加新主键 4、删除之前的唯一索引【可选】原因如下：The new table `zhangtest01`.`_zhang_test_new` does not have a PRIMARY KEY or a unique index which is required for the DELETE trigger. 1234567891011121314151617181920212223242526[root@docker01 ~]# pt-online-schema-change -h172.16.1.14 -uzhang06 -pzhang06 --nocheck-replication-filters --nocheck-alter --charset=UTF8 --max-load=&quot;Threads_running=1000&quot; --alter &quot;DROP PRIMARY KEY&quot; D=zhangtest01,t=zhang_test --execute No slaves found. See --recursion-method if host zhang has slaves.Not checking slave lag because no slaves were found and --check-slave-lag was not specified.Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Altering `zhangtest01`.`zhang_test`...Creating new table...Created new table zhangtest01._zhang_test_new OK.Altering new table...Altered `zhangtest01`.`_zhang_test_new` OK.2018-05-23T22:45:28 Creating triggers...2018-05-23T22:45:28 Created triggers OK.2018-05-23T22:45:28 Copying approximately 2005445 rows...2018-05-23T22:45:42 Copied rows OK.2018-05-23T22:45:42 Swapping tables...2018-05-23T22:45:42 Swapped original and new tables OK.2018-05-23T22:45:42 Dropping old table...2018-05-23T22:45:42 Dropped old table `zhangtest01`.`__zhang_test_old` OK.2018-05-23T22:45:42 Dropping triggers...2018-05-23T22:45:42 Dropped triggers OK.Successfully altered `zhangtest01`.`zhang_test`. 修改后的表结构【没有主键了，但有唯一索引】1234567CREATE TABLE `zhang_test` ( `id` int(10) NOT NULL, `uuid` int(11) DEFAULT NULL, `name` varchar(50) NOT NULL, `address` varchar(255) DEFAULT NULL, UNIQUE KEY `uniq_index_name` (`name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 命令参数说明123--[no]check-alter 解析-ALTER指定并尝试警告可能的意外行为（默认为“是”） 如果没有改选项，修改会失败 添加表主键1234567891011121314151617181920212223242526[root@docker01 ~]# pt-online-schema-change -h172.16.1.14 -uzhang06 -pzhang06 --nocheck-replication-filters --nocheck-alter --charset=UTF8 --max-load=&quot;Threads_running=1000&quot; --alter &quot;ADD PRIMARY KEY (id)&quot; D=zhangtest01,t=zhang_test --execute No slaves found. See --recursion-method if host zhang has slaves.Not checking slave lag because no slaves were found and --check-slave-lag was not specified.Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Altering `zhangtest01`.`zhang_test`...Creating new table...Created new table zhangtest01._zhang_test_new OK.Altering new table...Altered `zhangtest01`.`_zhang_test_new` OK.2018-05-23T22:47:23 Creating triggers...2018-05-23T22:47:23 Created triggers OK.2018-05-23T22:47:23 Copying approximately 2227360 rows...2018-05-23T22:47:36 Copied rows OK.2018-05-23T22:47:36 Swapping tables...2018-05-23T22:47:36 Swapped original and new tables OK.2018-05-23T22:47:36 Dropping old table...2018-05-23T22:47:36 Dropped old table `zhangtest01`.`__zhang_test_old` OK.2018-05-23T22:47:36 Dropping triggers...2018-05-23T22:47:36 Dropped triggers OK.Successfully altered `zhangtest01`.`zhang_test`. 修改后的表结构12345678CREATE TABLE `zhang_test` ( `id` int(10) NOT NULL, `uuid` int(11) DEFAULT NULL, `name` varchar(50) NOT NULL, `address` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `uniq_index_name` (`name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 多个操作合并1234567891011121314151617181920212223242526[root@docker01 ~]# pt-online-schema-change -h172.16.1.14 -uzhang06 -pzhang06 --nocheck-replication-filters --charset=UTF8 --max-load=&quot;Threads_running=1000&quot; --alter &quot;add last_name varchar(20) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;姓名&apos; after name, ADD INDEX index_address(address), add birthday date COMMENT &apos;生日&apos;&quot; D=zhangtest01,t=zhang_test --execute No slaves found. See --recursion-method if host zhang has slaves.Not checking slave lag because no slaves were found and --check-slave-lag was not specified.Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Altering `zhangtest01`.`zhang_test`...Creating new table...Created new table zhangtest01._zhang_test_new OK.Altering new table...Altered `zhangtest01`.`_zhang_test_new` OK.2018-05-23T22:55:17 Creating triggers...2018-05-23T22:55:17 Created triggers OK.2018-05-23T22:55:17 Copying approximately 1990757 rows...2018-05-23T22:55:39 Copied rows OK.2018-05-23T22:55:39 Swapping tables...2018-05-23T22:55:39 Swapped original and new tables OK.2018-05-23T22:55:39 Dropping old table...2018-05-23T22:55:39 Dropped old table `zhangtest01`.`__zhang_test_old` OK.2018-05-23T22:55:39 Dropping triggers...2018-05-23T22:55:39 Dropped triggers OK.Successfully altered `zhangtest01`.`zhang_test`. 修改前的表结构12345678CREATE TABLE `zhang_test` ( `id` int(10) NOT NULL, `uuid` int(11) DEFAULT NULL, `name` varchar(50) NOT NULL, `address` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `uniq_index_name` (`name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 修改后的表结构1234567891011CREATE TABLE `zhang_test` ( `id` int(10) NOT NULL, `uuid` int(11) DEFAULT NULL, `name` varchar(50) NOT NULL, `last_name` varchar(20) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;姓名&apos;, `address` varchar(255) DEFAULT NULL, `birthday` date DEFAULT NULL COMMENT &apos;生日&apos;, PRIMARY KEY (`id`), UNIQUE KEY `uniq_index_name` (`name`), KEY `index_address` (`address`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 附录：1、不停机不停服务，MYSQL可以这样修改亿级数据表结构 2、pt-online-schema-change解读 3、Mysql 查看连接数,状态 最大并发数(赞)]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>percona</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[-bash：fork：Cannot allocate memory 问题的处理]]></title>
    <url>%2F2019%2F08%2F30%2Flinux-thread%2F</url>
    <content type="text"><![CDATA[文章来源：fork:cannot allocate memory问题的处理 文章参考：pid max导致fork: Cannot allocate memory 的分析及解决办法 今天遇到服务器无法SSH，VNC操作命令提示fork:cannot allocate memory free查看内存还有（注意，命令可能要多敲几次才会出来） 查看最大进程数 sysctl kernel.pid_max ps -eLf | wc -l查看进程数 确认是进程数满了 修改最大进程数后系统恢复 1echo 1000000 &gt; /proc/sys/kernel/pid_max 永久生效 12echo &quot;kernel.pid_max=1000000 &quot; &gt;&gt; /etc/sysctl.confsysctl -p]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[“反向代理层”绝不能替代“DNS轮询”！]]></title>
    <url>%2F2019%2F08%2F12%2Fproxy_dns01%2F</url>
    <content type="text"><![CDATA[文章转载自微信公众号：「架构师之路」，作者： 58沈剑 有朋友问我，DNS轮询是不是过时的技术了？有了反向代理层（Nginx、LVS、F5等），是不是就不需要DNS轮询了？ 然而，反向代理层绝不能替代 DNS 轮询！ 反向代理层有什么用？架构实现时要注意什么？(1) 作为服务端统一入口，屏蔽后端WEB集群细节，代表整个WEB集群； PS：这就是为啥它叫反向代理。 (2) 保证WEB集群的扩展性，Nginx后端可随时加WEB实例； (3) 实施负载均衡，反向代理层会将请求均匀分发给后端WEB集群的每一个实例； (4) 保证WEB集群的高可用，任何一个WEB实例挂了，服务都不受影响； (5) 注意自身高可用，防止一台Nginx挂了，服务端统一入口受影响； 反向代理层还存在啥问题？反向代理层自身的扩展性问题并没有得到很好的解决，例如当Nginx成为系统瓶颈的时候，无法扩容。 DNS轮询如何解决反向代理层的扩展性问题？通过在DNS-server上对一个域名设置多个IP解析，能够增加入口Nginx实例个数，起到水平扩容的作用，解决反向代理层的扩展性问题。 因此，反向代理和DNS轮询并不是互斥的技术，however，这里详细展开讲一下接入层的架构渐进历程。 裸奔时代（1）单机架构 裸奔时代的架构图如上： (1) 浏览器通过DNS-server，域名解析到ip； (2) 浏览器通过ip访问web-server； 缺点： (1) 非高可用，web-server挂了整个系统就挂了； (2) 扩展性差，当吞吐量达到web-server上限时，无法扩容； PS：单机不涉及负载均衡问题。 简易扩容方案（2）DNS轮询假设tomcat的吞吐量是1000次每秒，当系统总吞吐量达到3000时，如何扩容是首先要解决的问题，DNS轮询是一个很容易想到的方案。 PS：DNS轮询解决扩展性问题。 此时的架构图如上： (1) 多部署几份web-server，1个tomcat抗1000，部署3个tomcat就能抗3000； (2) 在DNS-server层面，域名每次解析到不同的ip； 优点： (1) 零成本：在DNS-server上多配几个ip即可，功能也不收费； (2) 部署简单：多部署几个web-server即可，原系统架构不需要做任何改造； (3) 负载均衡：变成了多机，负载也是均衡的； 缺点： (1) 非高可用：DNS-server只负责域名解析ip，这个ip对应的服务是否可用，DNS-server是不保证的，假设有一个web-server挂了，部分服务会受到影响； (2) 扩容非实时：DNS解析有一个生效周期； (3) 暴露了太多的外网 ip； 简易扩容方案（3）反向代理Nginxtomcat的性能较差，但Nginx作为反向代理的性能就强很多，假设线上跑到1w，就比tomcat高了10倍，可以利用这个特性来做扩容。 此时的架构图如上： (1) 站点层与浏览器层之间加入了一个反向代理层，利用高性能的Nginx来做反向代理； (2) Nginx将http请求分发给后端多个web-server； 优点： (1) DNS-server不需要动； (2) 负载均衡：通过Nginx来保证； (3) 只暴露一个外网 ip，Nginx-&gt;tomcat之间使用内网访问； (4) 扩容实时：Nginx内部可控，随时增加web-server随时实时扩容； (5) 能够保证站点层的可用性：任何一台tomcat挂了，Nginx可以将流量迁移到其他tomcat； PS：反向代理，能够更实时，更方便的扩容了。 缺点： (1) 时延增加 + 架构更复杂了：中间多加了一个反向代理层； (2) 反向代理层成了单点，非高可用：tomcat挂了不影响服务，Nginx挂了怎么办？ 高可用方案（4）keepalived为了解决高可用的问题，keepalived出场了。 (1) 做两台Nginx组成一个集群，分别部署上keepalived，设置成相同的虚IP，保证Nginx的高可用； (2) 当一台Nginx挂了，keepalived能够探测到，并将流量自动迁移到另一台Nginx上，整个过程对调用方透明； 优点： (1) 解决了高可用的问题； PS：反向代理的高可用也解决了。 缺点： (1) 资源利用率只有50%； (2) Nginx仍然是接入单点，如果接入吞吐量超过的Nginx的性能上限怎么办，例如qps达到了50000咧？ scale up扩容方案（5）lvs/f5Nginx是应用软件，性能比tomcat好，但总有个上限，超出了上限，还是扛不住。 lvs就不一样了，它实施在操作系统层面；f5的性能又更好了，它实施在硬件层面；它们性能比Nginx好很多，例如每秒可以抗10w，这样可以利用他们来扩容，常见的架构图如下： (1) 如果通过Nginx可以扩展多个tomcat一样，可以通过lvs来扩展多个Nginx； (2) 通过keepalived+VIP的方案可以保证可用性； 99.9999%的公司到这一步基本就结束了，解决了接入层高可用、扩展性、负载均衡的问题。PS：上游再加一层扩充性能。 完美了嘛，还有什么潜在问题？ 好吧，不管是使用lvs还是f5，这些都是scale up的方案，根本上，lvs/f5还是会有性能上限，假设每秒能处理10w的请求，一天也只能处理80亿的请求（10w秒吞吐量*8w秒），那万一系统的日PV超过80亿怎么办呢？ scale out扩容方案（6）DNS轮询如之前文章所述，水平扩展，才是解决性能问题的根本方案，能够通过加机器扩充性能的方案才具备最好的扩展性。 facebook，google，baidu的PV是不是超过80亿呢，它们的域名只对应一个ip么，终点又是起点，还是得通过DNS轮询来进行扩容。PS：DNS轮询解决扩展性问题。 (1) 通过DNS轮询来线性扩展入口lvs层的性能； (2) 通过keepalived来保证高可用； (3) 通过lvs来扩展多个Nginx； (4) 通过Nginx来做负载均衡，业务七层路由； 总结稍微做一个简要的总结： (1) 接入层架构要考虑的问题域为：高可用、扩展性、反向代理、负载均衡； (2) Nginx、keepalived、lvs、f5可以很好的解决高可用、扩展性、反向代理、负载均衡的问题； (3) 水平扩展 scale out是解决扩展性问题的根本方案，DNS轮询是不能完全被Nginx/lvs/f5所替代的；]]></content>
      <categories>
        <category>DNS</category>
        <category>proxy</category>
      </categories>
      <tags>
        <tag>DNS</tag>
        <tag>proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[负载均衡，必须要知道的 5 件事]]></title>
    <url>%2F2019%2F08%2F12%2Fslb01%2F</url>
    <content type="text"><![CDATA[文章转载自微信公众号：「架构师之路」，作者： 58沈剑 什么是负载均衡？负载均衡（Load Balance）是分布式系统架构设计中必须考虑的因素之一，它通常是指，将请求/数据均匀分摊到多个操作单元上执行，负载均衡的关键在于均匀。 常见的负载均衡方案有哪些？ 常见互联网分布式架构如上，分为： 客户端层 反向代理层 站点层 服务层 数据层 可以看到，每一个下游都有多个上游调用，只需要做到，每一个上游都均匀访问每一个下游，就能实现整体的均匀分摊。 第一层：客户端层到反向代理层 客户端层到反向代理层的负载均衡，是通过“DNS轮询”实现的。 DNS-server 对于一个域名配置了多个解析 ip，每次 DNS 解析请求来访问 DNS-server，会轮询返回这些 ip，保证每个 ip 的解析概率是相同的。这些 ip 就是 nginx 的外网 ip，以做到每台 nginx 的请求分配也是均衡的。 第二层：反向代理层到站点层 反向代理层到站点层的负载均衡，是通过“nginx”实现的。 PS：nginx 是反向代理的泛指。 修改nginx.conf，可以实现多种均衡策略： (1) 请求轮询：和DNS轮询类似，请求依次路由到各个 web-server； (2) 最少连接路由：哪个web-server的连接少，路由到哪个 web-server； (3) ip 哈希：按照访问用户的ip哈希值来路由 web-server，只要用户的 ip 分布是均匀的，请求理论上也是均匀的，ip 哈希均衡方法可以做到，同一个用户的请求固定落到同一台 web-server 上，此策略适合有状态服务，例如 session； PS：站点层可以存储 session，但强烈不建议这么做，站点层无状态是分布式架构设计的基本原则之一，session最好放到数据层存储。 (4) … 第三层：站点层到服务层 站点层到服务层的负载均衡，是通过“服务连接池”实现的。 上游连接池会建立与下游服务多个连接，每次请求会“随机”选取连接来访问下游服务。除了负载均衡，服务连接池还能够实现故障转移、超时处理、限流限速、ID串行化等诸多功能。 第四层：访问数据层在数据量很大的情况下，由于数据层（db/cache）涉及数据的水平切分，所以数据层的负载均衡更为复杂一些，它分为“数据的均衡”，与“请求的均衡”。 数据的均衡是指：水平切分后的每个服务（db/cache），数据量是均匀的。 请求的均衡是指：水平切分后的每个服务（db/cache），请求量是均匀的。 业内常见的水平切分方式有这么几种： 按照range水平切分 每一个数据服务，存储一定范围的数据： user0 服务：存储 uid 范围 1-1kw user1 服务：存储 uid 范围 1kw-2kw 这个方案的好处是： 规则简单，service只需判断一下uid范围就能路由到对应的存储服务 数据均衡性较好 比较容易扩展，可以随时加一个uid[2kw,3kw]的数据服务 不足是： 请求的负载不一定均衡，一般来说，新注册的用户会比老用户更活跃，大range的服务请求压力会更大 按照 id 哈希水平切分 每一个数据服务，存储某个key值hash后的部分数据： user0服务：存储偶数uid数据 user1服务：存储奇数uid数据 这个方案的好处是： 规则简单，service只需对uid进行hash能路由到对应的存储服务 数据均衡性较好 请求均匀性较好 不足是： 不容易扩展，扩展一个数据服务，hash方法改变时候，可能需要进行数据迁移 总结负载均衡（Load Balance）是分布式系统架构设计中必须考虑的因素之一，它通常是指，将请求/数据均匀分摊到多个操作单元上执行，其的关键在于均匀： 反向代理层的负载均衡，是通过“DNS轮询”实现的 站点层的负载均衡，是通过“nginx”实现的 服务层的负载均衡，是通过“服务连接池”实现的 数据层的负载均衡，要考虑“数据的均衡”与“请求的均衡”两个点，常见的方式有“按照范围水平切分”与“hash水平切分”]]></content>
      <categories>
        <category>SLB</category>
      </categories>
      <tags>
        <tag>SLB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Swarm 常用操作]]></title>
    <url>%2F2019%2F08%2F08%2Fdocker-swarm01%2F</url>
    <content type="text"><![CDATA[说明本文档针对docker swarm操作。 针对的系统是以一个本地的测试系统为例。其中机器信息如下，172.16.1.13作为docker swarm的管理机。 本地测试的机器列表信息： 主机名 模拟的外网 内网IP 部署模块 mini01 10.0.0.11 172.16.1.11 tomcat、hadoop-datanode、hbase-regionserver 【swarm 管理】 mini02 10.0.0.12 172.16.1.12 tomcat、hadoop-datanode、hbase-regionserver 【swarm 管理】 mini03 10.0.0.13 172.16.1.13 visualizer、spark、zookeeper、hadoop-namnode、hbase-master【swarm 管理机】 docker swarm初始化根据规划在172.16.1.13这台机器上操作： 12345678910[root@mini03 ~]# docker swarm init # 针对机器只有一个IP的情况 Error response from daemon: could not choose an IP address to advertise since this system has multiple addresses on different interfaces (172.16.1.13 on eth0 and 10.0.0.13 on eth1) - specify one with --advertise-addr[root@mini03 ~]# docker swarm init --advertise-addr 172.16.1.13 # 针对机器有多个IP的情况，需要指定一个IP，一般都是指定内网IPSwarm initialized: current node (yo5f7qb28gf6g38ve4xhcis17) is now a manager.To add a worker to this swarm, run the following command: # 在其他机器上执行，这样可以加入该swarm管理 docker swarm join --token SWMTKN-1-4929ovxh6agko49u0yokrzustjf6yzt30iv1zvwqn8d3pndm92-0kuha3sa80u2u27yca6kzdbnb 172.16.1.13:2377To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions. 得到加入到该swarm的命令 1234[root@mini03 ~]# docker swarm join-token worker To add a worker to this swarm, run the following command: # 在其他机器上执行，这样可以加入该swarm管理 docker swarm join --token SWMTKN-1-4929ovxh6agko49u0yokrzustjf6yzt30iv1zvwqn8d3pndm92-0kuha3sa80u2u27yca6kzdbnb 172.16.1.13:2377 初始化网络初始化一个swarm网络，让系统组件使用这个指定的网络。 1234567891011121314151617181920212223242526272829303132333435363738[root@mini03 ~]# docker network create -d overlay --attachable zhang vu07em5fvpuojih6wgckdkdzj[root@mini03 docker-swarm]# docker network ls # 查看网络NETWORK ID NAME DRIVER SCOPEfa8a244c6bd5 bridge bridge local51c95dea1e5c docker_gwbridge bridge local7a7e31f4bce8 host host local5hgg372xwxbl ingress overlay swarmlmt3pjswf7l0 zhang overlay swarm5ea08e9a282f none null local[root@mini03 ~]# docker network inspect zhang # 查看网络信息 [ &#123; &quot;Name&quot;: &quot;zhang&quot;, &quot;Id&quot;: &quot;xiykborz8hn2td40ykhi20dck&quot;, &quot;Created&quot;: &quot;0001-01-01T00:00:00Z&quot;, &quot;Scope&quot;: &quot;swarm&quot;, &quot;Driver&quot;: &quot;overlay&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: true, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: null, &quot;Options&quot;: &#123; &quot;com.docker.network.driver.overlay.vxlanid_list&quot;: &quot;4097&quot; &#125;, &quot;Labels&quot;: null &#125;] 删除网络【慎用】 删除docker中的zhang网络 123456789[root@mini03 docker-swarm]# docker network rm zhang zhang[root@mini03 docker-swarm]# docker network lsNETWORK ID NAME DRIVER SCOPEfa8a244c6bd5 bridge bridge local51c95dea1e5c docker_gwbridge bridge local7a7e31f4bce8 host host local5hgg372xwxbl ingress overlay swarm5ea08e9a282f none null local 加入或退出swarm管理在mini01、mini02上执行 如下命令。 1docker swarm join --token SWMTKN-1-4929ovxh6agko49u0yokrzustjf6yzt30iv1zvwqn8d3pndm92-0kuha3sa80u2u27yca6kzdbnb 172.16.1.13:2377 当前swarm有哪些节点12345[root@mini03 ~]# docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION2pfwllgxpajx5aitlvcih9vsq mini01 Ready Active 17.09.0-cezho14u85itt5l2i6cpg8fcd6t mini02 Ready Active 17.09.0-ceyo5f7qb28gf6g38ve4xhcis17 * mini03 Ready Active Leader 17.09.0-ce 退出当前的swarm节点123456789101112# 在swarm管理机mini03上的操作# 其中 2pfwllgxpajx5aitlvcih9vsq 是mini01在swarm机器上的ID，根据docker node ls 获取[root@mini03 ~]# docker node rm --force 2pfwllgxpajx5aitlvcih9vsq # 如果mini01上的docker没有停止服务，那么就需要使用 --force 选项2pfwllgxpajx5aitlvcih9vsq[root@mini03 ~]# docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONzho14u85itt5l2i6cpg8fcd6t mini02 Ready Active 17.09.0-ceyo5f7qb28gf6g38ve4xhcis17 * mini03 Ready Active Leader 17.09.0-ce########################################### 需要在mini01上执行的命令，这样mini01才能彻底退出swarm管理[root@mini01 ~]# docker swarm leaveNode left the swarm. swarm管理机退出swarm首先需要删除所有节点，然后强制退出swarm即可 1234567[root@mini03 ~]# docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONyo5f7qb28gf6g38ve4xhcis17 * mini03 Ready Active Leader 17.09.0-ce[root@mini03 ~]# docker swarm leave --force # swarm管理机退出swarm，需要 --force 参数Node left the swarm. [root@mini03 ~]# docker node lsError response from daemon: This node is not a swarm manager. Use &quot;docker swarm init&quot; or &quot;docker swarm join&quot; to connect this node to swarm and try again. 当前swarm有哪些服务1234567891011[root@mini03 ~]# docker service ls # 只是示例，不是实际数据ID NAME MODE REPLICAS IMAGE PORTSlq7zkkal6ujt hadoop_datanode global 2/2 bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8 ph2fu37k886b hadoop_namenode replicated 1/1 bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8 *:50070-&gt;50070/tcpca47u5i2ubes hbase-master replicated 1/1 bde2020/hbase-master:1.0.0-hbase1.2.6 *:16010-&gt;16010/tcpmkks4oa2ppcn hbase-regionserver-1 replicated 1/1 bde2020/hbase-regionserver:1.0.0-hbase1.2.6 j4mhizg4j67p hbase-regionserver-2 replicated 1/1 bde2020/hbase-regionserver:1.0.0-hbase1.2.6 yndrkc2bcpra hbase_zoo1 replicated 1/1 zookeeper:3.4.10 *:2181-&gt;2181/tcpr5ycrvo0zout spark_spark replicated 1/1 zhang/spark:latest *:4040-&gt;4040/tcp,*:7777-&gt;7777/tcp,*:8081-&gt;8081/tcp,*:18080-&gt;8080/tcpf2v091nz24rg tomcat_tomcat global 2/2 zhang/tomcat:latest *:6543-&gt;6543/tcp,*:9999-&gt;9999/tcp,*:18081-&gt;8081/tcpclfpryaerq2l visualizer replicated 1/1 dockersamples/visualizer:latest *:8080-&gt;8080/tcp swarm标签管理标签添加根据最开始的主机和组件部署规划，标签规划如下：在swarm管理机mini03上执行 123456789101112131415# 给mini01机器的标签docker node update --label-add tomcat=true mini01docker node update --label-add datanode=true mini01docker node update --label-add hbase-regionserver-1=true mini01# 给mini02机器的标签docker node update --label-add tomcat=true mini02docker node update --label-add datanode=true mini02docker node update --label-add hbase-regionserver-2=true mini02# 给mini03机器的标签docker node update --label-add spark=true mini03docker node update --label-add zookeeper=true mini03docker node update --label-add namenode=true mini03docker node update --label-add hbase-master=true mini03 删除标签在swarm管理机mini03上执行，示例如下： 1docker node update --label-rm zookeeper mini03 查看swarm当前的标签在swarm管理机mini03上执行： 1234[root@mini03 ~]# docker node ls -q | xargs docker node inspect -f &apos;&#123;&#123;.ID&#125;&#125;[&#123;&#123;.Description.Hostname&#125;&#125;]:&#123;&#123;.Spec.Labels&#125;&#125;&apos;6f7dwt47y6qvgs3yc6l00nmjd[mini01]:map[tomcat:true datanode:true hbase-regionserver-1:true]5q2nmm2xaexhkn20z8f8ezglr[mini02]:map[tomcat:true datanode:true hbase-regionserver-2:true]ncppwjknhcwbegmliafut0718[mini03]:map[hbase-master:true namenode:true spark:true zookeeper:true] 查看日志启动容器时，查看相关日志，例如如下： 1234docker stack ps hadoopdocker stack ps hadoop --format &quot;&#123;&#123;.Name&#125;&#125;: &#123;&#123;.Error&#125;&#125;&quot;docker stack ps hadoop --format &quot;&#123;&#123;.Name&#125;&#125;: &#123;&#123;.Error&#125;&#125;&quot; --no-truncdocker stack ps hadoop --no-trunc]]></content>
      <categories>
        <category>Docker Swarm</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Docker Swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装指定版本的 Docker 服务]]></title>
    <url>%2F2019%2F08%2F06%2Fdocker-deploy01%2F</url>
    <content type="text"><![CDATA[说明之前部署docker服务的时候都是安装最新的docker版本，并使用docker swarm部署大数据组件。 但是在近期的一次部署发现 docker 18.06.1 版本，在使用docker swarm部署大数据组件的时候namenode存储的datanode信息不正确。原因是 18.06.1 版本中的docker swarm 存在一个LB网络，造成了该问题。 这个问题对于Hadoop本身是没有任何问题的，但是当我们启动hbase的时候却有问题了。通过日志发现hbase找不到datanode的节点信息，因为hbase得到的是LB的IP而不是datanode本身的IP，最终导致hbase启动失败。 最后解决的方案就是docker版本回退到 17.09.0 版本，该版本不存在LB网络。Hadoop的namenode中存储的datanode信息是正确的。 1234567891011121314151617181920212223242526272829[root@mini03 docker-swarm]# docker -vDocker version 18.06.1-ce, build e68fc7a[root@mini03 docker-swarm]# docker network lsNETWORK ID NAME DRIVER SCOPEf28f7ab2d811 bridge bridge local51c95dea1e5c docker_gwbridge bridge local7a7e31f4bce8 host host local3cxch31bl38k ingress overlay swarm5ea08e9a282f none null localpwk7oy2h3gnp zhang overlay swarm # 自己创建的网络[root@mini03 docker-swarm]# docker network inspect zhang ……………… &quot;Containers&quot;: &#123; &quot;a9e2e20c89bb6fbc2984a19c4c8e9f9500f3360f2b0434819fc31a143cbc7fc9&quot;: &#123; &quot;Name&quot;: &quot;visualizer_visualizer.1.0lgaqosyogoy0edkqdakeycz4&quot;, &quot;EndpointID&quot;: &quot;2cae08f3a1a63eadff6fee675e249ce19956dcc1d871329c90056a1829abc1d1&quot;, &quot;MacAddress&quot;: &quot;02:42:0a:00:00:04&quot;, &quot;IPv4Address&quot;: &quot;10.0.0.4/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;lb-zhang&quot;: &#123; &quot;Name&quot;: &quot;zhang-endpoint&quot;, &quot;EndpointID&quot;: &quot;44ed04b5768dd4ae9edf2e63bded8d5ab5af7cb43d49a4d0d4fbd999abfd5373&quot;, &quot;MacAddress&quot;: &quot;02:42:0a:00:00:02&quot;, &quot;IPv4Address&quot;: &quot;10.0.0.2/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;,……………… docker安装指定版本1234567891011121314151617181920212223242526272829303132# 安装必要的一些系统工具[root@mini02 tools]# yum install -y yum-utils device-mapper-persistent-data lvm2 # 添加软件源信息[root@mini02 tools]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 查看可安装的版本信息[root@mini02 tools]# yum makecache fast [root@mini02 tools]# yum list docker-ce.x86_64 --showduplicates | sort -r * updates: mirrors.aliyun.comLoading mirror speeds from cached hostfileLoaded plugins: fastestmirror * extras: mirrors.aliyun.com * epel: mirrors.aliyun.comdocker-ce.x86_64 18.06.1.ce-3.el7 docker-ce-stabledocker-ce.x86_64 18.06.0.ce-3.el7 docker-ce-stabledocker-ce.x86_64 18.03.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 18.03.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.12.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.12.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.09.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.09.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.06.2.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.06.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.06.0.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.03.3.ce-1.el7 docker-ce-stabledocker-ce.x86_64 17.03.2.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stabledocker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable# 安装指定版本的docker服务[root@mini02 tools]# yum -y install docker-ce-17.09.0.ce-1.el7.centos # 版本信息查看[root@mini02 tools]# docker -vDocker version 17.09.0-ce, build afdb6d4 加入开机自启动12345678[root@mini02 tools]# systemctl status docker● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled) Active: inactive (dead) Docs: https://docs.docker.com………………[root@mini02 tools]# systemctl enable docker.service # 加入开机自启动 Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service. 问题解决123456789101112131415161718[root@mini02 tools]# systemctl start dockerJob for docker.service failed because the control process exited with error code. See &quot;systemctl status docker.service&quot; and &quot;journalctl -xe&quot; for details.[root@mini02 tools]# journalctl -xe # 查询具体信息-- Defined-By: systemd-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel-- -- Unit docker.service has begun starting up.Nov 01 17:40:55 mini02 dockerd[2493]: time=&quot;2018-11-01T17:40:55.181209947+08:00&quot; level=info msg=&quot;libcontainerd: new containerd process, pid: 2501&quot;Nov 01 17:40:56 mini02 dockerd[2493]: time=&quot;2018-11-01T17:40:56.187023899+08:00&quot; level=error msg=&quot;[graphdriver] prior storage driver overlay2 failed: driver not supported&quot;Nov 01 17:40:56 mini02 dockerd[2493]: Error starting daemon: error initializing graphdriver: driver not supportedNov 01 17:40:56 mini02 systemd[1]: docker.service: main process exited, code=exited, status=1/FAILURENov 01 17:40:56 mini02 systemd[1]: Failed to start Docker Application Container Engine.-- Subject: Unit docker.service has failed-- Defined-By: systemd-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel………………# 具体信息如下截图，解决方法如下，之后就可以正常起docker服务了[root@mini02 tools]# mv /var/lib/docker /var/lib/docker.old 另请参考参考博客：Docker CE 镜像源站 参考博客：docker启动异常driver not supported]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware 实现 iptables NAT及端口映射]]></title>
    <url>%2F2019%2F08%2F06%2Fiptables01%2F</url>
    <content type="text"><![CDATA[前言本文只讲解实战应用，不会涉及原理讲解。如果想要了解iptables的工作流程或原理可参考如下博文。 具体操作是在PC机的VMware虚拟机上进行的，因此涉及的地址都是内网IP。在实际工作中也是一样的操作流程，只需要把涉及外网的地址改为公网IP即可。 文章参考：iptables nat及端口映射 文章参考：企业软件防火墙iptables 为什么有这篇文章？原因是在日常工作中，我们都会在自己的电脑上安装VMware虚拟机，并由此实现一些业务系统【如：LNMP】或模拟线上的网络环境等。 而本文模拟的就是IDC机房或办公网的环境。机房内网服务器不能上外网，只能通过网关服务器上外网。而外网服务器想要访问机房内部的服务器，也只能通过网关服务器转发实现访问。 iptables表和链的工作流程 常用操作123456789101112## 清空所有规则【默认是filter表】iptables -Fiptables -Xiptables -Ziptables -t nat -Fiptables -t nat -Xiptables -t nat -Z## 查看规则iptables -nLiptables -nL -t nat## 删除指定表指定链的指定行数据iptables -t nat -D POSTROUTING 1 涉及虚拟机网络设置内部服务器node01网络设置内网设置【只有一个网卡】 备注： 使用LAN区段，那么本机登录该虚拟机也不行，也ping不通，不在同一个网段不能互访。只能通过网关服务器ssh跳转登录访问。 eth0配置： 1234567891011121314[root@InnerNode01 network-scripts]# cat ifcfg-eth0 DEVICE=eth0TYPE=EthernetONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=noneIPV6INIT=yesUSERCTL=noIPADDR=172.16.10.10NETMASK=255.255.255.0GATEWAY=172.16.10.5# 阿里云DNSDNS1=223.5.5.5DNS2=223.6.6.6 网关服务器网络设置内网设置 备注：网关服务器的内网地址和内部服务器的地址在同一个网段。因此他们之间可以互访。 eth0配置： 12345678910[zhang@gateway01 network-scripts]$ cat ifcfg-eth0 DEVICE=eth0TYPE=EthernetONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=noneIPV6INIT=yesUSERCTL=noIPADDR=172.16.10.5NETMASK=255.255.255.0 外网设置【模拟的公网】 eth1配置： 1234567891011121314[root@gateway01 network-scripts]# cat ifcfg-eth1 DEVICE=eth1TYPE=EthernetONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=noneIPV6INIT=yesUSERCTL=noIPADDR=10.0.0.5NETMASK=255.255.255.0GATEWAY=10.0.0.2# 阿里云DNSDNS1=223.5.5.5DNS2=223.6.6.6 外网服务器设置外网设置【只有一个网卡】 eth0配置： 1234567891011121314[root@internet01 network-scripts]# cat ifcfg-eth0 DEVICE=eth0TYPE=EthernetONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=noneIPV6INIT=yesUSERCTL=noIPADDR=10.0.0.8NETMASK=255.255.255.0GATEWAY=10.0.0.2# 阿里云DNSDNS1=223.5.5.5DNS2=223.6.6.6 简单的NAT路由器网络架构 NAT需求介绍网关2个网络接口 Lan口: 172.16.10.5/24&ensp;&ensp;&ensp;&ensp;eth0 Wan口: 10.0.0.5/24&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;eth1 目的：实现内网中的节点服务器node01 IP：172.16.10.10（网段：172.16.10.0/24）可控的访问internet。 网关服务器操作1、网关机器开启linux的转发功能 123456789[root@gateway01 ~]# tail /etc/sysctl.conf # 添加如下内容…………net.ipv4.ip_forward = 1[root@gateway01 ~]# sysctl -p # 生效[root@gateway01 ~]# sysctl -a | grep &apos;net.ipv4.ip_forward&apos; net.ipv4.ip_forward = 1net.ipv4.ip_forward_use_pmtu = 0[root@gateway01 ~]# cat /proc/sys/net/ipv4/ip_forward1 2、网关机器iptables操作 1iptables -P FORWARD DROP 将FORWARD链的策略设置为DROP，这样做的目的是做到对内网ip的控制，你允许哪一个访问internet就可以增加一个规则，不在规则中的ip将无法访问internet。 1iptables -A FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT 这条规则规定允许任何地址到任何地址的确认包和关联包通过。一定要加这一条，否则你只允许lan IP访问没有用。 1iptables -t nat -A POSTROUTING -s 172.16.10.0/24 -j SNAT --to 10.0.0.5 这条规则做了一个SNAT，也就是源地址转换，将来自172.16.10.0/24的地址转换为10.0.0.5。 有这几条规则，一个简单的nat路由器就实现了。这时你可以将允许访问的ip或网段添加至FORWARD链，他们就能访问internet了。 12iptables -A FORWARD -s 172.16.10.10 -j ACCEPT # 允许单个地址 或者如下命令iptables -A FORWARD -s 172.16.10.0/24 -j ACCEPT # 允许该网段 比如我想让172.16.10.10这个地址访问internet，那么你就加如上的命令就可以了。 3、保存iptables规则 1iptables-save &gt; /etc/sysconfig/iptables 内部服务器node01测试1234567891011121314[root@InnerNode01 ~]# ping www.baidu.com # 查看是否可以ping通PING www.a.shifen.com (180.97.33.108) 56(84) bytes of data.64 bytes from 180.97.33.108 (180.97.33.108): icmp_seq=1 ttl=127 time=43.4 ms64 bytes from 180.97.33.108 (180.97.33.108): icmp_seq=2 ttl=127 time=42.6 ms64 bytes from 180.97.33.108 (180.97.33.108): icmp_seq=3 ttl=127 time=42.1 ms^C--- www.a.shifen.com ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2005msrtt min/avg/max/mdev = 42.114/42.735/43.420/0.561 ms[root@InnerNode01 ~]# [root@InnerNode01 ~]# telnet www.baidu.com 80 # telnet 是否可行Trying 112.34.112.40...Connected to www.baidu.com.Escape character is &apos;^]&apos;. 测验完毕！ 端口转发网络架构 端口转发需求介绍内部机器1个网络接口Lan内web server: 172.16.10.10:80 网关2个网络接口 Lan口:172.16.10.5/24&ensp;&ensp;&ensp;&ensp;eth0 Wan口:10.0.0.5/24&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;eth1 目的：对内部server进行端口转发，实现internet 10.0.0.8（网段：10.0.0.0/24）用户【模拟外网机器】访问内网服务器172.16.10.10:80。 网关服务器操作1、网关机器开启linux的转发功能 1234[root@gateway01 ~]# tail /etc/sysctl.conf # 添加如下内容…………net.ipv4.ip_forward = 1[root@gateway01 ~]# sysctl -p # 生效 2、网关机器iptables操作 1iptables -P FORWARD DROP 将FORWARD链的策略设置为DROP，这样做的目的是做到ip的控制，你允许哪一个访问就可以增加一个规则，不在规则中的ip将无法访问。 1iptables -A FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT 这条规则规定允许任何地址到任何地址的确认包和关联包通过。一定要加这一条，否则你只允许lan IP访问没有用。 1iptables -t nat -A PREROUTING -d 10.0.0.5 -p tcp --dport 80 -j DNAT --to 172.16.10.10:80 如果你要把访问 10.0.0.5:80 的数据包转发到Lan内web server，用上面的命令。 好了，命令完成了，端口转发也做完了，本例能不能转发呢？不能，为什么呢？我下面分析一下。本例中我们的FORWARD策略是DROP。那么也就是说，没有符合规则的包将被丢弃，不管内到外还是外到内。因此，我们需要加入下面的规则。 1iptables -A FORWARD -d 172.16.10.10 -p tcp --dport 80 -j ACCEPT 3、保存iptables规则 1iptables-save &gt; /etc/sysconfig/iptables 操作验证1、在内部服务器监听80端口 12345678910## xshell标签1操作[root@InnerNode01 ~]# nc -l 80 # 保持持续监听## xshell标签2操作[root@InnerNode01 ~]# netstat -lntupActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 808/rpcbind tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 1971/nc ### 可见80端口已经监听成功tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1099/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1355/master 2、在外网服务器Telnet 1234567[zhang@internet01 ~]$ telnet 10.0.0.5 80Trying 10.0.0.5...Connected to 10.0.0.5.Escape character is &apos;^]&apos;.^]telnet&gt; quitConnection closed. 由上可知，外网服务器（10.0.0.8）访问内部服务器（172.16.10.10:80）成功。 测验完毕！]]></content>
      <categories>
        <category>iptables</category>
      </categories>
      <tags>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从头到尾说一次 Java 垃圾回收]]></title>
    <url>%2F2019%2F07%2F23%2Fjvm01%2F</url>
    <content type="text"><![CDATA[文章转载自微信公众号：「阿里巴巴中间件」，作者：率鸽 之前上学的时候有这个一个梗，说在食堂里吃饭，吃完把餐盘端走清理的，是 C++ 程序员，吃完直接就走的，是 Java 程序员。 确实，在 Java 的世界里，似乎我们不用对垃圾回收那么的专注，很多初学者不懂 GC，也依然能写出一个能用甚至还不错的程序或系统。但其实这并不代表 Java 的 GC 就不重要。相反，它是那么的重要和复杂，以至于出了问题，那些初学者除了打开 GC 日志，看着一堆0101的天文，啥也做不了。 今天我们就从头到尾完整地聊一聊 Java 的垃圾回收。 什么是垃圾回收垃圾回收（Garbage Collection，GC），顾名思义就是释放垃圾占用的空间，防止内存泄露。有效的使用可以使用的内存，对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收。 Java 语言出来之前，大家都在拼命的写 C 或者 C++ 的程序，而此时存在一个很大的矛盾，C++ 等语言创建对象要不断的去开辟空间，不用的时候又需要不断的去释放控件，既要写构造函数，又要写析构函数，很多时候都在重复的 allocated，然后不停的析构。于是，有人就提出，能不能写一段程序实现这块功能，每次创建，释放控件的时候复用这段代码，而无需重复的书写呢？ 1960年，基于 MIT 的 Lisp 首先提出了垃圾回收的概念，而这时 Java 还没有出世呢！所以实际上 GC 并不是Java的专利，GC 的历史远远大于 Java 的历史！ 怎么定义垃圾既然我们要做垃圾回收，首先我们得搞清楚垃圾的定义是什么，哪些内存是需要回收的。 引用计数算法引用计数算法（Reachability Counting）是通过在对象头中分配一个空间来保存该对象被引用的次数（Reference Count）。如果该对象被其它对象引用，则它的引用计数加1，如果删除对该对象的引用，那么它的引用计数就减1，当该对象的引用计数为0时，那么该对象就会被回收。 1String m = new String(&quot;jack&quot;); 先创建一个字符串，这时候”jack”有一个引用，就是 m。 然后将 m 设置为 null，这时候”jack”的引用次数就等于0了，在引用计数算法中，意味着这块内容就需要被回收了。 1m = null; 引用计数算法是将垃圾回收分摊到整个应用程序的运行当中了，而不是在进行垃圾收集时，要挂起整个应用的运行，直到对堆中所有对象的处理都结束。因此，采用引用计数的垃圾收集不属于严格意义上的 “Stop-The-World” 的垃圾收集机制。 看似很美好，但我们知道JVM的垃圾回收就是 “Stop-The-World” 的，那是什么原因导致我们最终放弃了引用计数算法呢？看下面的例子。 123456789101112131415public class ReferenceCountingGC &#123; public Object instance; public ReferenceCountingGC(String name)&#123;&#125;&#125;public static void testGC()&#123; ReferenceCountingGC a = new ReferenceCountingGC(&quot;objA&quot;); ReferenceCountingGC b = new ReferenceCountingGC(&quot;objB&quot;); a.instance = b; b.instance = a; a = null; b = null;&#125; 定义2个对象 相互引用 置空各自的声明引用 我们可以看到，最后这2个对象已经不可能再被访问了，但由于他们相互引用着对方，导致它们的引用计数永远都不会为0，通过引用计数算法，也就永远无法通知GC收集器回收它们。 可达性分析算法可达性分析算法（Reachability Analysis）的基本思路是，通过一些被称为引用链（GC Roots）的对象作为起点，从这些节点开始向下搜索，搜索走过的路径被称为（Reference Chain)，当一个对象到 GC Roots 没有任何引用链相连时（即从 GC Roots 节点到该节点不可达），则证明该对象是不可用的。 通过可达性算法，成功解决了引用计数所无法解决的问题-“循环依赖”。只要你无法与 GC Root 建立直接或间接的连接，系统就会判定你为可回收对象。那这样就引申出了另一个问题，哪些属于 GC Root。 Java 内存区域在 Java 语言中，可作为 GC Root 的对象包括以下4种： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中 JNI（即一般说的 Native 方法）引用的对象 虚拟机栈（栈帧中的本地变量表）中引用的对象此时的 s，即为 GC Root，当 s 置空时，localParameter 对象也断掉了与 GC Root 的引用链，将被回收。 12345678public class StackLocalParameter &#123; public StackLocalParameter(String name)&#123;&#125;&#125;public static void testGC()&#123; StackLocalParameter s = new StackLocalParameter(&quot;localParameter&quot;); s = null;&#125; 方法区中类静态属性引用的对象s 为 GC Root，s 置为 null，经过 GC 后，s 所指向的 properties 对象由于无法与 GC Root 建立关系被回收。 而 m 作为类的静态属性，也属于 GC Root，parameter 对象依然与 GC root 建立着连接，所以此时 parameter 对象并不会被回收。 12345678910public class MethodAreaStaicProperties &#123; public static MethodAreaStaicProperties m; public MethodAreaStaicProperties(String name)&#123;&#125;&#125;public static void testGC()&#123; MethodAreaStaicProperties s = new MethodAreaStaicProperties(&quot;properties&quot;); s.m = new MethodAreaStaicProperties(&quot;parameter&quot;); s = null;&#125; 方法区中常量引用的对象m 即为方法区中的常量引用，也为 GC Root，s 置为 null 后，final 对象也不会因没有与 GC Root 建立联系而被回收。 123456789public class MethodAreaStaicProperties &#123; public static final MethodAreaStaicProperties m = MethodAreaStaicProperties(&quot;final&quot;); public MethodAreaStaicProperties(String name)&#123;&#125;&#125;public static void testGC()&#123; MethodAreaStaicProperties s = new MethodAreaStaicProperties(&quot;staticProperties&quot;); s = null;&#125; 本地方法栈中引用的对象任何 Native 接口都会使用某种本地方法栈，实现的本地方法接口是使用 C 连接模型的话，那么它的本地方法栈就是 C 栈。当线程调用 Java 方法时，虚拟机会创建一个新的栈帧并压入 Java 栈。然而当它调用的是本地方法时，虚拟机会保持 Java 栈不变，不再在线程的 Java 栈中压入新的帧，虚拟机只是简单地动态连接并直接调用指定的本地方法。 怎么回收垃圾在确定了哪些垃圾可以被回收后，垃圾收集器要做的事情就是开始进行垃圾回收，但是这里面涉及到一个问题是：如何高效地进行垃圾回收。 由于Java虚拟机规范并没有对如何实现垃圾收集器做出明确的规定，因此各个厂商的虚拟机可以采用不同的方式来实现垃圾收集器，这里我们讨论几种常见的垃圾收集算法的核心思想。 标记—清除算法 标记清除算法（Mark-Sweep）是最基础的一种垃圾回收算法，它分为2部分，先把内存区域中的这些对象进行标记，哪些属于可回收标记出来，然后把这些垃圾拎出来清理掉。就像上图一样，清理掉的垃圾就变成未使用的内存区域，等待被再次使用。 这逻辑再清晰不过了，并且也很好操作，但它存在一个很大的问题，那就是内存碎片。 上图中等方块的假设是 2M，小一些的是 1M，大一些的是 4M。等我们回收完，内存就会切成了很多段。我们知道开辟内存空间时，需要的是连续的内存区域，这时候我们需要一个 2M的内存区域，其中有2个 1M 是没法用的。这样就导致，其实我们本身还有这么多的内存的，但却用不了。 复制算法 复制算法（Copying）是在标记清除算法上演化而来，解决标记清除算法的内存碎片问题。它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。保证了内存的连续可用，内存分配时也就不用考虑内存碎片等复杂情况，逻辑清晰，运行高效。 上面的图很清楚，也很明显的暴露了另一个问题，合着我这140平的大三房，只能当70平米的小两房来使？代价实在太高。 标记整理算法 标记整理算法（Mark-Compact）标记过程仍然与标记—清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，再清理掉端边界以外的内存区域。 标记整理算法一方面在标记—清除算法上做了升级，解决了内存碎片的问题，也规避了复制算法只能利用一半内存区域的弊端。看起来很美好，但从上图可以看到，它对内存变动更频繁，需要整理所有存活对象的引用地址，在效率上比复制算法要差很多。 分代收集算法分代收集算法（Generational Collection）严格来说并不是一种思想或理论，而是融合上述 3 种基础的算法思想，而产生的针对不同情况所采用不同算法的一套组合拳。 对象存活周期的不同将内存划分为几块。一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。 在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用标记—清理或者标记整理算法来进行回收。 so，另一个问题来了，那内存区域到底被分为哪几块，每一块又有什么特别适合什么算法呢？ 内存模型与回收策略 Java 堆（Java Heap）是JVM所管理的内存中最大的一块，堆又是垃圾收集器管理的主要区域，这里我们主要分析一下 Java 堆的结构。 Java 堆主要分为2个区域：年轻代与老年代，其中年轻代又分 Eden 区和 Survivor 区，其中 Survivor 区又分 From 和 To 2个区。可能这时候大家会有疑问，为什么需要 Survivor 区，为什么Survivor 还要分2个区。不着急，我们从头到尾，看看对象到底是怎么来的，而它又是怎么没的。 Eden 区IBM 公司的专业研究表明，有将近98%的对象是朝生夕死，所以针对这一现状，大多数情况下，对象会在新生代 Eden 区中进行分配，当 Eden 区没有足够空间进行分配时，虚拟机会发起一次 Minor GC，Minor GC 相比 Major GC 更频繁，回收速度也更快。 通过 Minor GC 之后，Eden 会被清空，Eden 区中绝大部分对象会被回收，而那些无需回收的存活对象，将会进到 Survivor 的 To 区（若 To 区不够，则直接进入 Old 区）。 Survivor 区Survivor 区相当于是 Eden 区和 Old 区的一个缓冲，类似于我们交通灯中的黄灯。 Survivor 又分为2个区，一个是 From 区，一个是 To 区。每次执行 Minor GC，会将 Eden 区和 From 存活的对象放到 Survivor 的 To 区（如果 To 区不够，则直接进入 Old 区）。 为啥需要？不就是新生代到老年代么，直接 Eden 到 Old 不好了吗，为啥要这么复杂。 想想如果没有 Survivor 区，Eden 区每进行一次 Minor GC，存活的对象就会被送到老年代，老年代很快就会被填满。而有很多对象虽然一次 Minor GC 没有消灭，但其实也并不会蹦跶多久，或许第二次，第三次就需要被清除。这时候移入老年区，很明显不是一个明智的决定。 所以，Survivor 的存在意义就是减少被送到老年代的对象，进而减少 Major GC 的发生。Survivor 的预筛选保证，只有经历16次 Minor GC 还能在新生代中存活的对象，才会被送到老年代。 为啥需要俩？设置两个 Survivor 区最大的好处就是解决内存碎片化。 我们先假设一下，Survivor 如果只有一个区域会怎样。Minor GC 执行后，Eden 区被清空了，存活的对象放到了 Survivor 区，而之前 Survivor 区中的对象，可能也有一些是需要被清除的。问题来了，这时候我们怎么清除它们？在这种场景下，我们只能标记清除，而我们知道标记清除最大的问题就是内存碎片，在新生代这种经常会消亡的区域，采用标记清除必然会让内存产生严重的碎片化。 因此 Survivor 有2个区域，每次 Minor GC，会将之前 Eden 区和 From 区中的存活对象复制到 To 区域。第二次 Minor GC 时，From 与 To 职责兑换，这时候会将 Eden 区和 To 区中的存活对象再复制到 From 区域，以此反复。 如下图：「采集周期：每分钟采集一次」 这种机制最大的好处就是，整个过程中，永远有一个 Survivor space 是空的，另一个非空的 Survivor space 是无碎片的。那么，Survivor 为什么不分更多块呢？比方说分成三个、四个、五个?显然，如果 Survivor 区再细分下去，每一块的空间就会比较小，容易导致 Survivor 区满，两块 Survivor 区可能是经过权衡之后的最佳方案。 Old 区老年代占据着2/3的堆内存空间，只有在 Major GC 的时候才会进行清理，每次 GC 都会触发 “Stop-The-World” 。内存越大，STW 的时间也越长，所以内存也不仅仅是越大就越好。由于复制算法在对象存活率较高的老年代会进行很多次的复制操作，效率很低，所以老年代这里采用的是标记—整理算法。 除了上述所说，在内存担保机制下，无法安置的对象会直接进到老年代，以下几种情况也会进入老年代。 大对象大对象指需要大量连续内存空间的对象，这部分对象不管是不是“朝生夕死”，都会直接进到老年代。这样做主要是为了避免在 Eden 区及2个 Survivor 区之间发生大量的内存复制。当你的系统有非常多“朝生夕死”的大对象时，得注意了。 长期存活对象虚拟机给每个对象定义了一个对象年龄（Age）计数器。正常情况下对象会不断的在 Survivor 的 From 区与 To 区之间移动，对象在 Survivor 区中每经历一次 Minor GC，年龄就增加1岁。当年龄增加到15岁时，这时候就会被转移到老年代。当然，这里的15，JVM 也支持进行特殊设置。 动态对象年龄虚拟机并不重视要求对象年龄必须到15岁，才会放入老年区，如果 Survivor 空间中相同年龄所有对象大小的总合大于 Survivor 空间的一半，年龄大于等于该年龄的对象就可以直接进去老年区，无需等你 “成年”。 这其实有点类似于负载均衡，轮询是负载均衡的一种，保证每台机器都分得同样的请求。看似很均衡，但每台机的硬件不通，健康状况不同，我们还可以基于每台机接受的请求数，或每台机的响应时间等，来调整我们的负载均衡算法。 最后，常用的垃圾收集器有：Serial，Parallel Old，CMS，G1 本文部分内容参考自书籍：《深入理解Java虚拟机》。 本文作者：聂晓龙（花名：率鸽），阿里巴巴高级开发工程。目前团队正在疯狂招聘中，感兴趣的同学可直接邮件 xiaolong.nxl#alibaba-inc.com，fulan.zjf#alibaba-inc.com. 阅读原文]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux curl 表单登录或提交与cookie使用]]></title>
    <url>%2F2019%2F07%2F20%2Fcurl03%2F</url>
    <content type="text"><![CDATA[前言本文主要讲解通过curl 实现表单提交登录。单独的表单提交与表单登录都差不多，因此就不单独说了。 说明：针对curl表单提交实现登录，不是所有网站都适用，原因是有些网站后台做了限制或有其他校验。我们不知道这些网站后台的限制或校验机制具体是什么，因此直接curl表单登录可能是不行的。 当然，如下案例是可以用curl登录的。 案例：LeanCloud登录要求和结果要求：通过curl登录后，能正常访问leancloud的应用页面。 登录页面链接如下： 1https://leancloud.cn/dashboard/login.html#/signin 能正常访问如下页面： 1https://leancloud.cn/dashboard/applist.html#/apps 浏览器访问效果： 无登录直接访问结果浏览器访问结果 上图红框 403 中的访问连接如下： 1https://leancloud.cn/1.1/clients/self/apps 通过curl 验证是否登录123456789101112[root@iZ28xbsfvc4Z ~]# curl -i https://leancloud.cn/1.1/clients/self/appsHTTP/1.1 403 ForbiddenServer: openrestyDate: Sun, 14 Jul 2019 11:35:28 GMTContent-Type: application/json;charset=utf-8Transfer-Encoding: chunkedConnection: keep-aliveVary: Accept-EncodingCache-Control: no-cache,no-storePragma: no-cache&#123;&quot;code&quot;:1,&quot;error&quot;:&quot;User doesn&apos;t sign in.&quot;&#125; 获取表单字段信息 获取表单提交链接通过下图可得到表单提交的链接信息。具体如下： 1https://leancloud.cn/1.1/signin curl 表单登录并保存cookie信息123curl -v -c leancloud1.info -X POST -F &apos;email=yourname&apos; -F &apos;password=yourpassword&apos; https://leancloud.cn/1.1/signin# 或则curl -v -c leancloud3.info -X POST -d &apos;email=yourname&amp;password=yourpassword&apos; https://leancloud.cn/1.1/signin 查看cookie信息123456789101112131415161718[root@iZ28xbsfvc4Z 20190714_02]# lltotal 32-rw-r--r-- 1 root root 337 Jul 14 19:45 leancloud1.info-rw-r--r-- 1 root root 335 Jul 14 19:46 leancloud3.info[root@iZ28xbsfvc4Z 20190714_02]# cat leancloud1.info # Netscape HTTP Cookie File# http://curl.haxx.se/docs/http-cookies.html# This file was generated by libcurl! Edit at your own risk.#HttpOnly_leancloud.cn FALSE / TRUE 1563709522 uluru_user Ff1IPOiMX%2F6ipevuxy0OOg%3D%3Dleancloud.cn FALSE / TRUE 1563709522 XSRF-TOKEN 5647dc84bd6eaea37eca2d07ae0e401cca4ba76803989c8559XXXXX7283da[root@iZ28xbsfvc4Z 20190714_02]# cat leancloud3.info # Netscape HTTP Cookie File# http://curl.haxx.se/docs/http-cookies.html# This file was generated by libcurl! Edit at your own risk.#HttpOnly_leancloud.cn FALSE / TRUE 1563709591 uluru_user arTwQm6JylzLjBaQt7TpiQ%3D%3Dleancloud.cn FALSE / TRUE 1563709591 XSRF-TOKEN 751e12827c7c046408541bc1bf962b5912ac35b0d07f88120XXXXXX40704704 每列字段说明：domain：创建并可以读取变量的域名。flag：一个 TRUE/FALSE 值，表明给定域中的所有机器是否都可以访问该变量。此值由浏览器自动设置，具体取决于你为域设置的值。path：变量在域中有效的路径。secure：一个 TRUE/FALSE 值，表明是否需要与域的安全连接来访问变量。expiration：该变量将过期的UNIX时间。UNIX时间定义为自1970年1月1日00:00:00 GMT开始的秒数。name：变量名称value：变量值 校验是否登录成功直接访问和带有cookie访问，这两种访问方式，请对比查看。 直接访问123456789101112[root@iZ28xbsfvc4Z 20190714_02]# curl -i https://leancloud.cn/1.1/clients/self/appsHTTP/1.1 403 ForbiddenServer: openrestyDate: Sun, 14 Jul 2019 11:52:47 GMTContent-Type: application/json;charset=utf-8Transfer-Encoding: chunkedConnection: keep-aliveVary: Accept-EncodingCache-Control: no-cache,no-storePragma: no-cache&#123;&quot;code&quot;:1,&quot;error&quot;:&quot;User doesn&apos;t sign in.&quot;&#125; 带有cookie文件的访问12345678910111213141516# 使用cookie[root@iZ28xbsfvc4Z 20190714_02]# curl -i -b leancloud1.info https://leancloud.cn/1.1/clients/self/apps ## 或者[root@iZ28xbsfvc4Z 20190714_02]# curl -i -b leancloud3.info https://leancloud.cn/1.1/clients/self/appsHTTP/1.1 200 OKServer: openrestyDate: Sun, 14 Jul 2019 11:53:29 GMTContent-Type: application/json;charset=utf-8Transfer-Encoding: chunkedConnection: keep-aliveVary: Accept-EncodingCache-Control: no-cache,no-storePragma: no-cacheStrict-Transport-Security: max-age=31536000[&#123;&quot;app_domain&quot;:null,&quot;description&quot;:null,&quot;archive_status&quot;:0,&quot;biz_type&quot;:&quot;dev&quot;,&quot;master_key&quot;: ……………… 复制浏览器的cookie访问12345678910111213[root@iZ28xbsfvc4Z 20190720]# curl -i -H &apos;cookie: _ga=GA1.2.2055706705.1560005524; …………&apos; https://leancloud.cn/1.1/clients/self/appsHTTP/1.1 200 OKServer: openrestyDate: Sat, 20 Jul 2019 08:11:37 GMTContent-Type: application/json;charset=utf-8Transfer-Encoding: chunkedConnection: keep-aliveVary: Accept-EncodingCache-Control: no-cache,no-storePragma: no-cacheStrict-Transport-Security: max-age=31536000[&#123;&quot;app_domain&quot;:null,&quot;description&quot;:null,&quot;archive_status&quot;:0,&quot;biz_type&quot;:&quot;dev&quot;,&quot;master_key&quot;: ……………… 由上可知curl登录成功。 推荐阅读Linux curl 命令详解 Linux curl 常用示例 Linux curl 表单登录或提交与cookie使用]]></content>
      <categories>
        <category>curl</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux curl 常用示例]]></title>
    <url>%2F2019%2F07%2F18%2Fcurl02%2F</url>
    <content type="text"><![CDATA[前言本篇文章包含了curl的常用案例使用。 如果想了解curl选项的详细说明，请参考前一篇文章「Linux curl 命令详解」。 常见网页访问示例基本用法访问一个网页 1curl https://www.baidu.com 执行后，相关的网页信息会打印出来 进度条展示有时候我们不需要进度表展示，而需要进度条展示。比如：下载文件时。 可以通过 -#, --progress-bar 选项实现。 12345678[root@iZ28xbsfvc4Z 20190713]# curl https://www.baidu.com | head -n1 # 进度表显示 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 2443 100 2443 0 0 11662 0 --:--:-- --:--:-- --:--:-- 11688&lt;!DOCTYPE html&gt;[root@iZ28xbsfvc4Z 20190713]# curl -# https://www.baidu.com | head -n1 # 进度条显示######################################################################## 100.0%&lt;!DOCTYPE html&gt; 静默模式与错误信息打印当我们做一些操作时，可能会出现进度表。这时我们可以使用 -s, --silent 静默模式去掉这些不必要的信息。 如果使用 -s, --silent 时，还需要打印错误信息，那么还需要使用 -S, --show-error 选项。 静默模式示例1234567[root@iZ28xbsfvc4Z ~]# curl https://www.baidu.com | head -n1 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 2443 100 2443 0 0 11874 0 --:--:-- --:--:-- --:--:-- 11859&lt;!DOCTYPE html&gt;[root@iZ28xbsfvc4Z ~]# curl -s https://www.baidu.com | head -n1&lt;!DOCTYPE html&gt; 静默模式结合错误信息打印1234[root@iZ28xbsfvc4Z 20190713]# curl -s https://140.205.16.113/ [root@iZ28xbsfvc4Z 20190713]# [root@iZ28xbsfvc4Z 20190713]# curl -sS https://140.205.16.113/ curl: (51) Unable to communicate securely with peer: requested domain name does not match the server&apos;s certificate. 显示详细操作信息使用 -v, --verbose 选项实现。 以 &gt; 开头的行表示curl发送的”header data”；&lt; 表示curl接收到的通常情况下隐藏的”header data”；而以 * 开头的行表示curl提供的附加信息。 12345678910111213141516171819202122232425262728293031323334[root@iZ28xbsfvc4Z 20190712]# curl -v https://www.baidu.com* About to connect() to www.baidu.com port 443 (#0)* Trying 180.101.49.12...* Connected to www.baidu.com (180.101.49.12) port 443 (#0)* Initializing NSS with certpath: sql:/etc/pki/nssdb* CAfile: /etc/pki/tls/certs/ca-bundle.crt CApath: none* SSL connection using TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256* Server certificate:* subject: CN=baidu.com,O=&quot;Beijing Baidu Netcom Science Technology Co., Ltd&quot;,OU=service operation department,L=beijing,ST=beijing,C=CN* start date: May 09 01:22:02 2019 GMT* expire date: Jun 25 05:31:02 2020 GMT* common name: baidu.com* issuer: CN=GlobalSign Organization Validation CA - SHA256 - G2,O=GlobalSign nv-sa,C=BE&gt; GET / HTTP/1.1&gt; User-Agent: curl/7.29.0&gt; Host: www.baidu.com&gt; Accept: */*&gt; &lt; HTTP/1.1 200 OK&lt; Accept-Ranges: bytes&lt; Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform&lt; Connection: Keep-Alive&lt; Content-Length: 2443&lt; Content-Type: text/html&lt; Date: Fri, 12 Jul 2019 08:26:23 GMT&lt; Etag: &quot;588603eb-98b&quot;&lt; Last-Modified: Mon, 23 Jan 2017 13:23:55 GMT&lt; Pragma: no-cache&lt; Server: bfe/1.0.8.18&lt; Set-Cookie: BDORZ=27315; max-age=86400; domain=.baidu.com; path=/&lt; &lt;!DOCTYPE html&gt;……………… # curl 网页的具体信息 指定访问的请求方法当然curl默认使用GET方式访问。使用了 -d, --data &lt;data&gt; 选项，那么会默认为 POST方法访问。如果此时还想实现 GET 访问，那么可以使用 -G, --get 选项强制curl 使用GET方法访问。 同时 -X, --request &lt;command&gt; 选项也可以指定访问方法。 POST请求和数据传输为了抓包查看信息所以使用了 --local-port &lt;num&gt;[-num] 选项，在实际应用中不需要该选项。 12345678910111213141516171819202122232425[root@iZ28xbsfvc4Z ~]# curl -sv --local-port 9000 -X POST -d &apos;user=zhang&amp;pwd=123456&apos; http://www.zhangblog.com/2019/06/24/domainexpire/ | head -n1 ## 或者[root@iZ28xbsfvc4Z ~]# curl -sv --local-port 9000 -d &apos;user=zhang&amp;pwd=123456&apos; http://www.zhangblog.com/2019/06/24/domainexpire/ | head -n1* About to connect() to www.zhangblog.com port 80 (#0)* Trying 120.27.48.179...* Connected to www.zhangblog.com (120.27.48.179) port 80 (#0)&gt; POST /2019/06/24/domainexpire/ HTTP/1.1 # POST 请求方法&gt; User-Agent: curl/7.29.0&gt; Host: www.zhangblog.com&gt; Accept: */*&gt; Content-Length: 21&gt; Content-Type: application/x-www-form-urlencoded&gt; &#125; [data not shown]* upload completely sent off: 21 out of 21 bytes&lt; HTTP/1.1 405 Not Allowed&lt; Server: nginx/1.14.2&lt; Date: Thu, 18 Jul 2019 07:56:23 GMT&lt; Content-Type: text/html&lt; Content-Length: 173&lt; Connection: keep-alive&lt; &#123; [data not shown]* Connection #0 to host www.zhangblog.com left intact&lt;html&gt; 抓包信息 1[root@iZ28xbsfvc4Z tcpdump]# tcpdump -i any port 9000 -A -s 0 指定请求方法1curl -vs -X POST https://www.baidu.com | head -n1 1curl -vs -X PUT https://www.baidu.com | head -n1 保存访问网页使用linux的重定向功能保存1curl www.baidu.com &gt;&gt; baidu.html 使用curl的大O选项通过 -O, --remote-name 选项实现。 1234567[root@iZ28xbsfvc4Z 20190712]# curl -O https://www.baidu.com # 使用了 -O 选项，必须指定到具体的文件 错误使用curl: Remote file name has no length!curl: try &apos;curl --help&apos; or &apos;curl --manual&apos; for more information[root@iZ28xbsfvc4Z 20190712]# curl -O https://www.baidu.com/index.html # 使用了 -O 选项，必须指定到具体的文件 正确使用 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 2443 100 2443 0 0 13289 0 --:--:-- --:--:-- --:--:-- 13349 使用curl的小o选项通过 -o, --output &lt;file&gt; 选项实现。 12345678910111213141516[root@iZ28xbsfvc4Z 20190713]# curl -o sina.txt https://www.sina.com.cn/ # 单个操作[root@iZ28xbsfvc4Z 20190713]# ll-rw-r--r-- 1 root root 154 Jul 13 21:06 sina.txt[root@iZ28xbsfvc4Z 20190703]# curl &quot;http://www.&#123;baidu,douban&#125;.com&quot; -o &quot;site_#1.txt&quot; # 批量操作，注意curl 的地址需要用引号括起来[1/2]: http://www.baidu.com --&gt; site_baidu.txt % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 2381 100 2381 0 0 46045 0 --:--:-- --:--:-- --:--:-- 46686[2/2]: http://www.douban.com --&gt; site_douban.txt100 162 100 162 0 0 3173 0 --:--:-- --:--:-- --:--:-- 3173[root@iZ28xbsfvc4Z 20190703]# [root@iZ28xbsfvc4Z 20190703]# lltotal 220-rw-r--r-- 1 root root 2381 Jul 4 16:53 site_baidu.txt-rw-r--r-- 1 root root 162 Jul 4 16:53 site_douban.txt 允许不安全访问当我们使用curl进行https访问访问时，如果SSL证书是我们自签发的证书，那么这个时候需要使用 -k, --insecure 选项，允许不安全的访问。 1234567891011[root@iZ28xbsfvc4Z ~]# curl https://140.205.16.113/ # 被拒绝curl: (51) Unable to communicate securely with peer: requested domain name does not match the server&apos;s certificate.[root@iZ28xbsfvc4Z ~]# [root@iZ28xbsfvc4Z ~]# curl -k https://140.205.16.113/ # 允许执行不安全的证书连接&lt;!DOCTYPE HTML PUBLIC &quot;-//IETF//DTD HTML 2.0//EN&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=&quot;white&quot;&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;p&gt;You don&apos;t have permission to access the URL on this server.&lt;hr/&gt;Powered by Tengine&lt;/body&gt;&lt;/html&gt; 获取HTTP响应状态码在脚本中，这是很常见的测试网站是否正常的用法。 通过 -w, --write-out &lt;format&gt; 选项实现。 12345[root@iZ28xbsfvc4Z 20190713]# curl -o /dev/null -s -w %&#123;http_code&#125; https://baidu.com302[root@iZ28xbsfvc4Z 20190713]# [root@iZ28xbsfvc4Z 20190713]# [root@iZ28xbsfvc4Z 20190713]# curl -o /dev/null -s -w %&#123;http_code&#125; https://www.baidu.com200[root@iZ28xbsfvc4Z 20190713]# 指定proxy服务器以及其端口很多时候上网需要用到代理服务器(比如是使用代理服务器上网或者因为使用curl别人网站而被别人屏蔽IP地址的时候)，幸运的是curl通过使用 -x, --proxy &lt;[protocol://][user:password@]proxyhost[:port]&gt; 选项来支持设置代理。 1curl -x 192.168.100.100:1080 https://www.baidu.com 模仿浏览器访问有些网站需要使用特定的浏览器去访问他们，有些还需要使用某些特定的浏览器版本。我们可以通过 -A, --user-agent &lt;agent string&gt; 或者 -H, --header &lt;header&gt; 选项实现模拟浏览器访问。 123curl -A &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/75.0.3770.999&quot; http://www.zhangblog.com/2019/06/24/domainexpire/ 或者curl -H &apos;User-Agent: Mozilla/5.0&apos; http://www.zhangblog.com/2019/06/24/domainexpire/ 伪造referer（盗链）有些网站的网页对http访问的链接来源做了访问限制，这些限制几乎都是通过referer来实现的。 比如：要求是先访问首页，然后再访问首页中的邮箱页面，这时访问邮箱的referer地址就是访问首页成功后的页面地址。如果服务器发现对邮箱页面访问的referer地址不是首页的地址，就断定那是个盗连了。 可以通过 -e, --referer 或则 -H, --header &lt;header&gt; 实现伪造 referer 。 123curl -e &apos;https://www.baidu.com&apos; http://www.zhangblog.com/2019/06/24/domainexpire/或者curl -H &apos;Referer: https://www.baidu.com&apos; http://www.zhangblog.com/2019/06/24/domainexpire/ 构造HTTP请求头可以通过 -H, --header &lt;header&gt; 实现构造http请求头。 1curl -H &apos;Connection: keep-alive&apos; -H &apos;Referer: https://sina.com.cn&apos; -H &apos;User-Agent: Mozilla/1.0&apos; http://www.zhangblog.com/2019/06/24/domainexpire/ 保存响应头信息可以通过 -D, --dump-header &lt;file&gt; 选项实现。 12345[root@iZ28xbsfvc4Z 20190703]# curl -D baidu_header.info www.baidu.com ………………[root@iZ28xbsfvc4Z 20190703]# lltotal 4-rw-r--r-- 1 root root 400 Jul 3 10:11 baidu_header.info # 生成的头文件 限时访问--connect-timeout &lt;seconds&gt; 连接服务端的超时时间。这只限制了连接阶段，一旦curl连接了此选项就不再使用了。 123456# 当前 https://www.zhangXX.com 是国外服务器，访问受限[root@iZ28xbsfvc4Z ~]# curl --connect-timeout 10 https://www.zhangXX.com | head % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- 0:00:10 --:--:-- 0curl: (28) Connection timed out after 10001 milliseconds -m, --max-time &lt;seconds&gt; 允许整个操作花费的最大时间(以秒为单位)。这对于防止由于网络或链接变慢而导致批处理作业挂起数小时非常有用。 12345678910111213[root@iZ28xbsfvc4Z ~]# curl -m 10 --limit-rate 5 http://www.baidu.com/ | head # 超过10秒后，断开连接 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 2 2381 2 50 0 0 4 0 0:09:55 0:00:10 0:09:45 4curl: (28) Operation timed out after 10103 milliseconds with 50 out of 2381 bytes received&lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;met### 或[root@iZ28xbsfvc4Z ~]# curl -m 10 https://www.zhangXX.com | head # 超过10秒后，断开连接 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- 0:00:10 --:--:-- 0curl: (28) Connection timed out after 10001 milliseconds 显示抓取错误当我们请求访问失败时或者没有该网页时，网站一般都会给出一个错误的提示页面。 如果我们不需要这个错误页面，只想得到简洁的错误信息。那么可以通过 -f, --fail 选项实现。 12345678910[root@iZ28xbsfvc4Z 20190713]# curl http://www.zhangblog.com/201912312&lt;html&gt;&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=&quot;white&quot;&gt;&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx/1.14.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;[root@iZ28xbsfvc4Z 20190713]# curl -f http://www.zhangblog.com/201912312 # 得到更简洁的错误信息curl: (22) The requested URL returned error: 404 Not Found 表单登录与cookie使用参见：「Linux curl 表单登录或提交与cookie使用」 文件上传与下载涉及 FTP 服务，简单快速搭建可参考：《CentOS7下安装FTP服务》「https://www.cnblogs.com/zhi-leaf/p/5983550.html」 文件下载网页文件下载123# 以进度条展示，而不是进度表展示[root@iZ28xbsfvc4Z 20190715]# curl -# -o tmp.data2 http://www.zhangblog.com/uploads/tmp/tmp.data######################################################################## 100.0% FTP文件下载说明1：其中 ftp1 用户是ftp服务端的账号，具体家目录是：/mnt/ftp1 说明2：当我们使用 curl 通过 FTP 进行下载时，后面跟的路径都是：当前使用的 ftp 账号家目录为基础的相对路径，然后找到的目标文件。 示例1 12345678# 其中 tmp.data 的绝对路径是：/mnt/ftp1/tmpdata/tmp.data ；ftp1 账号的家目录是：/mnt/ftp1# 说明：/tmpdata/tmp.data 这个路径是针对 ftp1 账号的家目录而言的[yun@nginx_proxy01 20190715]$ curl -O ftp://ftp1:123456@172.16.1.195:21/tmpdata/tmp.data # 或者[yun@nginx_proxy01 20190715]$ curl -O -u ftp1:123456 ftp://172.16.1.195:21/tmpdata/tmp.data % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 2048M 100 2048M 0 0 39.5M 0 0:00:51 0:00:51 --:--:-- 143M 示例2 12345678# 其中 nginx-1.14.2.tar.gz 的绝对路径是：/tmp/nginx-1.14.2.tar.gz ；ftp1 账号的家目录是：/mnt/ftp1# 说明：/../../tmp/nginx-1.14.2.tar.gz 这个路径是针对 ftp1 账号的家目录而言的[yun@nginx_proxy01 20190715]$ curl -O ftp://ftp1:123456@172.16.1.195:21/../../tmp/nginx-1.14.2.tar.gz # 或者[yun@nginx_proxy01 20190715]$ curl -O -u ftp1:123456 ftp://172.16.1.195:21/../../tmp/nginx-1.14.2.tar.gz % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 991k 100 991k 0 0 5910k 0 --:--:-- --:--:-- --:--:-- 5937k 文件上传FTP文件上传可以通过 -T, --upload-file &lt;file&gt; 选项实现。 说明1：其中 ftp1 用户是ftp服务端的账号，具体家目录是：/mnt/ftp1 123456789# 其中 tmp_client.data 是客户端本地文件； # /tmpdata/ 这个路径是针对 ftp1 账号的家目录而言的，且上传时该目录必须是存在的，否则上传失败。# 因此上传后文件在ftp服务端的绝对路径是：/mnt/ftp1/tmpdata/tmp_client.data[yun@nginx_proxy01 20190715]$ curl -T tmp_client.data ftp://ftp1:123456@172.16.1.195:21/tmpdata/# 或者[yun@nginx_proxy01 20190715]$ curl -T tmp_client.data -u ftp1:123456 ftp://172.16.1.195:21/tmpdata/ % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 2048M 0 0 100 2048M 0 95.4M 0:00:21 0:00:21 --:--:-- 49.3M 断点续传使用 -C, --continue-at &lt;offset&gt; 选项实现。其中使用 “-C -“「注意有空格和无空格的情况」，告诉curl自动找出在哪里/如何恢复传输。 网页端断点续传下载1curl -C - -o tmp.data http://www.zhangblog.com/uploads/tmp/tmp.data # 下载一个 2G 的文件 FTP断点续传下载细节就不多说了，可参见上面的「FTP文件下载」 123curl -C - -o tmp.data1 ftp://ftp1:123456@172.16.1.195:21/tmpdata/tmp.data # 下载一个 2G 的文件# 或则curl -C - -o tmp.data1 -u ftp1:123456 ftp://172.16.1.195:21/tmpdata/tmp.data # 下载一个 2G 的文件 分段下载有时文件比较大，或者难以迅速传输，而利用分段传输，可以实现稳定、高效并且有保障的传输，更具有实用性，同时容易对差错文件进行更正。 可使用 -r, --range &lt;range&gt; 选项实现。 如下示例使用了同一张图片，大小为 18196 字节。 网页端分段下载分段下载 1234567891011121314[root@iZ28xbsfvc4Z 20190715]# curl -I http://www.zhangblog.com/uploads/hexo/00.jpg # 查看文件大小HTTP/1.1 200 OKServer: nginx/1.14.2Date: Mon, 15 Jul 2019 03:23:44 GMTContent-Type: image/jpegContent-Length: 18196 # 文件大小Last-Modified: Fri, 05 Jul 2019 08:04:58 GMTConnection: keep-aliveETag: &quot;5d1f04aa-4714&quot;Accept-Ranges: bytes### 分段下载一个文件[root@iZ28xbsfvc4Z 20190715]# curl -r 0-499 -o 00-jpg.part1 http://www.zhangblog.com/uploads/hexo/00.jpg[root@iZ28xbsfvc4Z 20190715]# curl -r 500-999 -o 00-jpg.part2 http://www.zhangblog.com/uploads/hexo/00.jpg[root@iZ28xbsfvc4Z 20190715]# curl -r 1000- -o 00-jpg.part3 http://www.zhangblog.com/uploads/hexo/00.jpg 查看下载文件 12345[root@iZ28xbsfvc4Z 20190715]# lltotal 36-rw-r--r-- 1 root root 500 Jul 15 11:25 00-jpg.part1-rw-r--r-- 1 root root 500 Jul 15 11:25 00-jpg.part2-rw-r--r-- 1 root root 17196 Jul 15 11:26 00-jpg.part3 文件合并 1234[root@iZ28xbsfvc4Z 20190715]# cat 00-jpg.part1 00-jpg.part2 00-jpg.part3 &gt; 00.jpg[root@iZ28xbsfvc4Z 20190715]# ll 00.jpgtotal 56-rw-r--r-- 1 root root 18196 Jul 15 11:29 00.jpg FTP分段下载分段下载 123[yun@nginx_proxy01 20190715]$ curl -r 0-499 -o 00-jpg.part1 ftp://ftp1:123456@172.16.1.195:21/tmpdata/00.jpg[yun@nginx_proxy01 20190715]$ curl -r 500-999 -o 00-jpg.part2 ftp://ftp1:123456@172.16.1.195:21/tmpdata/00.jpg[yun@nginx_proxy01 20190715]$ curl -r 1000- -o 00-jpg.part3 ftp://ftp1:123456@172.16.1.195:21/tmpdata/00.jpg 查看下载文件 1234[yun@nginx_proxy01 20190715]$ ll 00-jpg.part*-rw-rw-r-- 1 yun yun 500 Jul 15 17:59 00-jpg.part1-rw-rw-r-- 1 yun yun 500 Jul 15 18:00 00-jpg.part2-rw-rw-r-- 1 yun yun 17196 Jul 15 18:00 00-jpg.part3 文件合并 123[yun@nginx_proxy01 20190715]$ cat 00-jpg.part1 00-jpg.part2 00-jpg.part3 &gt; 00.jpg[yun@nginx_proxy01 20190715]$ ll 00.jpg -rw-rw-r-- 1 yun yun 18196 Jul 15 18:02 00.jpg 推荐阅读Linux curl 命令详解 Linux curl 常用示例 Linux curl 表单登录或提交与cookie使用]]></content>
      <categories>
        <category>curl</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux curl 命令详解]]></title>
    <url>%2F2019%2F07%2F16%2Fcurl01%2F</url>
    <content type="text"><![CDATA[命令概要该命令设计用于在没有用户交互的情况下工作。 curl 是一个工具，用于传输来自服务器或者到服务器的数据。「向服务器传输数据或者获取来自服务器的数据」 可支持的协议有（DICT、FILE、FTP、FTPS、GOPHER、HTTP、HTTPS、IMAP、IMAPS、LDAP、LDAPS、POP3、POP3S、RTMP、RTSP、SCP、SFTP、SMTP、SMTPS、TELNET和TFTP）。 curl提供了大量有用的技巧，比如代理支持、用户身份验证、FTP上传、HTTP post、SSL连接、cookie、文件断点续传、Metalink等等。正如你将在下面看到的，这些特性的数量会让您头晕目眩！ 访问的URL你可以在命令行上指定任意数量的url。它们将按指定的顺序依次获取。 你可以指定多个url，或url的部分通过在花括号内编写部分集，如： 123http://site.&#123;one,two,three&#125;.com# 参见curl http://www.zhangblog.com/2019/06/16/hexo&#123;04,05,06&#125;/ -I # 查看信息 或者可以使用[]得到字母数字序列的序列，如： 12345ftp://ftp.numericals.com/file[1-100].txtftp://ftp.numericals.com/file[001-100].txt # 前导用零ftp://ftp.letters.com/file[a-z].txt # 参见curl http://www.zhangblog.com/2019/06/16/hexo[04-06]/ -I # 查看信息 不支持嵌套序列，但可以使用几个相邻的序列： 1http://any.org/archive[1996-1999]/vol[1-4]/part&#123;a,b,c&#125;.html 你可以指定一个步长计数器的范围，以获得每第n个数字或字母： 12http://www.numericals.com/file[1-100:10].txt http://www.letters.com/file[a-z:2].txt 如果指定URL而没有protocol:// prefix，默认为HTTP。 常用选项一curl通常在操作过程中显示一个进度表，显示传输的数据量、传输速度和估计的剩余时间等。 -#, --progress-bar将curl进度显示为一个简单的进度条；而不是标准的、具有更多信息的进度表。 1234567[root@iZ28xbsfvc4Z 20190702]# curl -O http://www.zhangblog.com/2019/06/16/hexo04/index.html # 默认的进度表 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 97299 100 97299 0 0 186k 0 --:--:-- --:--:-- --:--:-- 186k[root@iZ28xbsfvc4Z 20190702]# [root@iZ28xbsfvc4Z 20190702]# curl -# -O http://www.zhangblog.com/2019/06/16/hexo04/index.html #简单的进度条######################################################################## 100.0% -0, --http1.0(HTTP)强制curl使用HTTP 1.0发出请求，而不是使用其内部首选的HTTP 1.1。 -1, --tlsv1(SSL)强制curl使用TLS 1.x 版本，当与远程TLS服务进行协商时。可以使用选项 --tlsv1.0、--tlsv1.1和 --tlsv1.2来更精确地控制TLS版本(如果使用的SSL后端支持这种级别的控制)。 -2, --sslv2(SSL)强制curl使用TLS 2 版本，当与远程TLS服务进行协商时。 -3, --sslv3(SSL)强制curl使用TLS 3 版本，当与远程TLS服务进行协商时。 -4, --ipv4如果curl能够将一个地址解析为多个IP版本(比如它支持ipv4和ipv6)，那么这个选项告诉curl只将名称解析为IPv4地址。 -6, --ipv6如果curl能够将一个地址解析为多个IP版本(比如它支持ipv4和ipv6)，那么这个选项告诉curl只将名称解析为IPv6地址。 -a, --append(FTP/SFTP)当在上传中使用时，这将告诉curl追加到目标文件而不是覆盖它。如果文件不存在，将创建它。注意，一些SSH服务器(包括OpenSSH)会忽略此标志。 -A, --user-agent &lt;agent string&gt;(HTTP)指定要发送到HTTP服务端的User-Agent字符串。当然也可以使用 -H, --header 选项来设置。用于模拟客户端，如：谷歌浏览器、火狐浏览器、IE 浏览器等等。 如果多次使用此选项，则将使用最后一个选项。 模仿浏览器访问 1curl -A &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/75.0.3770.999&quot; http://www.zhangblog.com/2019/06/24/domainexpire/ --basic(HTTP)告诉curl使用HTTP基本身份验证。这是默认的。 常用选项二-b, --cookie &lt;name=data&gt;(HTTP)将数据作为cookie传递给HTTP服务器。它应该是之前从服务端接收到的“Set-Cookie:”行中的数据。数据格式为“NAME1=VALUE1;NAME2 = VALUE2”。 如果行中没有使用 ‘=’ 符号，则将其视为一个文件名，用于读取先前存储的cookie行，如果它们匹配，则应在此会话中使用。要读取cookie文件的文件格式应该是纯HTTP头文件或Netscape/Mozilla cookie文件格式。 注意：使用 -b, --cookie 指定的文件仅用作输入。文件中不会存储cookies。要存储cookies，可以使用 -c, --cookie-jar 选项，或者您甚至可以使用 -D, --dump-header 将HTTP头保存到文件中。 -c, --cookie-jar &lt;file name&gt;(HTTP)指定希望curl在完成操作后将所有cookie写入哪个文件。Curl写之前从指定文件读取的所有cookie，以及从远程服务端接收的所有cookie。如果没有已知的cookie，则不会写入任何文件。该文件将使用Netscape cookie文件格式编写。如果你将文件名设置为单个破折号 “-” ，cookie将被标准输出。 该命令行选项将激活cookie引擎，使curl记录并使用cookies。激活它的另一种方法是使用 -b, --cookie 选项。 如果不能创建或写入cookie jar，那么整个curl操作就不会失败，甚至不能清楚地报告错误。使用 -v 会得到一个警告，但这是你得到的关于这种可能致命的情况的唯一可见反馈。 如果多次使用此选项，将使用最后指定的文件名。 --connect-timeout &lt;seconds&gt;连接服务端的超时时间。这只限制了连接阶段，一旦curl连接了此选项就不再使用了。 也可参见：-m, --max-time 选项。 123456# 当前 https://www.zhangXX.com 是国外服务器，访问受限[root@iZ28xbsfvc4Z ~]# curl --connect-timeout 10 https://www.zhangXX.com | head % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- 0:00:10 --:--:-- 0curl: (28) Connection timed out after 10001 milliseconds --create-dirs当与 -o 选项一起使用时，curl将根据需要创建必要的本地目录层次结构。 这个选项只创建与 -o 选项相关的dirs，没有其他内容。如果 -o 文件名没有使用dir，或者其中提到的dir已经存在，则不会创建dir。 示例 1curl -o ./hexo04/index.html --create-dirs http://www.zhangblog.com/2019/06/16/hexo04 -C, --continue-at &lt;offset&gt;按给定偏移量继续/恢复以前的文件传输。给定的偏移量是将被跳过的确切字节数，从源文件的开头开始计算，然后再将其传输到目标文件。 使用 “-C -“「注意有空格和无空格的情况」，告诉curl自动找出在哪里/如何恢复传输。然后，它使用给定的输出/输入文件来解决这个问题。 12# 下载一个 2G 的文件，可以反复测试，查看结果curl -C - -o tmp.data http://www.zhangblog.com/uploads/tmp/tmp.data -d, --data &lt;data&gt;使用该选项，那么默认请求方式为 POST。(HTTP)在POST请求中向HTTP服务器发送指定的数据，与浏览器在用户填写HTML表单并按下submit按钮时所做的相同。这将导致curl使用content-type application/x-www-form-urlencoded将数据传递给服务器。也可参见：-F，-form 。 如果这些命令在同一个命令行使用多次，这些数据片段将使用指定的分隔符 &amp; 合并。因此，使用 ‘-d name=daniel -d skill=lousy’ 将生成一个类似 ‘name=daniel&amp;skill=lousy’ 的post块，也可以直接这样合并使用。 -d, --data 与 --data-ascii 相同。post数据为纯粹的二进制数据时，那么使用 --data-binary 选项。要对表单字段的值进行url编码，可以使用 --data-urlencode。 如果您以字母@开始数据，那么其余的应该是一个文件名，以便从其中读取数据。或者 - 如果您希望curl从stdin【标准输入】读取数据。文件的内容必须已经是url编码的。还可以指定多个文件。因此，Posting数据名为 “foobar” 的文件将使用 --data @foobar 完成。 示例 请求信息: 123456789101112131415161718192021222324[root@iZ28xbsfvc4Z 20190712]# curl -sv --local-port 9000 -d &apos;user=zhang&amp;pwd=123456&apos; http://www.zhangblog.com/2019/06/24/domainexpire/ | head -n1 * About to connect() to www.zhangblog.com port 80 (#0)* Trying 120.27.48.179...* Local port: 9000* Connected to www.zhangblog.com (120.27.48.179) port 80 (#0)&gt; POST /2019/06/24/domainexpire/ HTTP/1.1 # 可见请求方式为POST&gt; User-Agent: curl/7.29.0&gt; Host: www.zhangblog.com&gt; Accept: */*&gt; Content-Length: 21&gt; Content-Type: application/x-www-form-urlencoded&gt; &#125; [data not shown]* upload completely sent off: 21 out of 21 bytes&lt; HTTP/1.1 405 Not Allowed&lt; Server: nginx/1.14.2&lt; Date: Fri, 12 Jul 2019 13:34:20 GMT&lt; Content-Type: text/html&lt; Content-Length: 173&lt; Connection: keep-alive&lt; &#123; [data not shown]* Connection #0 to host www.zhangblog.com left intact&lt;html&gt; 抓包信息 1[root@iZ28xbsfvc4Z tcpdump]# tcpdump -i any port 9000 -A -s 0 --data-ascii &lt;data&gt;参见 -d, --data --data-binary &lt;data&gt;(HTTP) POST数据完全按照指定的方式，没有任何额外的处理。 如果您以字母@开始数据，其余的应该是文件名。数据是以类似于 --data-ascii 的方式发布的，只不过保留了换行，而且永远不会进行转换【数据不转换】。 如果多次使用此选项，第一个选项后面的选项将按照 -d, --data 中的描述追加数据。 --data-urlencode &lt;data&gt;(HTTP)这个Post 数据，与另一个 --data 选项类似，除执行url编码以外。 -D, --dump-header &lt;file&gt;将响应协议头写入指定的文件。 如果多次使用此选项，则将使用最后一个选项。 当你想要存储HTTP站点发送给你的头文件时，使用此选项非常方便。 12345[root@iZ28xbsfvc4Z 20190703]# curl -D baidu_header.info www.baidu.com ………………[root@iZ28xbsfvc4Z 20190703]# lltotal 4-rw-r--r-- 1 root root 400 Jul 3 10:11 baidu_header.info # 生成的头文件 之后第二次curl调用通过 -b, --cookie 选项，可以从头部读取 cookies 。然而 -c, --cookie-jar 选项是存储 cookies 更好的方法。 常用选项三--digest(HTTP)启用HTTP摘要身份验证。这是一种身份验证方案，可以防止密码以明文通过网络发送。将此选项与普通的 -u, --user 选项组合使用，以设置用户名和密码。相关选项请参见 --ntlm, --negotiate 和 --anyauth。 如果多次使用此选项，则只使用第一个选项。 -e, --referer &lt;URL&gt;(HTTP)将 “Referer Page” 【从哪个页面跳转过来的】信息发送到HTTP服务器。当然也可以使用 -H, --header 标志来设置。 如果多次使用此选项，则将使用最后一个选项。 1curl -e &apos;https:www.baidu.com&apos; http://www.zhangblog.com/2019/06/24/domainexpire/ -f, --fail(HTTP)在服务器错误上静默失败(完全没有输出)。这主要是为了使脚本等更好地处理失败的尝试。 在通常情况下，当HTTP服务器无法交付文档时，它会返回一个HTML文档，说明原因(通常还会描述原因)。此标志将阻止curl输出该值并返回错误22。 12345678910[root@iZ28xbsfvc4Z 20190713]# curl http://www.zhangblog.com/201912312&lt;html&gt;&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=&quot;white&quot;&gt;&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx/1.14.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;[root@iZ28xbsfvc4Z 20190713]# curl -f http://www.zhangblog.com/201912312curl: (22) The requested URL returned error: 404 Not Found -F, --form &lt;name=content&gt;(HTTP)这允许curl模拟用户按下submit按钮后填充的表单。 该情况让curl 可使用Content-Type multipart/form-data POST数据。也可以上传二进制文件等。 @文件名：使一个文件作为文件上传附加在post中。&lt;文件名：从文件中获取该文本字段的内容。 例如，要将密码文件发送到服务器，其中“password”是表单字段的名称，/etc/passwd将作为输入: 1curl -F password=@/etc/passwd www.mypasswords.com 您还可以使用 ‘type=’ 告诉curl使用什么 Content-Type ，方法类似于： 123curl -F &quot;web=@index.html;type=text/html&quot; url.com或curl -F &quot;name=daniel;type=text/foo&quot; url.com 可以通过设置 filename= 更改本地上传的文件名，如下： 1curl -F &quot;file=@localfile;filename=nameinpost&quot; url.com 上传的文件名从改为了 nameinpost 如果文件名/路径包括 ‘,’ 或 ‘;’ ，必须用双引号括起来： 123curl -F &quot;file=@\&quot;localfile\&quot;;filename=\&quot;nameinpost\&quot;&quot; url.com或curl -F &apos;file=@&quot;localfile&quot;;filename=&quot;nameinpost&quot;&apos; url.com 最外层可用单引号或双引号。 这个选项可以多次使用。 请勿如下使用 1curl -F &apos;user=zhang&amp;password=pwd&apos; url.com # 这种用法是错误的 --form-string &lt;name=string&gt;(HTTP)类似于 --form，只是命名参数的value字符串按字面意思使用。在值中以 ‘@’ 和 ‘&lt;’ 开头的字符，以及 ‘;type=’ 字符串没有特殊的含义。 如果字符串值有可能意外触发 --form 的 “@” 或 “&lt;” 特性，请优先使用此选项。 -g, --globoff这个选项关闭了“URL全局解析器”。当您设置这个选项时，您可以指定包含字母 {}[] 的url，而不需要curl本身来解释它们。 注意，这些字母不是正常的合法URL内容，但是它们应该按照URI标准进行编码。 -G, --get使用此选项时，将使所有使用 -d, --data 或 --data-binary 指定的数据在HTTP GET请求中使用，而不是在POST请求中使用。数据将被追加到URL的一个 ‘?’ 的分隔符后。 如果与 -I 结合使用，POST数据将被替换追加到带有HEAD请求的URL中。 如果多次使用此选项，则只使用第一个选项。 示例 12345678910111213141516171819202122232425[root@iZ28xbsfvc4Z 20190712]# curl -sv -G --local-port 9000 -d &apos;user=zhang&amp;pwd=123456&apos; http://www.zhangblog.com/2019/06/24/domainexpire/ | head -n1 或则[root@iZ28xbsfvc4Z 20190713]# curl -sv --local-port 9000 &quot;http://www.zhangblog.com/2019/06/24/domainexpire/?user=zhang&amp;pwd=123456&quot; | head -n1* About to connect() to www.zhangblog.com port 80 (#0)* Trying 120.27.48.179...* Local port: 9000* Connected to www.zhangblog.com (120.27.48.179) port 80 (#0)&gt; GET /2019/06/24/domainexpire/?user=zhang&amp;pwd=123456 HTTP/1.1 # 可见请求方式为 GET，且参数追加到了URI后&gt; User-Agent: curl/7.29.0&gt; Host: www.zhangblog.com&gt; Accept: */*&gt; &lt; HTTP/1.1 200 OK&lt; Server: nginx/1.14.2&lt; Date: Fri, 12 Jul 2019 14:04:19 GMT&lt; Content-Type: text/html&lt; Content-Length: 51385&lt; Last-Modified: Tue, 09 Jul 2019 13:55:19 GMT&lt; Connection: keep-alive&lt; ETag: &quot;5d249cc7-c8b9&quot;&lt; Accept-Ranges: bytes&lt; &#123; [data not shown]* Connection #0 to host www.zhangblog.com left intact&lt;!DOCTYPE html&gt; 抓包信息 1[root@iZ28xbsfvc4Z tcpdump]# tcpdump -i any port 9000 -A -s 0 -H, --header &lt;header&gt;(HTTP) 要发送到服务端的自定义请求头。 此选项可多次用于添加/替换/删除多个headers。 1curl -H &apos;Connection: keep-alive&apos; -H &apos;Referer: https://sina.com.cn&apos; -H &apos;User-Agent: Mozilla/1.0&apos; http://www.zhangblog.com/2019/06/24/domainexpire/ --ignore-content-length(HTTP)忽略Content-Length 头信息。 -i, --include(HTTP)在输出的内容中包含HTTP 头信息。 1curl -i https://www.baidu.com -I, --head(HTTP/FTP/FILE)只获取HTTP头文件。在FTP或FILE 文件上使用时，curl只显示文件大小和最后修改时间。 1curl -I https://www.baidu.com -k, --insecure(SSL)允许curl执行不安全的SSL连接和传输。所有SSL连接都尝试使用默认安装的CA证书包来确保安全。 示例 1234567891011[root@iZ28xbsfvc4Z ~]# curl https://140.205.16.113/ # 被拒绝curl: (51) Unable to communicate securely with peer: requested domain name does not match the server&apos;s certificate.[root@iZ28xbsfvc4Z ~]# [root@iZ28xbsfvc4Z ~]# curl -k https://140.205.16.113/ # 允许执行不安全的证书连接&lt;!DOCTYPE HTML PUBLIC &quot;-//IETF//DTD HTML 2.0//EN&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=&quot;white&quot;&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;p&gt;You don&apos;t have permission to access the URL on this server.&lt;hr/&gt;Powered by Tengine&lt;/body&gt;&lt;/html&gt; 常用选项四--keepalive-time &lt;seconds&gt;keepalive 时长。如果使用no-keepalive，则此选项无效。 如果多次使用此选项，则将使用最后一个选项。如果未指定，该选项默认为60秒。 --key &lt;key&gt;(SSL/SSH)私钥文件名。允许你在这个单独的文件中提供你的私钥。 对于SSH，如果没有指定，curl尝试如下顺序：’~/.ssh/id_rsa’，’~/.ssh/id_dsa’，’./id_rsa’，’./id_dsa’。 如果多次使用此选项，则将使用最后一个选项。 --key-type &lt;type&gt;(SSL)私钥文件类型。指定 --key 提供的私钥的类型。支持DER、PEM和ENG。如果没有指定，则定为PEM。 如果多次使用此选项，则将使用最后一个选项。 -L, --location(HTTP/HTTPS) 跟踪重定向如果服务器报告请求页面已移动到另一个位置(用location: header和3XX响应代码表示)，此选项将使curl在新位置上重做请求。 如果与 -i, --include 或 -I, --head 一起使用，将显示所有请求页面的标题。 1234567891011121314151617181920[root@iZ28xbsfvc4Z ~]# curl -I -L https://baidu.com/ HTTP/1.1 302 Moved Temporarily # 302 重定向Server: bfe/1.0.8.18Date: Thu, 04 Jul 2019 03:07:15 GMTContent-Type: text/htmlContent-Length: 161Connection: keep-aliveLocation: http://www.baidu.com/HTTP/1.1 200 OKAccept-Ranges: bytesCache-Control: private, no-cache, no-store, proxy-revalidate, no-transformConnection: Keep-AliveContent-Length: 277Content-Type: text/htmlDate: Thu, 04 Jul 2019 03:07:15 GMTEtag: &quot;575e1f60-115&quot;Last-Modified: Mon, 13 Jun 2016 02:50:08 GMTPragma: no-cacheServer: bfe/1.0.8.18 --limit-rate &lt;speed&gt;指定要使用curl的最大传输速率。 如果有一个有限的管道，并且希望传输不要使用您的全部带宽，那么这个特性是非常有用的。 12curl --limit-rate 500 http://www.baidu.com/curl --limit-rate 2k http://www.baidu.com/ 单位：默认字节，除非添加后缀。附加 “k” 或 “K” 表示千字节， “m” 或 “M” 表示兆字节，而 “g” 或 “G” 表示千兆字节。例如:200K, 3m和1G。 给定的速率是整个传输过程中计算的平均速度。这意味着curl可能在短时间内使用更高的传输速度，但是随着时间的推移，它只使用给定的速率。 如果多次使用此选项，则将使用最后一个选项。 --local-port &lt;num&gt;[-num]指定本地的一个端口或端口范围去连接。 请注意，端口号本质上是一种稀缺资源，有时会很忙，因此将此范围设置为太窄可能会导致不必要的连接失败。 12curl --local-port 9000 http://www.baidu.com/curl --local-port 9000-9999 http://www.baidu.com/ -m, --max-time &lt;seconds&gt;允许整个操作花费的最大时间(以秒为单位)。 这对于防止由于网络或链接变慢而导致批处理作业挂起数小时非常有用。 也可参见：--connect-timeout 选项 12345678910111213[root@iZ28xbsfvc4Z ~]# curl -m 10 --limit-rate 5 http://www.baidu.com/ | head # 超过10秒后，断开连接 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 2 2381 2 50 0 0 4 0 0:09:55 0:00:10 0:09:45 4curl: (28) Operation timed out after 10103 milliseconds with 50 out of 2381 bytes received&lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;met### 或[root@iZ28xbsfvc4Z ~]# curl -m 10 https://www.zhangXX.com | head # 超过10秒后，断开连接 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- 0:00:10 --:--:-- 0curl: (28) Connection timed out after 10001 milliseconds --max-filesize &lt;bytes&gt;指定要下载的文件的最大大小(以字节为单位)。如果请求的文件大于这个值，那么传输将不会启动，curl将返回退出代码63。 示例 123456789101112131415161718192021222324[root@iZ28xbsfvc4Z ~]# curl -I http://www.zhangblog.com/uploads/hexo/00.jpg # 正常HTTP/1.1 200 OKServer: nginx/1.14.2Date: Thu, 04 Jul 2019 07:24:24 GMTContent-Type: image/jpegContent-Length: 18196Last-Modified: Mon, 24 Jun 2019 01:43:02 GMTConnection: keep-aliveETag: &quot;5d102aa6-4714&quot;Accept-Ranges: bytes[root@iZ28xbsfvc4Z ~]# echo $?0[root@iZ28xbsfvc4Z ~]# [root@iZ28xbsfvc4Z ~]# [root@iZ28xbsfvc4Z ~]# curl --max-filesize 1000 -I http://www.zhangblog.com/uploads/hexo/00.jpg # 受限异常HTTP/1.1 200 OKServer: nginx/1.14.2Date: Thu, 04 Jul 2019 07:24:54 GMTContent-Type: image/jpegcurl: (63) Maximum file size exceeded[root@iZ28xbsfvc4Z ~]# [root@iZ28xbsfvc4Z ~]# echo $?63 --max-redirs &lt;num&gt;设置允许的最大重定向跟踪数。 如果也使用了 -L, --location，则此选项可用于防止curl在悖论中无限重定向。默认情况下，限制为50重定向。将此选项设置为-1，使其无限。 --no-keepalive禁用在TCP连接上使用keepalive消息，因为默认情况下curl启用了它们。 注意，这是文档中已否定的选项名。因此，您可以使用 --keepalive 来强制keepalive。 常用选项五-o, --output &lt;file&gt;输出到一个文件，而不是标准输出。 如果使用 {} 或 [] 来获取多个documents。可以使用 ‘#’ 后跟说明符中的一个数字。该变量将替换为正在获取URL的当前字符串。就像： 12curl http://&#123;one,two&#125;.site.com -o &quot;file_#1.txt&quot;curl http://&#123;site,host&#125;.host[1-5].com -o &quot;#1_#2&quot; 示例1 12345678910111213141516171819[root@iZ28xbsfvc4Z 20190703]# curl &quot;http://www.zhangblog.com/2019/06/16/hexo&#123;04,05,06&#125;/&quot; -o &quot;file_#1.info&quot; # 注意curl 的地址需要用引号括起来或[root@iZ28xbsfvc4Z 20190703]# curl &quot;http://www.zhangblog.com/2019/06/16/hexo[04-06]/&quot; -o &quot;file_#1.info&quot; # 注意curl 的地址需要用引号括起来[1/3]: http://www.zhangblog.com/2019/06/16/hexo04/ --&gt; file_04.info % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 97299 100 97299 0 0 1551k 0 --:--:-- --:--:-- --:--:-- 1557k[2/3]: http://www.zhangblog.com/2019/06/16/hexo05/ --&gt; file_05.info100 54409 100 54409 0 0 172M 0 --:--:-- --:--:-- --:--:-- 172M[3/3]: http://www.zhangblog.com/2019/06/16/hexo06/ --&gt; file_06.info100 56608 100 56608 0 0 230M 0 --:--:-- --:--:-- --:--:-- 230M[root@iZ28xbsfvc4Z 20190703]# [root@iZ28xbsfvc4Z 20190703]# lltotal 212-rw-r--r-- 1 root root 97299 Jul 4 16:51 file_04.info-rw-r--r-- 1 root root 54409 Jul 4 16:51 file_05.info-rw-r--r-- 1 root root 56608 Jul 4 16:51 file_06.info 示例2 12345678910111213[root@iZ28xbsfvc4Z 20190703]# curl &quot;http://www.&#123;baidu,douban&#125;.com&quot; -o &quot;site_#1.txt&quot; # 注意curl 的地址需要用引号括起来[1/2]: http://www.baidu.com --&gt; site_baidu.txt % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 2381 100 2381 0 0 46045 0 --:--:-- --:--:-- --:--:-- 46686[2/2]: http://www.douban.com --&gt; site_douban.txt100 162 100 162 0 0 3173 0 --:--:-- --:--:-- --:--:-- 3173[root@iZ28xbsfvc4Z 20190703]# [root@iZ28xbsfvc4Z 20190703]# lltotal 220-rw-r--r-- 1 root root 2381 Jul 4 16:53 site_baidu.txt-rw-r--r-- 1 root root 162 Jul 4 16:53 site_douban.txt -O, --remote-name写入到本地文件，名称与远程文件的名称相同。(只使用远程文件的文件部分，路径被切断。) 用于保存的远程文件名是从给定的URL中提取的，没有其他内容。因此，文件将保存在当前工作目录中。如果希望将文件保存在另一个目录中，请确保在curl调用 -O, --remote-name之前更改当前工作目录! 1234567[root@iZ28xbsfvc4Z 20190712]# curl -O https://www.baidu.com # 使用了 -O 选项，必须指定到具体的文件 错误使用curl: Remote file name has no length!curl: try &apos;curl --help&apos; or &apos;curl --manual&apos; for more information[root@iZ28xbsfvc4Z 20190712]# curl -O https://www.baidu.com/index.html # 使用了 -O 选项，必须指定到具体的文件 正确使用 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 2443 100 2443 0 0 13289 0 --:--:-- --:--:-- --:--:-- 13349 --pass &lt;phrase&gt;(SSL/SSH)私钥密码 如果多次使用此选项，则将使用最后一个选项。 --post301告诉curl当301重定向时，不要将POST请求转换为GET请求。 非rfc行为在web浏览器中无处不在，因此curl在缺省情况下进行转换以保持一致性。但是，服务器可能需要在重定向之后将POST保留为POST。 这个选项只有在使用 -L, --location 时才有意义 --post302告诉curl当302重定向时，不要将POST请求转换为GET请求。 非rfc行为在web浏览器中无处不在，因此curl在缺省情况下进行转换以保持一致性。但是，服务器可能需要在重定向之后将POST保留为POST。 这个选项只有在使用 -L, --location 时才有意义 --post303告诉curl当303重定向时，不要将POST请求转换为GET请求。 非rfc行为在web浏览器中无处不在，因此curl在缺省情况下进行转换以保持一致性。但是，服务器可能需要在重定向之后将POST保留为POST。 这个选项只有在使用 -L, --location 时才有意义 说明：上述三个选项都是为了防止在重定向过程中，原来的 POST 请求，变为 GET请求。为了防止该情况，有两种处理方式。1、使用上述选项可避免；2、使用 -X POST 选项和命令。 示例 1[root@iZ28xbsfvc4Z ~]# curl -Lsv -d &apos;user=zhang&apos; https://baidu.com | head -n1 开始是POST请求，302 重定向后变为了 GET请求。 1[root@iZ28xbsfvc4Z ~]# curl -Lsv -d &apos;user=zhang&apos; --post301 --post302 --post303 https://baidu.com | head -n1 前后都是 POST 请求。但是选项较多。 1[root@iZ28xbsfvc4Z ~]# curl -Lsv -d &apos;user=zhang&apos; -X POST https://baidu.com | head -n1 前后都是 POST 请求。推荐使用此命令。 --pubkey &lt;key&gt;(SSH)公钥文件名。允许在这个单独的文件中提供公钥。 如果多次使用此选项，则将使用最后一个选项。 -r, --range &lt;range&gt;(HTTP/FTP/SFTP/FILE)从HTTP/1.1、FTP或SFTP服务器或本地文件检索字节范围。范围可以通过多种方式指定。用于分段下载。 有时文件比较大，或者难以迅速传输，而利用分段传输，可以实现稳定、高效并且有保障的传输，更具有实用性，同时容易对差错文件进行更正。 0-499：指定前500个字节500-999：指定第二个500字节-500：指定最后500个字节9500-：指定9500字节及之后的字节0-0,-1：指定第一个和最后一个字节500-700,600-799：从偏移量500开始指定300字节100-199,500-599：指定两个单独100字节的范围 分段下载 12345678910111213[root@iZ28xbsfvc4Z 20190715]# curl -I http://www.zhangblog.com/uploads/hexo/00.jpg # 查看文件大小HTTP/1.1 200 OKServer: nginx/1.14.2Date: Mon, 15 Jul 2019 03:23:44 GMTContent-Type: image/jpegContent-Length: 18196 # 文件大小Last-Modified: Fri, 05 Jul 2019 08:04:58 GMTConnection: keep-aliveETag: &quot;5d1f04aa-4714&quot;Accept-Ranges: bytes[root@iZ28xbsfvc4Z 20190715]# curl -r 0-499 -o 00-jpg.part1 http://www.zhangblog.com/uploads/hexo/00.jpg[root@iZ28xbsfvc4Z 20190715]# curl -r 500-999 -o 00-jpg.part2 http://www.zhangblog.com/uploads/hexo/00.jpg[root@iZ28xbsfvc4Z 20190715]# curl -r 1000- -o 00-jpg.part3 http://www.zhangblog.com/uploads/hexo/00.jpg 查看下载文件 12345[root@iZ28xbsfvc4Z 20190715]# lltotal 36-rw-r--r-- 1 root root 500 Jul 15 11:25 00-jpg.part1-rw-r--r-- 1 root root 500 Jul 15 11:25 00-jpg.part2-rw-r--r-- 1 root root 17196 Jul 15 11:26 00-jpg.part3 文件合并 1234[root@iZ28xbsfvc4Z 20190715]# cat 00-jpg.part1 00-jpg.part2 00-jpg.part3 &gt; 00.jpg[root@iZ28xbsfvc4Z 20190715]# lltotal 56-rw-r--r-- 1 root root 18196 Jul 15 11:29 00.jpg -R, --remote-time使curl尝试获取远程文件的时间戳，如果可用，则使本地文件获得相同的时间戳【针对修改时间戳Modify】。 1curl -o nfs1.info -R http://www.zhangblog.com/2019/07/05/nfs1/ --retry &lt;num&gt;传输出现问题时，重试的次数。数字设置为0将使curl不重试(这是缺省值)。 出现的瞬时错误如：timeout、FTP 4xx响应状代码或HTTP 5xx响应状代码。 当curl准备重试传输时，它将首先等待一秒钟，之后对于所有即将到来的重试，它将把等待时间延长一倍，直到达到10分钟，这将是其余重试之间的延迟。 --retry-delay &lt;seconds&gt;传输出现问题时，设置重试间隔时间。将此延迟设置为零将使curl使用默认的延迟时间。 --retry-max-time &lt;seconds&gt;传输出现问题时，设置最大重试时间。将此选项设置为0则不超时重试。 常用选项六-s, --silent静默或静音模式。不显示进度表/条或错误消息。 示例 1234567[root@iZ28xbsfvc4Z 20190713]# curl https://www.baidu.com | head -n1 # 默认有进度表 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 2443 100 2443 0 0 13346 0 --:--:-- --:--:-- --:--:-- 13349&lt;!DOCTYPE html&gt;[root@iZ28xbsfvc4Z 20190713]# curl -s https://www.baidu.com | head -n1&lt;!DOCTYPE html&gt; -S, --show-error当与 -s 一起使用时，如果curl失败，curl将显示一条错误消息。 1234[root@iZ28xbsfvc4Z 20190713]# curl -s https://140.205.16.113/ [root@iZ28xbsfvc4Z 20190713]# [root@iZ28xbsfvc4Z 20190713]# curl -sS https://140.205.16.113/ curl: (51) Unable to communicate securely with peer: requested domain name does not match the server&apos;s certificate. --stderr &lt;file&gt;将错误信息重定向到一个文件。如果文件名是普通的 ‘-‘，则将其写入stdout。 如果多次使用此选项，则将使用最后一个选项。 123456[root@iZ28xbsfvc4Z 20190713]# curl --stderr err.info https://140.205.16.113/ [root@iZ28xbsfvc4Z 20190713]# lltotal 92-rw-r--r-- 1 root root 116 Jul 13 10:19 err.info[root@iZ28xbsfvc4Z 20190713]# cat err.info curl: (51) Unable to communicate securely with peer: requested domain name does not match the server&apos;s certificate. -T, --upload-file &lt;file&gt;这将指定的本地文件传输到远程URL。如果指定的URL中没有文件部分，Curl将附加本地文件名。 注意：必须在最后一个目录上使用尾随 / 来真正证明Curl没有文件名，否则Curl会认为您的最后一个目录名是要使用的远程文件名。这很可能导致上传操作失败。如果在HTTP(S)服务器上使用此命令，则将使用PUT命令。 同时也支持多个文件上传，如下： 123curl -T &quot;&#123;file1,file2&#125;&quot; http://www.uploadtothissite.com或则curl -T &quot;img[1-1000].png&quot; ftp://ftp.picturemania.com/upload/ --trace &lt;file&gt;对指定文件进行debug。包括所有传入和传出数据。 此选项会覆盖之前使用的 -v、--verbose或 --trace-ascii。 如果多次使用此选项，则将使用最后一个选项。 1curl --trace trace.info https://www.baidu.com --trace-ascii &lt;file&gt;对指定文件进行debug。包括所有传入和传出数据。 这非常类似于 --trace，但是省略了十六进制部分，只显示转储的ASCII部分。使它输出更小，对于我们来说可能更容易阅读。 此选项会覆盖之前使用的 -v、--verbose或 --trace。 如果多次使用此选项，则将使用最后一个选项。 1curl --trace-ascii trace2.info https://www.baidu.com --trace-time为curl显示的每个跟踪或冗长的行添加时间戳。 1curl --trace-ascii trace3.info --trace-time https://www.baidu.com -v, --verbose显示详细操作信息。主要用于调试。 以 &gt; 开头的行表示curl发送的”header data”；&lt; 表示curl接收到的通常情况下隐藏的”header data”；而以 * 开头的行表示curl提供的附加信息。 12345678910111213141516171819202122232425262728293031323334[root@iZ28xbsfvc4Z 20190712]# curl -v https://www.baidu.com* About to connect() to www.baidu.com port 443 (#0)* Trying 180.101.49.12...* Connected to www.baidu.com (180.101.49.12) port 443 (#0)* Initializing NSS with certpath: sql:/etc/pki/nssdb* CAfile: /etc/pki/tls/certs/ca-bundle.crt CApath: none* SSL connection using TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256* Server certificate:* subject: CN=baidu.com,O=&quot;Beijing Baidu Netcom Science Technology Co., Ltd&quot;,OU=service operation department,L=beijing,ST=beijing,C=CN* start date: May 09 01:22:02 2019 GMT* expire date: Jun 25 05:31:02 2020 GMT* common name: baidu.com* issuer: CN=GlobalSign Organization Validation CA - SHA256 - G2,O=GlobalSign nv-sa,C=BE&gt; GET / HTTP/1.1&gt; User-Agent: curl/7.29.0&gt; Host: www.baidu.com&gt; Accept: */*&gt; &lt; HTTP/1.1 200 OK&lt; Accept-Ranges: bytes&lt; Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform&lt; Connection: Keep-Alive&lt; Content-Length: 2443&lt; Content-Type: text/html&lt; Date: Fri, 12 Jul 2019 08:26:23 GMT&lt; Etag: &quot;588603eb-98b&quot;&lt; Last-Modified: Mon, 23 Jan 2017 13:23:55 GMT&lt; Pragma: no-cache&lt; Server: bfe/1.0.8.18&lt; Set-Cookie: BDORZ=27315; max-age=86400; domain=.baidu.com; path=/&lt; &lt;!DOCTYPE html&gt;……………… # curl 网页的具体信息 -w, --write-out &lt;format&gt;在完成和成功操作后要在stdout上显示什么。 支持如下变量，具体含义请自行参见curl文档。 123456789101112131415161718192021222324252627content_typefilename_effectiveftp_entry_pathhttp_codehttp_connectlocal_iplocal_portnum_connectsnum_redirectsredirect_urlremote_ipremote_portsize_downloadsize_headersize_requestsize_uploadspeed_downloadspeed_uploadssl_verify_resulttime_appconnecttime_connecttime_namelookuptime_pretransfertime_redirecttime_starttransfertime_totalurl_effective 示例 1234567[root@iZ28xbsfvc4Z 20190713]# curl -o /dev/null -s -w %&#123;content_type&#125; www.baidu.com # 输出结果没有换行text/html[root@iZ28xbsfvc4Z 20190713]# [root@iZ28xbsfvc4Z 20190713]# curl -o /dev/null -s -w %&#123;http_code&#125; www.baidu.com # 输出结果没有换行200[root@iZ28xbsfvc4Z 20190713]# [root@iZ28xbsfvc4Z 20190713]# curl -o /dev/null -s -w %&#123;local_port&#125; www.baidu.com # 输出结果没有换行37346[root@iZ28xbsfvc4Z 20190713]# [root@iZ28xbsfvc4Z 20190713]# -x, --proxy &lt;[protocol://][user:password@]proxyhost[:port]&gt;使用指定的HTTP代理。如果没有指定端口号，则假定它位于端口1080。 -X, --request &lt;command&gt;(HTTP)指定与HTTP服务器通信时的请求方式。默认GET 1curl -vs -X POST https://www.baidu.com | head -n1 1curl -vs -X PUT https://www.baidu.com | head -n1 推荐阅读Linux curl 命令详解 Linux curl 常用示例 Linux curl 表单登录或提交与cookie使用]]></content>
      <categories>
        <category>curl</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS 服务搭建与配置]]></title>
    <url>%2F2019%2F07%2F05%2Fnfs1%2F</url>
    <content type="text"><![CDATA[本文讲解在 CentOS 5.x、CentOS 6.x 和 CentOS 7.x 环境下，如何安装与部署 NFS 服务。 注意：一台机器不要同时做 NFS 的服务端和 NFS 的客户端。如果同时作了 NFS 的服务端和客户端，那么在关机的时候，会一直夯住，可能十分钟之后甚至更久才能关闭成功。 NFS 工作原理简介 启动 NFS SERVER 之前，首先要启动 RPC 服务（CentOS 5.x 下为 portmap 服务，CentOS 6.x 和 CentOS 7.x 下为 rpcbind 服务，下同），否则 NFS SERVER 就无法向 RPC 服务注册了。 另外，如果 RPC 服务重新启动，原来已经注册好的NFS端口数据就会丢失，因此，此时 RPC 服务管理的NFS程序也需要重新启动以重新向RPC注册。 要特别注意的是：一般修改NFS配置文件后，是不需要重启NFS的，直接在命令行执行 /etc/init.d/nfs reload 「针对CentOS 5.x 或 CentOS 6.x」 或 systemctl reload nfs-server.service 「针对CentOS 7.x」 或 exportfs -rv 即可使修改的 /etc/exports 生效。 NFS 服务所需的安装包安装 NFS 和 RPC 「服务端、客户端都安装」12345[root@backup ~]# rpm -qa nfs-utils rpcbind[root@backup ~]# yum install nfs-utils rpcbind -y #nfs需要的安装包[root@backup ~]# rpm -qa nfs-utils rpcbindnfs-utils-1.2.3-64.el6.x86_64rpcbind-0.2.0-11.el6_7.x86_64 查看用户信息1234567891011[root@nfs01 ~]# tail /etc/passwdhaldaemon:x:68:68:HAL daemon:/:/sbin/nologinntp:x:38:38::/etc/ntp:/sbin/nologinsaslauth:x:499:76:Saslauthd user:/var/empty/saslauth:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologintcpdump:x:72:72::/:/sbin/nologinoldboy:x:500:500::/home/oldboy:/bin/bashrpc:x:32:32:Rpcbind Daemon:/var/cache/rpcbind:/sbin/nologin #yum安装rpc服务时创建的rpcuser:x:29:29:RPC Service User:/var/lib/nfs:/sbin/nologin #yum安装rpc服务时创建的nfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologin #yum安装nfs服务时创建的 NFS 版本查看服务端版本查看1nfsstat -s 客户端版本查看1nfsstat -c NFS服务端搭建配置exports12345678910[root@nfs01 ~]# mkdir /data[root@nfs01 ~]# ll -d /data/drwxr-xr-x. 3 root root 4096 Apr 11 09:49 /data/[root@nfs01 ~]# chown -R nfsnobody.nfsnobody /data/ [root@nfs01 ~]# ll -d /data/ drwxr-xr-x. 3 nfsnobody nfsnobody 4096 Apr 11 09:49 /data/[root@nfs01 ~]# cat /etc/exports # share /data for web created by zhangliang at 2016-05-21/data 172.16.1.0/24(rw,sync)#172.16.1.0/24(rw,sync) 没有空格 其他配置示例： 1234# 指定 IP 配置/opt 192.168.0.1(ro) 192.168.0.2(rw)# 指定 网段/data 172.16.1.0/24(rw,sync) 启动rpcbind服务CentOS 5.x 和 CentOS 6.x 启动方式1234567891011121314151617181920212223242526[root@nfs01 ~]# /etc/init.d/rpcbind start [root@nfs01 ~]# netstat -anp | grep &apos;rpc&apos; tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 1346/rpcbind tcp 0 0 0.0.0.0:38420 0.0.0.0:* LISTEN 1368/rpc.statd tcp 0 0 :::13894 :::* LISTEN 1368/rpc.statd tcp 0 0 :::111 :::* LISTEN 1346/rpcbind udp 0 0 0.0.0.0:673 0.0.0.0:* 1346/rpcbind udp 0 0 127.0.0.1:703 0.0.0.0:* 1368/rpc.statd udp 0 0 0.0.0.0:15306 0.0.0.0:* 1368/rpc.statd udp 0 0 0.0.0.0:111 0.0.0.0:* 1346/rpcbind udp 0 0 :::673 :::* 1346/rpcbind udp 0 0 :::50537 :::* 1368/rpc.statd udp 0 0 :::111 :::* 1346/rpcbind unix 2 [ ACC ] STREAM LISTENING 10120 1346/rpcbind /var/run/rpcbind.sockunix 2 [ ] DGRAM 10207 1368/rpc.statd [root@nfs01 ~]# rpcinfo -p localhost program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper 100000 2 tcp 111 portmapper 100000 4 udp 111 portmapper 100000 3 udp 111 portmapper 100000 2 udp 111 portmapper 100024 1 udp 15306 status 100024 1 tcp 38420 status#### 由上可知，暂时只有自己的端口服务，没有其他的 CentOS 7.x 启动方式1234567891011121314151617[root@nginx_cdn ~]# systemctl start rpcbind.service [root@nginx_cdn ~]# netstat -anp | grep &apos;rpc&apos; tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 1930/rpcbind tcp6 0 0 :::111 :::* LISTEN 1930/rpcbind udp 0 0 0.0.0.0:832 0.0.0.0:* 1930/rpcbind udp 0 0 0.0.0.0:111 0.0.0.0:* 1930/rpcbind udp6 0 0 :::832 :::* 1930/rpcbind udp6 0 0 :::111 :::* 1930/rpcbind unix 2 [ ACC ] STREAM LISTENING 17999 1/systemd /var/run/rpcbind.sock[root@nginx_cdn ~]# rpcinfo -p localhost program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper 100000 2 tcp 111 portmapper 100000 4 udp 111 portmapper 100000 3 udp 111 portmapper 100000 2 udp 111 portmapper 启动NFSCentOS 5.x 和 CentOS 6.x 启动方式123456789101112131415161718192021222324252627282930313233343536373839404142[root@nfs01 ~]# /etc/init.d/nfs start Starting NFS services: [ OK ]Starting NFS quotas: [ OK ]Starting NFS mountd: [ OK ]Starting NFS daemon: [ OK ]正在启动 RPC idmapd： [确定][root@nfs01 ~]# rpcinfo -p localhost program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper 100000 2 tcp 111 portmapper 100000 4 udp 111 portmapper 100000 3 udp 111 portmapper 100000 2 udp 111 portmapper 100024 1 udp 15306 status 100024 1 tcp 38420 status 100011 1 udp 875 rquotad 100011 2 udp 875 rquotad 100011 1 tcp 875 rquotad 100011 2 tcp 875 rquotad 100005 1 udp 11473 mountd 100005 1 tcp 62369 mountd 100005 2 udp 17528 mountd 100005 2 tcp 47308 mountd 100005 3 udp 11312 mountd 100005 3 tcp 51724 mountd 100003 2 tcp 2049 nfs 100003 3 tcp 2049 nfs 100003 4 tcp 2049 nfs 100227 2 tcp 2049 nfs_acl 100227 3 tcp 2049 nfs_acl 100003 2 udp 2049 nfs 100003 3 udp 2049 nfs 100003 4 udp 2049 nfs 100227 2 udp 2049 nfs_acl 100227 3 udp 2049 nfs_acl 100021 1 udp 25181 nlockmgr 100021 3 udp 25181 nlockmgr 100021 4 udp 25181 nlockmgr 100021 1 tcp 20093 nlockmgr 100021 3 tcp 20093 nlockmgr 100021 4 tcp 20093 nlockmgr CentOS 7.x 启动方式1234567891011121314151617181920212223242526272829[root@nginx_cdn ~]# systemctl start nfs.service [root@nginx_cdn ~]# rpcinfo -p localhost program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper 100000 2 tcp 111 portmapper 100000 4 udp 111 portmapper 100000 3 udp 111 portmapper 100000 2 udp 111 portmapper 100024 1 udp 44741 status 100024 1 tcp 23203 status 100005 1 udp 20048 mountd 100005 1 tcp 20048 mountd 100005 2 udp 20048 mountd 100005 2 tcp 20048 mountd 100005 3 udp 20048 mountd 100005 3 tcp 20048 mountd 100003 3 tcp 2049 nfs 100003 4 tcp 2049 nfs 100227 3 tcp 2049 nfs_acl 100003 3 udp 2049 nfs 100003 4 udp 2049 nfs 100227 3 udp 2049 nfs_acl 100021 1 udp 48638 nlockmgr 100021 3 udp 48638 nlockmgr 100021 4 udp 48638 nlockmgr 100021 1 tcp 16146 nlockmgr 100021 3 tcp 16146 nlockmgr 100021 4 tcp 16146 nlockmgr 加入开始自启动CentOS 5.x 和 CentOS 6.x 环境使用 /etc/rc.local123456789[root@nfs01 ~]# tail /etc/rc.local # You can put your own initialization stuff in here if you don&apos;t# want to do the full Sys V style init stuff.touch /var/lock/subsys/local# start rpc and nfs server/etc/init.d/rpcbind start/etc/init.d/nfs start 使用chkconfig123456789[root@nfs01 ~]# chkconfig rpcbind on [root@nfs01 ~]# chkconfig nfs on [root@nfs01 ~]# ls /etc/rc.d/rc3.d/* | grep -E &apos;rpc|nfs&apos; /etc/rc.d/rc3.d/K61nfs-rdma/etc/rc.d/rc3.d/K69rpcsvcgssd/etc/rc.d/rc3.d/S13rpcbind/etc/rc.d/rc3.d/S14nfslock/etc/rc.d/rc3.d/S19rpcgssd/etc/rc.d/rc3.d/S30nfs 查看rpc服务和NFS服务的开机启动顺序 12345678910111213141516171819202122[root@nfs01 ~]# head /etc/init.d/rpcbind #! /bin/sh## rpcbind Start/Stop RPCbind## chkconfig: 2345 13 87 #运行级别 开机顺序 关机顺序【其中 2345 指的是 运行级别】# description: The rpcbind utility is a server that converts RPC program \# numbers into universal addresses. It must be running on the \# host to be able to make RPC calls on a server on that machine.## processname: rpcbind[root@nfs01 ~]# head /etc/init.d/nfs #!/bin/sh## nfs This shell script takes care of starting and stopping# the NFS services.## chkconfig: - 30 60# description: NFS is a popular protocol for file sharing across networks.# This service provides NFS server functionality, which is \# configured via the /etc/exports file.# probe: true CentOS 7.x 环境12[root@nginx_cdn ~]# systemctl enable rpcbind.service [root@nginx_cdn ~]# systemctl enable nfs.service 查看具体状态情况 12345678[root@nginx_cdn ~]# systemctl status rpcbind.service ● rpcbind.service - RPC bind service Loaded: loaded (/usr/lib/systemd/system/rpcbind.service; enabled; vendor preset: enabled)………………[root@nginx_cdn ~]# systemctl status nfs.service ● nfs-server.service - NFS server and services Loaded: loaded (/usr/lib/systemd/system/nfs-server.service; enabled; vendor preset: disabled)……………… 查看有哪些参数生效12[root@nfs01 ~]# cat /var/lib/nfs/etab /data 172.16.1.0/24(rw,sync,wdelay,hide,nocrossmnt,secure,root_squash,no_all_squash,no_subtree_check,secure_locks,acl,anonuid=65534,anongid=65534,sec=sys,rw,root_squash,no_all_squash) 参数说明：ro：只读设置，这样 NFS 客户端只能读、不能写（默认设置）；rw：读写设置，NFS 客户端可读写；sync：将数据同步写入磁盘中，效率低，但可以保证数据的一致性（默认设置）；async：将数据先保存在内存缓冲区中，必要时才写入磁盘；如果服务器重新启动，这种行为可能会导致数据损坏，但效率高；root_squash：当客户端用 root 用户访问该共享文件夹时，将 root 用户映射成匿名用户（默认设置）；no_root_squash：客户端的 root 用户不映射。这样客户端的 root 用户与服务端的 root 用户具有相同的访问权限，这可能会带来严重的安全影响。没有充分的理由，不应该指定此选项；all_squash：客户端所有普通用户及所属组都映射为匿名用户及匿名用户组；「推荐设置」no_all_squash：客户端所有普通用户及所属组不映射（默认设置）；subtree_check：如果共享，如：/usr/bin之类的子目录时，强制NFS检查父目录的权限；no_subtree_check：即使共享 NFS 服务端的子目录时，nfs服务端也不检查其父目录的权限，这样可以提高效率（默认设置）；secure：限制客户端只能从小于1024的tcp/ip端口连接nfs服务器（默认设置）；insecure：允许客户端从大于1024的tcp/ip端口连接服务器；wdelay：检查是否有相关的写操作，如果有则将这些写操作一起执行，这样可以提高效率（默认设置）；no_wdelay：若有写操作则立即执行，当使用async时，无需此设置；anonuid=xxx：将远程访问的所有用户主都映射为匿名用户主账户，并指定该匿名用户主为本地用户主（UID=xxx）；anongid=xxx：将远程访问的所有用户组都映射为匿名用户组账户，并指定该匿名用户组为本地用户组（GID=xxx）； 检查是否成功123[root@nfs01 ~]# showmount -e 172.16.1.31 # 其中 172.16.1.31 为 NFS 服务端IP Export list for 172.16.1.31:/data 172.16.1.0/24 NFS客户端配置启动rpcbind服务CentOS 5.x 和 CentOS 6.x 环境12[root@web01 ~]# /etc/init.d/rpcbind start Starting rpcbind: [ OK ] CentOS 7.x 环境1[root@nginx_proxy01 ~]# systemctl start rpcbind.service 检查共享信息123[root@web01 ~]# showmount -e 172.16.1.31 Export list for 172.16.1.31:/data 172.16.1.0/24 NFS挂载在2台机器都挂载 NFS，好用于后面的测试。 1[root@web01 ~]# mount -t nfs 172.16.1.31:/data /mnt 查看挂载信息查询方式1123456[root@web01 ~]# df -h #有时可能会被卡主Filesystem Size Used Avail Use% Mounted on/dev/sda3 8.8G 1.5G 6.9G 18% /tmpfs 495M 0 495M 0% /dev/shm/dev/sda1 190M 40M 141M 23% /boot172.16.1.31:/data 8.8G 1.5G 6.9G 18% /mnt 查询方式212345678910111213[root@web01 ~]# cat /proc/mounts # 优先使用，监控时使用该命令rootfs / rootfs rw 0 0proc /proc proc rw,relatime 0 0sysfs /sys sysfs rw,relatime 0 0devtmpfs /dev devtmpfs rw,relatime,size=490920k,nr_inodes=122730,mode=755 0 0devpts /dev/pts devpts rw,relatime,gid=5,mode=620,ptmxmode=000 0 0tmpfs /dev/shm tmpfs rw,relatime 0 0/dev/sda3 / ext4 rw,relatime,barrier=1,data=ordered 0 0/proc/bus/usb /proc/bus/usb usbfs rw,relatime 0 0/dev/sda1 /boot ext4 rw,relatime,barrier=1,data=ordered 0 0none /proc/sys/fs/binfmt_misc binfmt_misc rw,relatime 0 0sunrpc /var/lib/nfs/rpc_pipefs rpc_pipefs rw,relatime 0 0172.16.1.31:/data/ /mnt nfs4 rw,relatime,vers=4,rsize=131072,wsize=131072,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=172.16.1.8,minorversion=0,local_lock=none,addr=172.16.1.31 0 0 测试在客户端和服务端之间测试「2个客户端，1个服务端」 1、任意客户端创建文件夹或创建文件并且输入数据，在服务端是否可以查看； 2、服务端创建文件夹或创建文件并且输入数据，在任意客户端是否可以查看； 3、在客户端A 删除客户端B 创建的文件 4、在客户端B 删除客户端A 创建的文件 加入开机自启动如果是 CentOS 7 环境，那么必须保证 /etc/rc.d/rc.local 文件具有可执行权限，否则该脚本不会执行也不会生效。 开机自启动方式1123456[root@web01 mnt]$ ll /etc/rc.local lrwxrwxrwx. 1 root root 13 Nov 14 2018 /etc/rc.local -&gt; rc.d/rc.local[root@web01 mnt]# tail -3 /etc/rc.local # mount nfsmount -t nfs 172.16.1.31:/data /mnt 开机自启动方式2123[root@web01 mnt]$ cat /etc/fstab # 添加如下信息172.16.1.31:/data /mnt nfs defaults 0 0 存在问题加入了开机自启动，当重启 NFS 客户端机器时，如果此时 NFS 服务端机器已关机，或者网络存在问题等等。使 NFS 客户端连接 NFS 服务端失败，那么此时会造成 NFS 客户端机器起不来的情况。 因此为了避免该情况发生，不建议机器开机自启动就挂载 NFS。 如果一台机器必须挂载 NFS，那么我们就做好监控。当该机器未挂载 NFS 时就告警给我们，然后我们去手动挂载。 当然如果实际环境中你们的 NFS 服务极其稳定，且几乎不再改变 NFS 服务端地址，那么此时你也可以加入开机自启动。 这些都是根据实际具体情况具体分析的。]]></content>
      <categories>
        <category>NFS</category>
      </categories>
      <tags>
        <tag>NFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本：通过域名获取证书的过期时间]]></title>
    <url>%2F2019%2F06%2F24%2Fdomainexpire%2F</url>
    <content type="text"><![CDATA[各位读者都是经常上网的人，当今社会我们可以暂时性没有很多东西，但是就是不能没有网络。否则的话可能会产生严重的焦虑，感觉自己突然就和社会脱节了。 那么在访问各网站的时候，不知道你有没有注意几乎所有网站网址的开头都是 https:// 打头的，而不是 http:// 打头。为什么呢？因为 https 协议对比 http 协议而言安全性更有保证。防止你访问过程中产生的敏感信息被第三方人或组织非法获取到，并作他用。 自签发证书和权威证书当然如果一个网站需要提供 https 访问，那么需要 SSL 证书，这个证书有两种途经获取：第一，我们自签发；第二，购买权威证书。 这两个有什么区别呢？前者不被浏览器承认，因为这个证书是自签发的，认为是非法的。谁知道你有没有动过什么手脚呢，对吧。 自签发证书，谷歌浏览器访问结果如下： 如果我们使用权威证书呢，那么需要我们申请域名，然后备案「就是用来做什么的，如果用途不当，也好查你。」，之后就是向 SSL 权威机构购买 SSL 权威证书了。购买完后，就能在你的网站上使用了。 权威证书，谷歌浏览器访问结果如下： 是不是想着这样就万事大吉了，以后这个 SSL 证书就能够一直使用下去了。呵呵……，少年你太单纯了，要是这样怎么符合细水长流的做法，权威机构是不会只做一锤子买卖的，那样岂不亏大了。这个 SSL 证书是有过期时间的，如果过期你还未更新，仍使用老的 SSL 证书，那么浏览器就会提示不安全。那样你的用户还敢访问你的网站吗，哼哼…………。 实际中不管是个人，还是部门，还是一个公司，总不能每天都看看自家网站的 SSL 证书什么时候过期吧。即便每天看，只要是人执行那总有打盹的时候，那就会有疏漏，要是发生证书过期并且未及时更新新证书产生了其他影响，这事儿就难说了。 因此为了避免上述现象，我们应该怎么防范呢。答案：对 SSL 证书过期时间加监控，比如过期时间小于 30 天就告警，这样我们就能从容处理了。大多数公司都有告警系统吧，例如：zabbix 或者 cacti 或者 open-falcon 等等。 所谓监控好加，但是如何获取 SSL 证书的过期时间呢，这才是重点。那么就到了我们今天的正文了。「哎，扯了半天终于到正主了，让各位读者久等了。」 通过域名获取 SSL 证书过期时间需要两个文件，一个用于存储域名和端口信息，另一个是具体检测 SSL 证书过期时间的执行脚本。注意：这两个文件是在一个目录下。 domain_ssl.info「存储域名信息」 123[root@mini05 20180930]# cat domain_ssl.info # 检测百度域名www.baidu.com:443 check_domain_time.sh「SSL 证书过期检测脚本」 123456789101112131415161718192021222324252627282930313233343536373839404142[root@mini05 20180930]# cat check_domain_time.sh #!/bin/bash################ Version Info ################### Create Date: 2018-09-29# Author: Zhang# Mail: zhang@xxxx.com# Version: 1.0# Attention: 通过域名获取证书的过期时间################################################# V1.0.0 2018-09-29 脚本编写 张# 1.通过域名获取证书的过期时间################################################# 加载环境变量. /etc/profile. ~/.bash_profile. /etc/bashrc# 脚本所在目录即脚本名称script_dir=$( cd &quot;$( dirname &quot;$0&quot; )&quot; &amp;&amp; pwd )script_name=$(basename $&#123;0&#125;)readFile=&quot;$&#123;script_dir&#125;/domain_ssl.info&quot;grep -v &apos;^#&apos; $&#123;readFile&#125; | while read line;do # 读取存储了需要监测的域名的文件 # echo &quot;$&#123;line&#125;&quot; get_domain=$(echo &quot;$&#123;line&#125;&quot; | awk -F &apos;:&apos; &apos;&#123;print $1&#125;&apos;) get_port=$(echo &quot;$&#123;line&#125;&quot; | awk -F &apos;:&apos; &apos;&#123;print $2&#125;&apos;) # echo $&#123;get_domain&#125; # echo &quot;$&#123;get_port&#125;&quot; # echo &quot;======&quot; # 使用openssl获取域名的证书情况，然后获取其中的到期时间 END_TIME=$(echo | openssl s_client -servername $&#123;get_domain&#125; -connect $&#123;get_domain&#125;:$&#123;get_port&#125; 2&gt;/dev/null | openssl x509 -noout -dates |grep &apos;After&apos;| awk -F &apos;=&apos; &apos;&#123;print $2&#125;&apos;| awk -F &apos; +&apos; &apos;&#123;print $1,$2,$4 &#125;&apos; ) END_TIME1=$(date +%s -d &quot;$END_TIME&quot;) # 将日期转化为时间戳 NOW_TIME=$(date +%s -d &quot;$(date | awk -F &apos; +&apos; &apos;&#123;print $2,$3,$6&#125;&apos;)&quot;) # 将当前的日期也转化为时间戳 RST=$(($(($END_TIME1-$NOW_TIME))/(60*60*24))) # 到期时间减去目前时间再转化为天数 echo &quot;$&#123;RST&#125;&quot;done 执行结果 12[root@mini05 20180930]# sh check_domain_time.sh 389 有了上面这个结果后，相信你就知道应该怎么对其进行监控了。]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用 github+hexo 搭建个人博客07-next主题接入搜索和站点管理]]></title>
    <url>%2F2019%2F06%2F17%2Fhexo07%2F</url>
    <content type="text"><![CDATA[前言这是搭建个人博客系统系列文章的最后一篇，如果你是从第一篇一路跟下来的，那么恭喜你，即将完成整个博客网站的搭建。OK，话不多说，开始我们的收官之战。 不知你想过没有，如果我们的文章少，一眼看完整个目录，那么还好。但是如果日积月累几年下来，我们的文章增加到 100+ 以上，那么不管是你博主，还是访问用户，如何去快速找到所需的文章呢。这时我们就需要用到搜索了。 还有就是我们的文章最终是要让其他人看的，而不是我们自娱自乐。除了到各大平台引流到自己的博客系统外，最好让搜索引擎也收录我们的文章。常用的搜索引擎有百度和谷歌，因此本文会针对这两者进行讲解。 搜索服务Local Search添加百度/谷歌/本地 自定义站点内容搜索。 12345678910111213141516[root@iZ28xbsfvc4Z hexo]# pwd # 站点目录/app/softinsall/hexo[root@iZ28xbsfvc4Z hexo]# npm install hexo-generator-searchdb --save [root@iZ28xbsfvc4Z hexo]# vim _config.yml # 站点配置文件，追加信息# Local Searchsearch: path: search.xml field: post format: html limit: 10000[root@iZ28xbsfvc4Z hexo]# cd themes/next/ # 到主题目录[root@iZ28xbsfvc4Z next]# vim _config.yml # 修改主题配置文件# Local search# Dependencies: https://github.com/flashlab/hexo-generator-searchlocal_search: enable: true # 从 false 改为 true 然后进入站点目录，清除静态文件和缓存，重新生成，之后再启动服务即可 hexo clean ==&gt; hexo g ==&gt; hexo s -p 80 页面效果 站点管理先确认博客是否被收录在百度或者谷歌上面输入下面格式来判断，如果能搜索到就说明被收录，否则就没有。 1site:zhangblog.com 创建站点地图文件站点地图是一种文件，您可以通过该文件列出您网站上的网页，从而将您网站内容的组织架构告知Google和其他搜索引擎。搜索引擎网页抓取工具会读取此文件，以便更加智能地抓取您的网站。 安装插件在站点目录安装插件，并修改站点配置文件。 1234567891011121314151617181920[root@iZ28xbsfvc4Z hexo]# pwd # 站点目录/app/softinsall/hexo[root@iZ28xbsfvc4Z hexo]# npm install hexo-generator-sitemap --save [root@iZ28xbsfvc4Z hexo]# npm install hexo-generator-baidu-sitemap --save [root@iZ28xbsfvc4Z hexo]# vim _config.yml # 添加如下信息# 站点地图Plugins: - hexo-generator-baidu-sitemap - hexo-generator-sitemapbaidusitemap: path: baidusitemap.xmlsitemap: path: sitemap.xml[root@iZ28xbsfvc4Z hexo]# hexo g # 生成静态文件，可见有 baidusitemap.xml 和 sitemap.xml 文件生成INFO Start processingINFO Files loaded in 1.25 sINFO Generated: baidusitemap.xml # 生成的文件INFO Generated: sitemap.xml # 生成的文件INFO 2 files generated in 1.26 s 百度站点地图 http://www.zhangblog.com/baidusitemap.xml 谷歌站点地图 http://www.zhangblog.com/sitemap.xml 百度收录我们的博客 百度资源平台：https://ziyuan.baidu.com/dashboard/index 添加站点 这里推荐使用文件验证。下载文件放到 hexo\public 目录下即可。 数据引入 ==&gt; 链接提交为了方便我们使用「自动提交」下的「自动推送」和「sitemap」。 自动推送自动推送很简单，就是在你代码里面嵌入自动推送JS代码，在页面被访问时，页面URL将立即被推送给百度。 将复制的 JS 代码，添加到如下文件： 123456789101112131415161718[root@iZ28xbsfvc4Z next]# pwd #主题目录/app/softinsall/hexo/themes/next[root@iZ28xbsfvc4Z next]# vim layout/_partials/footer.swig # 在文件最后面追加&lt;!-- 百度自动推送 --&gt;&lt;script&gt;(function()&#123; var bp = document.createElement(&apos;script&apos;); var curProtocol = window.location.protocol.split(&apos;:&apos;)[0]; if (curProtocol === &apos;https&apos;) &#123; bp.src = &apos;https://zz.bdstatic.com/linksubmit/push.js&apos;; &#125; else &#123; bp.src = &apos;http://push.zhanzhang.baidu.com/push.js&apos;; &#125; var s = document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(bp, s);&#125;)();&lt;/script&gt; 代码来源 sitemap提交这个直接提交就行。 得到结果 如何选择链接提交方式1、主动推送：最为快速的提交方式，推荐你将站点当天新产出链接立即通过此方式推送给百度，以保证新链接可以及时被百度收录。2、自动推送：最为便捷的提交方式，请将自动推送的JS代码部署在站点的每一个页面源代码中，部署代码的页面在每次被浏览时，链接会被自动推送给百度。可以与主动推送配合使用。3、sitemap：您可以定期将网站链接放到sitemap中，然后将sitemap提交给百度。百度会周期性的抓取检查您提交的sitemap，对其中的链接进行处理，但收录速度慢于主动推送。4、手动提交：一次性提交链接给百度，可以使用此种方式。 谷歌收录我们的博客谷歌操作比较简单，就是向 Google 站长工具提交 sitemap 就可以了。 谷歌资源地址：https://search.google.com/search-console?hl=zh-CN 得到结果 总结上述这些完成后，搜索引擎不会马上就收录完成。得等一两天后才会完成收录。在站点管理页面中才有数据。 谷歌收录会快些最长几天，百度的话可能要等半个月左右吧。 推荐阅读Linux下使用 github+hexo 搭建个人博客01-hexo搭建 Linux下使用 github+hexo 搭建个人博客02-hexo部署到Github Pages Linux下使用 github+hexo 搭建个人博客03-hexo配置优化 Linux下使用 github+hexo 搭建个人博客04-next主题优化 Linux下使用 github+hexo 搭建个人博客05-next主题接入评论系统 Linux下使用 github+hexo 搭建个人博客06-next主题接入数据统计 Linux下使用 github+hexo 搭建个人博客07-next主题接入搜索和站点管理]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用 github+hexo 搭建个人博客06-next主题接入数据统计]]></title>
    <url>%2F2019%2F06%2F16%2Fhexo06%2F</url>
    <content type="text"><![CDATA[前言之前说了 next 主题的优化和接入评论系统。让我们完成了自己所需的页面风格和排版，也可让访问用户在每篇博文评论，完成博主和访问用户的交互。 本章我们继续讲解其他重要功能。 既然是一个网站，那么我们就需要收集网站访问数据，提供流量趋势、来源分析、转化跟踪、页面热力图、访问流等多种统计分析服务；这时我们就需要引入——百度统计。 上述的统计只能在百度统计中查看，但我想在自己的网站页面直接就能看一些简单的数据。比如：网站访问人数，访问次数，每篇文章访问次数，网站总字数，每篇文章字数，阅读时长估算等。那么我们就可以引入不蒜子统计，字数统计，阅读次数统计了。具体那就参见下文了。 百度统计需要在百度统计进行注册，并拿到脚本的 ID。 之后在主题配置文件中修改。 12345[root@iZ28xbsfvc4Z next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@iZ28xbsfvc4Z next]# vim _config.yml # Baidu Analytics IDbaidu_analytics: 983XXXXXXXXXXXXXXXXXXXXXXXXXX2 访问报告查看过半小时或一小时左右可在百度统计查看报告。 不蒜子统计编辑主题配置文件中的 busuanzi_count 的配置项。 123456789101112131415161718192021[root@iZ28xbsfvc4Z next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@iZ28xbsfvc4Z next]# vim _config.yml # Show PV/UV of the website/page with busuanzi.# Get more information on http://ibruce.info/2015/04/04/busuanzi/busuanzi_count: # count values only if the other configs are false enable: true # custom uv span for the whole site site_uv: true site_uv_header: 本站访客数 site_uv_footer: 人次 # custom pv span for the whole site site_pv: true site_pv_header: 本站总访问量 site_pv_footer: 次 # custom pv span for one page only # 每篇博文阅读次数，使用 leancloud 统计。原因是在「首页」中，leancloud 统计也能看阅读次数，而不蒜子则不行。 page_pv: false page_pv_header: 本文总阅读量 page_pv_footer: 次 不蒜子域名修改因七牛强制过期『dn-lbstatics.qbox.me』域名，与客服沟通无果，只能更换域名到『busuanzi.ibruce.info』！ 修改如下： 1234567[root@iZ28xbsfvc4Z next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@iZ28xbsfvc4Z next]# vim layout/_third-party/analytics/busuanzi-counter.swig &#123;% if theme.busuanzi_count.enable %&#125;&lt;div class=&quot;busuanzi-count&quot;&gt; &lt;script async src=&quot;https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt;……………… 浏览器访问页面底部 阅读次数统计在 LeanCloud 中创建 Class在之前的评论系统中，已经讲解了 LeanCloud 账号的创建、应用创建、获取App ID 和 App Key 已经安全加固。这里仅对阅读次数的 Class 创建做讲解。 数据栏中，_开头的都是系统预定义好的表。 为了区分，新建一张表来保存数据。为了保证对NexT主题的修改兼容，新建Class名字必须为Counter。 为了避免权限问题导致 次数统计显示不正常，选择无限制，创建Class。 主题配置修改在主题配置文件中修改： 123456789[root@iZ28xbsfvc4Z next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@iZ28xbsfvc4Z next]# vim _config.yml # Show number of visitors to each article.# You can visit https://leancloud.cn get AppID and AppKey.leancloud_visitors: enable: true app_id: h7YmXXXXXXXXXXXXXX app_key: VhTGXXXXXXXXXX 浏览器访问文章标题 字数统计用于统计文章的字数以及分析出阅读时间。 安装 wordcount 插件需要安装的插件 123[root@iZ28xbsfvc4Z hexo]# pwd # 站点目录/app/softinsall/hexo[root@iZ28xbsfvc4Z hexo]# npm install hexo-wordcount --save 主题配置修改在主题配置文件中修改。 1234567891011121314[root@iZ28xbsfvc4Z next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@iZ28xbsfvc4Z next]# vim _config.yml # Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true # 文本显示 wordcount: true # 单篇 字数统计 min2read: true # 单篇 阅读时长 totalcount: true # 网站 字数统计 # 该post_wordcount的所有设置另起一行显示 separated_meta: true[root@iZ28xbsfvc4Z next]# vim languages/zh-Hans.yml # 从英文改为中文 totalcount: 本站总字数 浏览器访问文章标题 页面底部 推荐阅读Linux下使用 github+hexo 搭建个人博客01-hexo搭建 Linux下使用 github+hexo 搭建个人博客02-hexo部署到Github Pages Linux下使用 github+hexo 搭建个人博客03-hexo配置优化 Linux下使用 github+hexo 搭建个人博客04-next主题优化 Linux下使用 github+hexo 搭建个人博客05-next主题接入评论系统 Linux下使用 github+hexo 搭建个人博客06-next主题接入数据统计 Linux下使用 github+hexo 搭建个人博客07-next主题接入搜索和站点管理]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用 github+hexo 搭建个人博客05-next主题接入评论系统]]></title>
    <url>%2F2019%2F06%2F16%2Fhexo05%2F</url>
    <content type="text"><![CDATA[前言静态站点拥有一定的局限性，因此我们需要借助于第三方服务来扩展我们站点的功能。 而评论系统是最常用于和网站用户交流的，因此本章讲解在 next 主题，如何接入评论系统。 参考网站：Next 使用文档，第三方服务集成 http://theme-next.iissnan.com/third-party-services.html 常用评论系统考虑到国内整体互联网环境，因此评论系统除了考虑到长期可用外，还需要考虑不会被屏蔽。因此在这里推荐三款评论系统。 来必力虽然是韩国的「撇开政治因素」，但是UI设计和后台管理也比较不错，数据可视化用到了图标来展示，所以有付费和免费两个版本，博客只需要用免费的就行了。当然付费的效果主要体现在数据分析上，还可以取消掉免费版未来所带来的广告。当然由于网站在国外，因此登录该网站有些慢，这个你要理解。 登录后可评论。 畅言随着国内其他家评论系统的停服，畅言的地位比之前更加壮大，也正因此听说广告越来越多，饱受诟病。如果想去掉广告，很简单氪金充钱就行。还有就是该评论系统注册时需要填写备案信息，这点请大家务必知晓。 登录后可评论。 Valine由于我们使用的是Next 5.1.3版本，本身就已经集成了valine，因此正常情况下是按照官方文档走就可以了，5分钟开启你的评论系统。因为我们的评论系统其实是放在 LeanCloud 上的，因此首先需要去 LeanCloud 注册一个账号。 可匿名评论。 综上所述，优先选择来必力或 Valine。 来必力评论获取 livere_uid当然怎么在来必力网站注册之类的我就不多说了。说一点：注册完毕提交信息后，可能会等两三分钟才会成功。 如果遇见韩文，那么可以用有道翻译或百度翻译。 如下页面可获取你的ID 在Next主题配置当前版本的 Next 主题已经集成来必力评论系统，因此只需在主题配置文件中配置 livere_uid 即可。 123456[root@iZ28xbsfvc4Z next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@iZ28xbsfvc4Z next]# vim _config.yml # Support for LiveRe comments system.# You can get your uid from https://livere.com/insight/myCode (General web site)livere_uid: MTAyMC8XXXXXXXXXXNw== 浏览器访问 数据分析页面 Valine 评论系统LeanCloud 账号注册LeanCloud 官网地址 https://leancloud.cn 请自行注册 创建应用注册完毕后，创建应用，我这创建的的是 zhangblog。 创建Class 数据栏中，_开头的都是系统预定义好的表。 为了区分，新建一张表来保存数据。为了保证对NexT主题的修改兼容，新建Class名字必须为Comment。 为了避免权限问题导致 次数统计显示不正常，选择无限制，创建Class。 获取 App ID 和 App Key 如下：Class创建完成后，选择界面最左侧的设置 → 应用Key，复制App ID和App Key。 安全加固因为AppID以及AppKey是暴露在外的，为了确保只用于我们自己的博客，可设置Web安全域名，填入自己的博客域名。 修改主题配置上文说过，Next 5.1.3版本已经集成 Valine，因此我们只需在主题配置文件中修改即可。 12345678910111213141516[root@iZ28xbsfvc4Z next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@iZ28xbsfvc4Z next]# vim _config.yml # Valine.# You can get your appid and appkey from https://leancloud.cn# more info please open https://valine.js.orgvaline: enable: true appid: h7YmXXXXXXXXXXXXXXXXXX appkey: VhTXXXXXXXXXXXXXXX notify: false # mail notifier , https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: 来了，就撩两句呗！ # comment box placeholder avatar: mm # gravatar style guest_info: nick,mail,link # custom comment header pageSize: 20 # pagination size 浏览器访问 推荐阅读Linux下使用 github+hexo 搭建个人博客01-hexo搭建 Linux下使用 github+hexo 搭建个人博客02-hexo部署到Github Pages Linux下使用 github+hexo 搭建个人博客03-hexo配置优化 Linux下使用 github+hexo 搭建个人博客04-next主题优化 Linux下使用 github+hexo 搭建个人博客05-next主题接入评论系统 Linux下使用 github+hexo 搭建个人博客06-next主题接入数据统计 Linux下使用 github+hexo 搭建个人博客07-next主题接入搜索和站点管理]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用 github+hexo 搭建个人博客04-next主题优化]]></title>
    <url>%2F2019%2F06%2F16%2Fhexo04%2F</url>
    <content type="text"><![CDATA[前言上篇我们说了 hexo 的优化，针对的站点的优化。 本篇讲解 next 主题的优化，包括：使用语言、前端页面显示宽度、菜单、侧栏、头像、添加或取消动画效果、打赏功能等等。 让页面排版更符合我们所要的功能和所想的风格。 可参考网站 http://theme-next.iissnan.com/getting-started.html 主题设定选择 Scheme修改 next 主题配置文件。 12345678[root@zhangblog next]# pwd/app/softinsall/hexo/themes/next[root@zhangblog next]# vim _config.yml # Schemes#scheme: Muse#scheme: Mistscheme: Pisces#scheme: Gemini 可以自行更换，不用重启 hexo 服务。个人更喜欢 Pisces，将菜单栏放在左侧，而不是原来的顶部。Muse 默认 Scheme，这是 NexT 最初的版本，黑白主调，大量留白Mist Muse 的紧凑版本，整洁有序的单栏外观Pisces 双栏 Scheme，小家碧玉似的清新 页面宽度设置默认情况下，该主题页面两边留白较多，所以如果需要可以把两边留白处减少些。 当然，此步操作可略。 123456789101112131415[root@zhangblog css]# pwd/app/softinsall/hexo/themes/next/source/css[root@zhangblog css]# vim _variables/base.styl # 修改处一$main-desktop = 1160px[root@zhangblog css]# vim _schemes/Pisces/_layout.styl # 修改处二 .content-wrap &#123; float: right; box-sizing: border-box; padding: $content-desktop-padding; /* width: $content-desktop; 改为如下信息 */ width: calc(100% - 252px); background: white; min-height: 700px; box-shadow: $box-shadow-inner; border-radius: $border-radius-inner; 设置语言页面默认为英文，改为中文显示。 首先确定该主题支持哪些语言。 1234567891011121314151617181920[root@zhangblog languages]# pwd # 在主题目录，查看 next 主题支持哪些语言/app/softinsall/hexo/themes/next[root@zhangblog languages]# ll languages/total 64-rw-r--r-- 1 root root 1669 Jun 7 20:13 default.yml-rw-r--r-- 1 root root 1601 Jun 7 20:13 de.yml-rw-r--r-- 1 root root 1712 Jun 7 20:13 en.yml-rw-r--r-- 1 root root 1553 Jun 7 20:13 fr-FR.yml-rw-r--r-- 1 root root 1507 Jun 7 20:13 id.yml-rw-r--r-- 1 root root 1688 Jun 7 20:13 it.yml-rw-r--r-- 1 root root 1573 Jun 7 20:13 ja.yml-rw-r--r-- 1 root root 1596 Jun 7 20:13 ko.yml-rw-r--r-- 1 root root 1729 Jun 7 20:13 nl-NL.yml-rw-r--r-- 1 root root 1545 Jun 7 20:13 pt-BR.yml-rw-r--r-- 1 root root 1583 Jun 7 20:13 pt.yml-rw-r--r-- 1 root root 2632 Jun 7 20:13 ru.yml-rw-r--r-- 1 root root 1997 Jun 7 20:13 vi.yml-rw-r--r-- 1 root root 1781 Jun 7 20:13 zh-Hans.yml # 中文简体，使用该语言-rw-r--r-- 1 root root 1763 Jun 7 20:13 zh-hk.yml-rw-r--r-- 1 root root 1763 Jun 7 20:13 zh-tw.yml 在站点配置文件使用指定语言。 123456[root@zhangblog hexo]# pwd # 站点目录/app/softinsall/hexo[root@zhangblog hexo]# vim _config.yml ………………language: zh-Hanstimezone: 重新生成静态文件，然后重启 hexo 服务，再次访问可见是中文显示了。 设置菜单菜单配置包括三个部分，第一是菜单项（名称和链接），第二是菜单项的显示文本，第三是菜单项对应的图标。 修改主题配置文件。 1234567891011121314[root@zhangblog next]# vim _config.yml menu: home: / || home archives: /archives/ || archive tags: /tags/ || tags categories: /categories/ || th about: /about/ || user #schedule: /schedule/ || calendar sitemap: /sitemap.xml || sitemap commonweal: /404/ || heartbeat# Enable/Disable menu icons.menu_icons: enable: true home 主页archives 归档类tags 标签页categories 分类页about 关于页schedule 时间表sitemap 网站地图commonweal 公益 404 设置侧栏修改主题配置文件。 12345[root@zhangblog next]# vim _config.yml sidebar: # Sidebar Position, available values: left | right (only for Pisces | Gemini). position: left #position: right 默认不用修改。侧边栏位置，可用值:：left | right (仅适用于 Pisces | Gemini)。 设置头像修改主题配置文件。 1234567[root@zhangblog next]# vim _config.yml # Sidebar Avataravatar: # In theme directory (source/images): /images/avatar.gif # In site directory (source/uploads): /uploads/avatar.gif # You can also use other linking images. url: /uploads/avatar.png 如果是站外，完整的互联网 URI 如：http://example.com/avatar.png 如果是站内：1、将头像放置主题目录下的 source/uploads/ （新建 uploads 目录若不存在），配置为：avatar: /uploads/avatar.png2、或者 放置在 source/images/ 目录下，配置为：avatar: /images/avatar.png 图片路径 1234[root@zhangblog next]# pwd # next 主题目录/app/softinsall/hexo/themes/next[root@zhangblog next]# ll source/uploads/avatar.png -rw-r--r-- 1 root root 131807 Apr 30 14:39 source/uploads/avatar.png 主题配置设置「RSS」false：禁用 RSS，不在页面上显示 RSS 连接。留空：使用 Hexo 生成的 Feed 链接。 你可以需要先安装 hexo-generator-feed 插件。 插件地址：https://github.com/hexojs/hexo-generator-feed 安装插件 123[root@iZ28xbsfvc4Z hexo]# pwd # 站点目录/app/softinsall/hexo[root@iZ28xbsfvc4Z hexo]# npm install hexo-generator-feed --save 站点配置文件修改 123456789101112[root@zhangblog hexo]# pwd/app/softinsall/hexo[root@zhangblog hexo]# vim _config.yml #Feed Atomfeed: type: atom path: atom.xml limit: 20 hub: content: content_limit: 140 content_limit_delim: &apos; &apos; 参数讲解：type: RSS 的类型(atom/rss2)path: 文件路径，默认是 atom.xml/rss2.xmllimit: 展示文章的数量，使用 0 或则 false 代表展示全部hub:content: 在RSS文件中是否包含内容，有3个值 true/false 默认不填为 falsecontent_limit: 指定内容的长度作为摘要，仅仅在上面content设置为 false 和没有自定义的描述出现content_limit_delim: 上面截取描述的分隔符，截取内容是以指定的这个分隔符作为截取结束的标志。在达到规定的内容长度之前最后出现的这个分隔符之前的内容，防止从中间截断。 添加「标签」页面新建标签页面 1234[root@zhangblog hexo]# pwd # 定位到 Hexo 站点目录下/app/softinsall/hexo[root@zhangblog hexo]# hexo new page tags INFO Created: /app/softinsall/hexo/source/tags/index.md 标签页面设置 123456789101112[root@zhangblog tags]# pwd/app/softinsall/hexo/source/tags[root@zhangblog tags]# lltotal 4-rw-r--r-- 1 root root 79 Jun 7 10:48 index.md[root@zhangblog tags]# cat index.md ---title: All Tagsdate: 2019-06-07 10:36:52type: &quot;tags&quot;comments: false--- 注意：如果有集成评论服务，页面也会带有评论。 若需要关闭的话，请添加字段 comments 并将值设置为 false。 使用标签在文章中使用标签。 123456789[root@zhangblog hexo]# pwd/app/softinsall/hexo[root@zhangblog hexo]# head source/_posts/MarkDown-新手指南.md # 相关信息如下---title: MarkDown 新手指南date: 2019-06-04 19:28:51tags: - MarkDown--- 浏览器访问 添加「分类」页面新建分类页面 1234[root@zhangblog hexo]# pwd # 定位到 Hexo 站点目录下/app/softinsall/hexo[root@zhangblog hexo]# hexo new page categories INFO Created: /app/softinsall/hexo/source/categories/index.md 分类页面设置 123456789101112[root@zhangblog categories]# pwd/app/softinsall/hexo/source/categories[root@zhangblog categories]# lltotal 4-rw-r--r-- 1 root root 89 Jun 7 11:04 index.md[root@zhangblog categories]# cat index.md ---title: 文章分类date: 2019-06-07 11:00:17type: &quot;categories&quot;comments: false--- 注意：如果有集成评论服务，页面也会带有评论。 若需要关闭的话，请添加字段 comments 并将值设置为 false。 使用分类在文章中使用分类。 1234567891011[root@zhangblog hexo]# pwd/app/softinsall/hexo[root@zhangblog hexo]# head source/_posts/MarkDown-新手指南.md # 相关信息如下---title: MarkDown 新手指南date: 2019-06-04 19:28:51tags: - MarkDowncategories: - MarkDown--- 浏览器访问 添加「关于」页面新建关于页面 1234[root@zhangblog hexo]# pwd # 定位到 Hexo 站点目录下/app/softinsall/hexo[root@zhangblog hexo]# hexo new page aboutINFO Created: /app/softinsall/hexo/source/about/index.md 关于页面编辑 123456789101112131415161718192021222324252627282930313233[root@zhangblog about]# pwd/app/softinsall/hexo/source/about[root@zhangblog about]# lltotal 4-rw-r--r-- 1 root root 47 Jun 7 16:07 index.md[root@zhangblog about]# cat index.md ---title: 关于我date: 2019-06-07 16:07:36---# 关于本博客本博客诞生于 2019-06，虽然 2015-02 就开始在 CSDN 写博客，但是最开始都是作为自己的笔记记录，因此刚开始那段时间也不怎么重视排版。如果在 CSDN 看了我那些早期的博客，发现排版不好，体验性欠缺，还请多多包涵。后来该博客经过几次改版，自己发现不怎么适应。因此就转到了博客园。相比前者的经常改版，甚至有段时间广告频繁，博客园就好很多，页面也非常清爽。………………等等，后期可能还会有其他动作，敬请期待…………# 联系方式邮箱：zhanglianghhh@163.comQQ: 1369929127&lt;/br&gt;&lt;center&gt;**你对本站的捐赠，就是我最大的动力！**&lt;/center&gt;--- 浏览器访问 添加「公益404」页面腾讯公益404页面，寻找丢失儿童，让大家一起关注此项公益事业！ 新建关于页面 1234[root@zhangblog hexo]# pwd # 定位到 Hexo 站点目录下/app/softinsall/hexo[root@zhangblog hexo]# hexo new page 404INFO Created: /app/softinsall/hexo/source/404/index.md 关于页面编辑 1234567891011121314151617181920212223242526272829[root@zhangblog 404]# pwd/app/softinsall/hexo/source/404[root@zhangblog 404]# lltotal 4-rw-r--r-- 1 root root 758 Jun 7 23:19 index.md[root@zhangblog 404]# cat index.md ---title: 404date: 2019-06-07 23:15:22---&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8;&quot;/&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge,chrome=1&quot; /&gt; &lt;meta name=&quot;robots&quot; content=&quot;all&quot; /&gt; &lt;meta name=&quot;robots&quot; content=&quot;index,follow&quot;/&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://qzone.qq.com/gy/404/style/404style.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;script type=&quot;text/plain&quot; src=&quot;http://www.qq.com/404/search_children.js&quot; charset=&quot;utf-8&quot; homePageUrl=&quot;/&quot; homePageName=&quot;回到我的主页&quot;&gt; &lt;/script&gt; &lt;script src=&quot;https://qzone.qq.com/gy/404/data.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://qzone.qq.com/gy/404/page.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 浏览器访问 侧边栏社交链接侧栏社交链接的修改包含两个部分，第一是链接，第二是链接图标。两者配置均在主题配置文件中。 1234567891011121314[root@zhangblog next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@zhangblog next]# vim _config.ymlsocial: GitHub: https://github.com/zhanglianghhh || github E-Mail: mailto:zhanglianghhh@163.com || envelope 知乎: https://www.zhihu.com/people/lightzhang-23-69/activities || globe CSDN: https://blog.csdn.net/woshizhangliang999 || codiepie 博客园: https://www.cnblogs.com/zhanglianghhh/p/ || rss-squaresocial_icons: enable: true icons_only: false transition: false 以如下配置说明： GitHub: https://github.com/zhanglianghhh || github GitHub： 表示页面显示的文字https://github.com/zhanglianghhh ： 跳转URLgithub： 使用的图标 更多图标参见如下网站： http://www.fontawesome.com.cn/faicons/ 页面效果 开启打赏功能越来越多的平台（微信公众号、新浪博客、简书、百度打赏等）支持打赏功能，付费阅读时代越来越近，因此增加了打赏功能。 支持微信打赏和支付宝打赏，只需在主题配置文件中填入微信和支付宝收款二维码图片地址，即可开启打赏功能。 1234567[root@zhangblog next]# pwd # 在主题目录/app/softinsall/hexo/themes/next[root@zhangblog next]# vim _config.yml # Rewardreward_comment: 坚持原创分享，你的支持就是我最大的动力！wechatpay: /uploads/weixin_cash_code.pngalipay: /uploads/alipay_cash_code.png 图片所在位置 123456[root@zhangblog next]# pwd # 在主题目录/app/softinsall/hexo/themes/next[root@zhangblog next]# ll source/uploads/weixin_cash_code.png -rw-r--r-- 1 root root 27337 Jun 7 19:39 source/uploads/weixin_cash_code.png[root@zhangblog next]# ll source/uploads/alipay_cash_code.png -rw-r--r-- 1 root root 58235 Jun 7 19:37 source/uploads/alipay_cash_code.png 页面效果 友情链接在主题配置文件中修改。 1234567891011[root@zhangblog next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@zhangblog next]# vim _config.yml# Blog rollslinks_icon: linklinks_title: Links#links_layout: blocklinks_layout: inlinelinks: OpenInfo: http://mp.weixin.qq.com/user1 stormzhang: http://mp.weixin.qq.com/user2 页面效果 站点建立时间这个时间将在站点的底部显示，例如 © 2015- 2019。 编辑主题配置文件，修改字段 since。 12345678910[root@zhangblog next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@zhangblog next]# vim _config.ymlfooter: # Specify the date when the site was setup. # If not defined, current year will be used. 修改处如下 since: 2015 # Icon between year and copyright info. icon: user 页面效果 订阅微信公众号在每篇文章的末尾默认显示微信公众号二维码，扫一扫，轻松订阅。 编辑主题配置文件，如下： 12345678[root@zhangblog next]# pwd # 在主题目录/app/softinsall/hexo/themes/next[root@zhangblog next]# vim _config.yml# Wechat Subscriberwechat_subscriber: enabled: true qcode: /uploads/weixin_pulic_code.png description: 欢迎扫一扫，订阅我的微信公众号！ 页面样式修改 1234567891011[root@zhangblog next]# pwd # 在主题目录/app/softinsall/hexo/themes/next[root@zhangblog next]# vim layout/_macro/wechat-subscriber.swig &lt;div id=&quot;wechat_subscriber&quot; style=&quot;display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center&quot;&gt;&lt;!-- &lt;img id=&quot;wechat_subscriber_qcode&quot; src=&quot;&#123;&#123; theme.wechat_subscriber.qcode &#125;&#125;&quot; alt=&quot;&#123;&#123; theme.author &#125;&#125; wechat&quot; style=&quot;width: 200px; max-width: 100%;&quot;/&gt; 去掉 style 中的 width: 200px; --&gt; &lt;img id=&quot;wechat_subscriber_qcode&quot; src=&quot;&#123;&#123; theme.wechat_subscriber.qcode &#125;&#125;&quot; alt=&quot;&#123;&#123; theme.author &#125;&#125; wechat&quot; style=&quot;max-width: 100%;&quot;/&gt; &lt;div&gt;&#123;&#123; theme.wechat_subscriber.description &#125;&#125;&lt;/div&gt;&lt;/div&gt; 页面效果 设置「动画效果」Next 主题默认开启动画效果，由于该效果使用 JavaScript 编写，因此只有当 JavaScript 脚本加载完毕后，才会显示页面。如果你对加载速度在乎的话，那么可以关闭动画效果。 编辑主题配置文件，如下： 12345678[root@zhangblog next]# pwd # 在主题目录/app/softinsall/hexo/themes/next[root@zhangblog next]# vim _config.yml# Use velocity to animate everything.motion: # true 开启动画， false 关闭动画 enable: true async: false 设置「背景动画」Next 主题自带四种背景动画效果，有兴趣自行体验，不过建议最好别开背景动画，因为会消耗额外的客户端资源。 编辑主题配置文件，如下： 1234567891011121314[root@zhangblog next]# pwd # 在主题目录/app/softinsall/hexo/themes/next[root@zhangblog next]# vim _config.yml# Canvas-nestcanvas_nest: false# three_wavesthree_waves: false# canvas_linescanvas_lines: false# canvas_spherecanvas_sphere: false 底部版权信息修改主题配置文件，如下： 12345678[root@zhangblog next]# pwd # 在主题目录/app/softinsall/hexo/themes/next[root@zhangblog next]# vim _config.yml# Declare license on postspost_copyright: enable: true license: CC BY-NC-SA 3.0 license_url: https://creativecommons.org/licenses/by-nc-sa/3.0/ 页面效果 添加文章更新时间在主题配置文件中进行修改配置。 123456789[root@iZ28xbsfvc4Z next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@iZ28xbsfvc4Z next]# vim _config.yml # Post meta display settingspost_meta: item_text: true created_at: true updated_at: true # 从 false 改为 true categories: true 浏览器访问 首页不显示全文(只显示预览)在主题配置文件中进行修改配置。 123456789[root@iZ28xbsfvc4Z next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@iZ28xbsfvc4Z next]# vim _config.yml # Automatically Excerpt. Not recommend.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: # 从 false 改为 true enable: true length: 150 页面效果 文章末尾统一添加“本文结束”标记12345678910111213141516171819[root@iZ28xbsfvc4Z next]# pwd # 主题目录/app/softinsall/hexo/themes/next[root@iZ28xbsfvc4Z next]# vim layout/_macro/passage-end-tag.swig # 增加该文件&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style=&quot;text-align:center;color: #555;font-size:24px;&quot;&gt;&lt;-------------The End-------------&gt;&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt;[root@iZ28xbsfvc4Z next]# vim layout/_macro/post.swig # 修改该文件，在 &lt;div class=&quot;post-body&gt;…………&lt;/div&gt; 标签后增加如下信息 &lt;!-- 文章末尾统一添加“本文结束”标记 --&gt; &lt;div&gt; &#123;% if not is_index %&#125; &#123;% include &apos;passage-end-tag.swig&apos; %&#125; &#123;% endif %&#125; &lt;/div&gt;[root@iZ28xbsfvc4Z next]# vim _config.yml # 主题配置文件修改# 文章末尾添加“本文结束”标记passage_end_tag: enabled: true 页面效果 推荐阅读Linux下使用 github+hexo 搭建个人博客01-hexo搭建 Linux下使用 github+hexo 搭建个人博客02-hexo部署到Github Pages Linux下使用 github+hexo 搭建个人博客03-hexo配置优化 Linux下使用 github+hexo 搭建个人博客04-next主题优化 Linux下使用 github+hexo 搭建个人博客05-next主题接入评论系统 Linux下使用 github+hexo 搭建个人博客06-next主题接入数据统计 Linux下使用 github+hexo 搭建个人博客07-next主题接入搜索和站点管理]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用 github+hexo 搭建个人博客03-hexo配置优化]]></title>
    <url>%2F2019%2F06%2F14%2Fhexo03%2F</url>
    <content type="text"><![CDATA[前言上两张文章，我们说了 hexo 部署、主题的切换、博文的创建、MarkDown 简单使用和 hexo 部署到 GitHub Pages。 也说了我们会使用 next 主题做为我们后期博客的使用和维护。但是该主题的原生态，可能或多或少不满足我们当前的需求，因此需要我们对其进行优化，达到我们想要的效果。 因此这篇文章和下篇文章主要就是针对主题的优化进行书写的。 注意事项 1、优化完毕或者新建博客后需要 hexo g 生成静态文件； 2、然后重新启动服务，使用命令 hexo s -p 80 3、浏览器查看没有问题后，部署到 GitHub，使用命令：hexo d hexo 的 _config.yml优化官网地址 https://hexo.io/zh-cn/docs/configuration.html 网站设置部分123456789[root@zhangblog hexo]# vim _config.yml # Sitetitle: lightzhang博客subtitle:description: lightzhang博客，不止于技术，更记录人生点滴感悟。keywords:author: lightzhanglanguage:timezone: title 网站标题，需要填写subtitle 网站副标题description 网站描述，主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。author 您的名字，用于主题显示文章的作者。language 网站使用的语言timezone 网站时区。Hexo 默认使用您电脑的时区。 网址设置部分1234567[root@zhangblog hexo]# vim _config.yml # URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: http://www.zhangblog.comroot: /permalink: :year/:month/:day/:title/permalink_defaults: url 网址root 网站根目录permalink 文章的永久链接格式 默认格式 :year/:month/:day/:title/permalink_defaults 永久链接中各部分的默认值 网站存放在子目录如果您的网站存放在子目录中，例如 http://yoursite.com/blog，则请将您的 url 设为 http://yoursite.com/blog 并把 root 设为 /blog/。 目录设置部分12345678910[root@zhangblog hexo]# vim _config.yml# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render: 目录一般不需要修改。source_dir 资源文件夹，这个文件夹用来存放内容。默认：sourcepublic_dir 公共文件夹，这个文件夹用于存放生成的站点文件。默认：publictag_dir 标签文件夹。默认：tagsarchive_dir 归档文件夹。默认：archivescategory_dir 分类文件夹。默认：categoriescode_dir Include code 文件夹 downloads/codei18n_dir 国际化（i18n）文件夹。默认 :langskip_render 跳过指定文件的渲染 文章设置部分12345678910111213141516[root@zhangblog hexo]# vim _config.yml# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: 一般不用修改new_post_name 新文章的文件名称。默认 :title.mddefault_layout 预设布局，默认 postauto_spacing 在中文和英文之间加入空格，默认 falsetitlecase 把标题转换为 title case，默认 falseexternal_link 在新标签中打开链接，默认 truefilename_case 把文件名称转换为 (1) 小写或 (2) 大写，默认 0render_drafts 显示草稿，默认 falsepost_asset_folder 启动 Asset 文件夹，默认 falserelative_link 把链接改为与根目录的相对位址，默认 falsefuture 显示未来的文章，默认 truehighlight 代码块的设置 分页设置部分12345[root@zhangblog hexo]# vim _config.yml # Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page per_page 每页显示的文章量 (0 = 关闭分页功能)，默认 10pagination_dir 分页目录，默认 page 扩展部分设置1234[root@zhangblog hexo]# vim _config.yml # Extensions# 使用主题theme: next theme 当前使用主题名称。值为false时禁用主题 部署部分设置1234567[root@zhangblog hexo]# vim _config.yml# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:zhanglianghhh/zhanglianghhh.github.io.git branch: master deploy 部署部分的设置 推荐阅读Linux下使用 github+hexo 搭建个人博客01-hexo搭建 Linux下使用 github+hexo 搭建个人博客02-hexo部署到Github Pages Linux下使用 github+hexo 搭建个人博客03-hexo配置优化 Linux下使用 github+hexo 搭建个人博客04-next主题优化 Linux下使用 github+hexo 搭建个人博客05-next主题接入评论系统 Linux下使用 github+hexo 搭建个人博客06-next主题接入数据统计 Linux下使用 github+hexo 搭建个人博客07-next主题接入搜索和站点管理]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用 github+hexo 搭建个人博客02-hexo部署到Github Pages]]></title>
    <url>%2F2019%2F06%2F12%2Fhexo02%2F</url>
    <content type="text"><![CDATA[前言之前的这篇文章《Linux下使用 github+hexo 搭建个人博客01-hexo搭建》，相信大家都知道怎么搭建 hexo ，怎么切换主题，并且完成了一篇博文的创建，以及 MarkDown 标记语法的用法。如果还不清楚或者不知道的，那就先回去看看这篇文章。 那么我们接下来就需要将 hexo 和 GitHub Pages 结合了，为什么要结合呢？因为当前我们的博客还是在本地机器，如果因为我们不小心删了数据，或者购买的云服务因为没有及时续费，导致机器被释放了，那我们就永久失去了这些数据。 因此如果这些数据对我们还有用，并且想永久保存，那么就需要找个类似 SVN 或者 Git 之类的代码版本托管仓库了。那理所当然选 GitHub 了，就当前环境还有比 GitHub 更好的吗。 注册 GitHub 账号GitHub 官网： https://github.com/ 具体注册过程也很简单，这里就不说了。请自行注册。 使用 GitHub Pages创建指定的 GitHub 仓库点击创建按钮 仓库名称和配置选择 开启 GitHub Pages进入 Settings 默认已开启 GitHub Pages 选择主题 浏览器访问 https://zhanglianghhh.github.io/ 在 GitHub 上添加 SSH Keys 信息为了能将个人博客服务器上的博客数据推送到 GitHub，达到数据永久保存效果，我们需要把博客服务器的 SSH keys 信息在 GitHub 上添加信任。 本地服务器创建 ssh-key 信息123456789101112131415161718192021222324252627282930[root@zhangblog ~]# ssh-keygen -t rsa # 如果遇见等待输入的地方，按下 Enter 回车键即可，无需任何其他输入Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:73zrQW4LTBgAVqQKvOoTxFrgaGF/sobf643Q+3w7or0 root@zhangblogThe key&apos;s randomart image is:+---[RSA 2048]----+| o++ ||oo . . . ||*oo . . ||.*o+ . o ||+oo + S . . ||oo o. + o ||. +... + + ||.. ...*. = o.o || .. .*+E+.=o+. |+----[SHA256]-----+[root@zhangblog ~]# cd .ssh/[root@zhangblog .ssh]# lltotal 12-rw------- 1 root root 0 Jun 3 17:02 authorized_keys-rw------- 1 root root 1675 Jun 5 14:17 id_rsa-rw-r--r-- 1 root root 396 Jun 5 14:17 id_rsa.pub-rw-r--r-- 1 root root 395 Dec 14 17:15 known_hosts[root@zhangblog .ssh]# cat id_rsa.pub # 具体的公钥信息ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQD4iDDDDDDDDDDgMMutdH7KdI5P7BrtHbfRG+MYyr1/Gtz45hJgbVHBCTFZaTn2+MekFQcZVkyc2kEU7L7mm4ZGWkStgbXkas+uTFwo3kLlX8ozcUC3jM8rhzbWPv8piq58ezBnrMZ0zNsCgHGXpokUmLqYt1mpLXz5rsOzwGgHHkp+Wlr+6tTQxr/+9T4CiE/RkFKi/mehn01rjOcVluYSkwkVii03EzMlMcoyV3ctnWzwyZIWAQAsvDSN2CQAdRtaUHOJOAoRv8/s4jDiWU1ia0JYmm2D/IWcLl2hxNtGeVHTFk9l1djtUQu47zuoOM4y6ySlUx28HNIAMw14gjIv5 root@zhangblog GitHub 添加 SSH Keys OK，这样我们就添加成功了。 GitHub 连接测试1234567[root@zhangblog ~]# ssh -T git@github.comThe authenticity of host &apos;github.com (13.250.177.223)&apos; can&apos;t be established.RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.RSA key fingerprint is MD5:16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;github.com,13.250.177.223&apos; (RSA) to the list of known hosts.Hi zhanglianghhh! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 可见连接 GitHub 成功。 设置你的账号信息12[root@zhangblog hexo]# git config --global user.name &quot;zhanglianghhh&quot; [root@zhangblog hexo]# git config --global user.email &quot;zhanglianghhh@163.com&quot; 这里的用户名和邮箱，应该和Github上的账户邮箱保持一致，防止之后同步的不一致。 Hexo 部署到 GitHub Pages_config.yml 配置修改12345678910[root@zhangblog hexo]# pwd/app/softinsall/hexo[root@zhangblog hexo]# vim _config.yml………………# Deployment## Docs: https://hexo.io/docs/deployment.html # 修改或添加如下信息deploy: type: git repo: git@github.com:zhanglianghhh/zhanglianghhh.github.io.git branch: master 在部署到 GitHub 之前，还需要安装如下扩展： 123[root@iZ28xbsfvc4Z hexo]# pwd # 站点目录/app/softinsall/hexo[root@iZ28xbsfvc4Z hexo]# npm install hexo-deployer-git --save 部署到 GitHub123[root@zhangblog hexo]# pwd/app/softinsall/hexo[root@zhangblog hexo]# hexo d -g # 部署前，先生成静态文件 -g 可选 浏览器访问12https://zhanglianghhh.github.io/ # GitHub Pages 的访问http://www.zhangblog.com/ # 个人网站的访问 推荐阅读Linux下使用 github+hexo 搭建个人博客01-hexo搭建 Linux下使用 github+hexo 搭建个人博客02-hexo部署到Github Pages Linux下使用 github+hexo 搭建个人博客03-hexo配置优化 Linux下使用 github+hexo 搭建个人博客04-next主题优化 Linux下使用 github+hexo 搭建个人博客05-next主题接入评论系统 Linux下使用 github+hexo 搭建个人博客06-next主题接入数据统计 Linux下使用 github+hexo 搭建个人博客07-next主题接入搜索和站点管理]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用 github+hexo 搭建个人博客01-hexo搭建]]></title>
    <url>%2F2019%2F06%2F11%2Fhexo01%2F</url>
    <content type="text"><![CDATA[前言文章首发于：lightzhang博客文章地址：http://www.zhangblog.com微信公众号：OpenInfo 为什么要搭建自己的博客系统？ 原因有好几个吧，归类如下：1、自己搭建博客系统很有成就感，可以自己选定页面风格和页面排版； 2、自己搭建博客系统可以根据自己的需要添加各种插件功能，因此整体上比网上的第三方博客网站更好； 3、hexo 支持 MarkDown 标记语法，我们可以很容易的上手，排版简单明了； 4、网上主流的第三方博客网站，不一定很符合你个人的风格，而且由于网站要持续运营下去，因此在此过程中会不可避免的接入广告。当然这点我们也要理解，要允许网站有盈利，这样才能一直为大家服务下去； 5、第三方博客网站肯定会有系统升级，因此会时有出现各种改版的情况，你之前写的博文可能不符合新版本，造成之前的博文排版变得奇丑无比，简直令人崩溃「当然这种情况很少」。还有就是如果改版后符合你的操作习惯那还好，如果不符合那你就有点方了。 6、第三方博客网站有时会出现其他问题。最常见的就是博客页面改版「上一条说过」和图片加载不出来的情况等等。 大概就是上述几条吧，如果你还有其他的原因，欢迎你在文章底部留言！ 说明：如果要把 hexo 生成的静态文件对外提供访问，那么请使用 Nginx 完成。Nginx的部分配置如下： 1234567891011121314server &#123; listen 80; server_name www.zhangblog.com zhangblog.com 120.27.48.179; access_log logs/access.log main; location / &#123; alias /app/softinsall/hexo/public/; index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 本次部署的机器信息12机器系统：CentOS Linux release 7.5IP地址：120.27.48.179 因为该博客本人会长期维护和支持下去，因此我是在阿里云购买的机器。 域名解析【可省略】由于这个博客系统是我以后经常使用并且持续维护，因此我在阿里云购买了域名并且进行了备案。域名为：zhangblog.com 。并将域名 zhangblog 解析到了 120.27.48.179。 如果你只是个人测试使用，或者没有自己的域名，那么该项可省略。 安装 Git1[root@zhangblog ~]# yum install -y git 具体使用处1、后续在 hexo 安装不同的主题时，会使用Git方式获取这些主题；2、将 hexo 与自己的 GitHub Pages 结合时。 node.js 安装nodejs 下载官网地址： 1http://nodejs.cn/download/ 为了方便，我们直接下载二进制版本。这样就省去了编译安装步骤。 二进制安装包下载 123[root@zhangblog software]# pwd/app/software[root@zhangblog software]# wget https://npm.taobao.org/mirrors/node/v10.16.0/node-v10.16.0-linux-x64.tar.xz # 下载二进制安装包 nodejs 部署123456789101112[root@zhangblog software]# pwd/app/software[root@zhangblog software]# tar xf node-v10.16.0-linux-x64.tar.xz [root@zhangblog software]# mv node-v10.16.0-linux-x64 /app/softinsall/[root@zhangblog software]# cd /app/softinsall/[root@zhangblog softinsall]# pwd/app/softinsall[root@zhangblog softinsall]# ln -s node-v10.16.0-linux-x64 nodejs[root@zhangblog softinsall]# lltotal 4lrwxrwxrwx 1 root root 23 Jun 4 15:59 nodejs -&gt; node-v10.16.0-linux-x64drwxrwxr-x 6 500 500 4096 May 29 05:36 node-v10.16.0-linux-x64 版本信息 1234[root@zhangblog bin]# pwd/app/softinsall/nodejs/bin[root@zhangblog bin]# ./node -vv10.16.0 创建软连接 12[root@zhangblog bin]# ln -s /app/softinsall/nodejs/bin/node /usr/local/bin/node [root@zhangblog bin]# ln -s /app/softinsall/nodejs/bin/npm /usr/local/bin/npm hexo 常用操作如果熟悉 hexo 命令，那么可以忽略这一节。 hexo 操作命令官网 1https://hexo.io/docs/commands $ hexo init [folder]初始化一个网站。如果没有提供文件夹，Hexo将在当前目录中创建网站。 $ hexo new [layout] 创建新文章。如果没有提供布局，Hexo 将使用 _config.yml 中的 default_layout 项提供的布局。如果标题包含空格，用引号括起来。 $ hexo generate 1简写：hexo g 生成静态文件。 可选项 1-d, --deploy 生成静态文件完成后部署 $ hexo server 1简写：hexo s 启动本地服务器。默认情况下，这是在 http://localhost:4000/ 可选项 1-p, --port 使用端口，覆盖默认端口 $ hexo deploy 1简写：hexo d 部署你的网站。 可选项 1-g, --generate 完成部署之前，生成静态文件。 $ hexo clean清除缓存文件(db.json)和生成的文件(public)。使用新主题或想重新生成静态文件时可使用 $ hexo version版本信息 12345678910111213141516171819[root@zhangblog hexo]# hexo versionhexo: 3.8.0hexo-cli: 2.0.0os: Linux 3.10.0-862.14.4.el7.x86_64 linux x64http_parser: 2.8.0node: 10.16.0v8: 6.8.275.32-node.52uv: 1.28.0zlib: 1.2.11brotli: 1.0.7ares: 1.15.0modules: 64nghttp2: 1.34.0napi: 4openssl: 1.1.1bicu: 64.2unicode: 12.1cldr: 35.1tz: 2019a hexo 部署1[root@zhangblog ~]# npm install hexo-cli -g # 安装 hexo 将 hexo 命令添加到全局，采用软连接方式。 123[root@zhangblog bin]# pwd # hexo 命令所在目录/app/softinsall/nodejs/lib/node_modules/hexo-cli/bin[root@zhangblog bin]# ln -s /app/softinsall/nodejs/lib/node_modules/hexo-cli/bin/hexo /usr/local/bin/hexo 部署 hexo 博客环境部署 hexo可以放在和 nodejs 同层级的目录。 1234567891011121314151617[root@zhangblog softinsall]# pwd/app/softinsall[root@zhangblog softinsall]# mkdir hexo[root@zhangblog softinsall]# cd hexo/[root@zhangblog hexo]# hexo init # 新建一个网站，默认在目前的文件夹建立网站。[root@zhangblog hexo]# ll total 168-rw-r--r-- 1 root root 1765 Jun 4 16:14 _config.ymldrwxr-xr-x 285 root root 12288 Jun 4 16:15 node_modules-rw-r--r-- 1 root root 443 Jun 4 16:14 package.json-rw-r--r-- 1 root root 138442 Jun 4 16:15 package-lock.jsondrwxr-xr-x 2 root root 4096 Jun 4 16:14 scaffoldsdrwxr-xr-x 3 root root 4096 Jun 4 16:14 sourcedrwxr-xr-x 3 root root 4096 Jun 4 16:14 themes[root@zhangblog hexo]# ll themes/ # 查看自带的主题total 4drwxr-xr-x 6 root root 4096 Jun 4 16:14 landscape 启动环境测试123456789101112131415[root@zhangblog hexo]# hexo g # 生成静态文件[root@zhangblog hexo]# lltotal 200-rw-r--r-- 1 root root 1765 Jun 4 16:14 _config.yml-rw-r--r-- 1 root root 25063 Jun 4 16:26 db.jsondrwxr-xr-x 285 root root 12288 Jun 4 16:15 node_modules-rw-r--r-- 1 root root 447 Jun 4 16:26 package.json-rw-r--r-- 1 root root 138442 Jun 4 16:15 package-lock.jsondrwxr-xr-x 7 root root 4096 Jun 4 16:26 public # 生成的静态文件drwxr-xr-x 2 root root 4096 Jun 4 16:14 scaffoldsdrwxr-xr-x 3 root root 4096 Jun 4 16:14 sourcedrwxr-xr-x 3 root root 4096 Jun 4 16:14 themes[root@zhangblog hexo]# hexo s # 启动服务，默认是 http://localhost:4000INFO Start processingINFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop. 端口信息12[root@zhangblog ~]# netstat -lntup | grep &apos;hexo&apos;tcp6 0 0 :::4000 :::* LISTEN 7072/hexo 浏览器访问1http://www.zhangblog.com:4000/ 更新 hexo 主题获取NexT主题该主题是我们以后长期使用的主题，后续的优化也是基于该主题进行。由于该主题风格和页面排版都很好，因此推荐大家使用。 123456[root@zhangblog hexo]# pwd/app/softinsall/hexo# 注意当前的目录， themes/next 指定存放的位置[root@zhangblog hexo]# git clone https://github.com/theme-next/hexo-theme-next themes/next # 新地址，当前维护中【但是有些细节不如老版本的】# 或者 ***** [root@zhangblog hexo]# git clone https://github.com/iissnan/hexo-theme-next themes/next # 老地址，没有维护了「推荐使用」 next 主题在 GitHub 有两个地址： 12https://github.com/theme-next/hexo-theme-next # 新地址，当前维护中https://github.com/iissnan/hexo-theme-next # 老地址，没有维护了 使用主题12345678910[root@zhangblog hexo]# hexo clean # 清楚缓存和静态文件目录[root@zhangblog hexo]# vim _config.yml # 修改该配置…………# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: next…………[root@zhangblog hexo]# hexo g # 生成静态文件[root@zhangblog hexo]# hexo s -p 80 # 启动服务，指定端口 浏览器访问1http://www.zhangblog.com/ 新建一篇博客新建博客12345678910[root@zhangblog hexo]# pwd/app/softinsall/hexo[root@zhangblog hexo]# hexo new &apos;MarkDown_Use_Guide&apos;INFO Created: /app/softinsall/hexo/source/_posts/MarkDown_Use_Guide.md[root@zhangblog hexo]# cat source/_posts/MarkDown_Use_Guide.md # 系统生成内容如下---title: MarkDown_Use_Guidedate: 2019-06-04 19:28:51tags:--- 为博客添加内容—- Markdown 新手指南123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115[root@zhangblog hexo]# pwd/app/softinsall/hexo[root@zhangblog hexo]# cat source/_posts/MarkDown_Use_Guide.md ---title: MarkDown 新手指南date: 2019-06-04 19:28:51tags: - MarkDowncategories: - MarkDown---# 标题# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 ---# 列表## 无序列表- 文本1- 文本2- 文本3## 有序列表1. 文本12. 文本23. 文本3---# 链接、图片和引用## 这是一个超连接[lightzhang 个人博客](http://www.zhangblog.com/)## 这是一个站外图片链接![示例图](https://www.cnblogs.com/images/logo_small.gif)## 这是一个站内图片链接![数字网络](/uploads/weixin_pulic_small.jpg)## 这个一个引用&gt; 宠辱不惊，看庭前花开花落；去留无意，望天上云卷云舒---# 粗体和斜体从最开始的 *wordpress* ,到 *tale* ,到现在的**hexo**,网站变得越来越简单,越来越轻量级,这里主要说说**hexo**的使用。---# 代码引用## 多行代码···「备注：实践中，请把前一行开头的 · 改为 `」#!/bin/bash################ Version Info ################### Create Date: 2018-09-29# Author: Zhang# Mail: zhang@xxxx.com# Version: 1.0# Attention: 脚本描述说明################################################···「备注：实践中，请把前一行开头的 · 改为 `」## 单行代码 【只能一行】`/bin/sh echo &quot;test&quot; &gt;&gt; /dev/null`---# 表格## 书写格式1| Tables | Are | Cool || ------------- |:-------------:| -----:|| col 3 is | right-aligned | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 |## 书写格式2dog | bird | cat----|------|----foo | foo | foobar | bar | barbaz | baz | baz## 书写格式3| 名称 | 系统版本 | 内网IP | Hostname ||--|--|--|--|| salt100 | CentOS7.5 | 172.16.1.100 | 10.0.0.100 || salt01 | CentOS7.5 | 172.16.1.11 | 10.0.0.11 || salt02 | CentOS7.5 | 172.16.1.12 | 10.0.0.12 || salt03 | CentOS7.5 | 172.16.1.13 | 10.0.0.13 |# 字体或图片居中&lt;center&gt;**读万卷书，行万里路**&lt;/center&gt;&lt;center&gt;![数字网络](/uploads/avatar_small.png)&lt;/center&gt;--- 站内图片位置12345678[root@zhangblog hexo]# pwd # 站点位置/app/softinsall/hexo[root@zhangblog hexo]# ll source/uploads/total 388-rw-r--r-- 1 root root 131807 Apr 30 14:39 avatar.png-rw-r--r-- 1 root root 16602 Jun 7 17:39 avatar_small.png-rw-r--r-- 1 root root 209605 Jun 7 17:02 weixin_pulic.jpg-rw-r--r-- 1 root root 19296 Jun 11 14:55 weixin_pulic_small.jpg 生成静态文件123[root@zhangblog hexo]# pwd/app/softinsall/hexo[root@zhangblog hexo]# hexo g # 生成静态文件 浏览器访问12http://www.zhangblog.com/http://www.zhangblog.com/2019/06/04/MarkDown_Use_Guide/ 推荐阅读Linux下使用 github+hexo 搭建个人博客01-hexo搭建 Linux下使用 github+hexo 搭建个人博客02-hexo部署到Github Pages Linux下使用 github+hexo 搭建个人博客03-hexo配置优化 Linux下使用 github+hexo 搭建个人博客04-next主题优化 Linux下使用 github+hexo 搭建个人博客05-next主题接入评论系统 Linux下使用 github+hexo 搭建个人博客06-next主题接入数据统计 Linux下使用 github+hexo 搭建个人博客07-next主题接入搜索和站点管理]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown 新手指南]]></title>
    <url>%2F2019%2F06%2F04%2FMarkDown_Use_Guide%2F</url>
    <content type="text"><![CDATA[标题一级标题二级标题三级标题四级标题五级标题六级标题 列表无序列表 文本1 文本2 文本3 有序列表 文本1 文本2 文本3 链接、图片和引用这是一个超连接lightzhang 个人博客 这是一个站外图片链接 这是一个站内图片链接 这个一个引用 宠辱不惊，看庭前花开花落；去留无意，望天上云卷云舒 粗体和斜体从最开始的 wordpress ,到 tale ,到现在的hexo,网站变得越来越简单,越来越轻量级,这里主要说说hexo的使用。 代码引用多行代码12345678#!/bin/bash################ Version Info ################### Create Date: 2018-09-29# Author: Zhang# Mail: zhang@xxxx.com# Version: 1.0# Attention: 脚本描述说明################################################ 单行代码 【只能一行】/bin/sh echo &quot;test&quot; &gt;&gt; /dev/null 表格书写格式1 Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 书写格式2 dog bird cat foo foo foo bar bar bar baz baz baz 书写格式3 名称 系统版本 内网IP Hostname salt100 CentOS7.5 172.16.1.100 10.0.0.100 salt01 CentOS7.5 172.16.1.11 10.0.0.11 salt02 CentOS7.5 172.16.1.12 10.0.0.12 salt03 CentOS7.5 172.16.1.13 10.0.0.13 字体或图片居中 读万卷书，行万里路]]></content>
      <categories>
        <category>MarkDown</category>
      </categories>
      <tags>
        <tag>MarkDown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F06%2F03%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
